{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## TorchServe Continuous Batching Serve Llama-2-70B on Inferentia-2\n",
    "This notebook demonstrates TorchServe continuous batching serving Llama-2-70b on Inferentia-2 `inf2.48xlarge` with DLAMI: Deep Learning AMI Neuron PyTorch 1.13 (Ubuntu 20.04) 20231226"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Installation\n",
    "Note: This section can be skipped once Neuron DLC 2.16 with TorchServe latest version is released."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Install Python venv\n",
    "!sudo apt-get install -y python3.9-venv g++\n",
    "\n",
    "# Create Python venv\n",
    "!python3.9 -m venv aws_neuron_venv_pytorch\n",
    "\n",
    "# Activate Python venv\n",
    "!source aws_neuron_venv_pytorch/bin/activate\n",
    "!python -m pip install -U pip\n",
    "\n",
    "# Clone Torchserve git repository\n",
    "!git clone https://github.com/pytorch/serve.git\n",
    "\n",
    "# Install dependencies, now all commands run under serve dir\n",
    "!cd serve\n",
    "!git checkout feat/inf2_cb\n",
    "!python ts_scripts/install_dependencies.py --neuronx --environment=dev\n",
    "\n",
    "# Install torchserve and torch-model-archiver\n",
    "python ts_scripts/install_from_src.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create model artifacts\n",
    "\n",
    "Note: run `mv model/models--meta-llama--Llama-2-70b-hf/snapshots/90052941a64de02075ca800b09fcea1bdaacb939/model.safetensors.index.json model/models--meta-llama--Llama-2-70b-hf/snapshots/90052941a64de02075ca800b09fcea1bdaacb939/model.safetensors.index.json.bkp`\n",
    " if neuron sdk does not support safetensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# login in Hugginface hub\n",
    "!huggingface-cli login --token $HUGGINGFACE_TOKEN\n",
    "!python examples/large_models/utils/Download_model.py --model_path model --model_name meta-llama/Llama-2-13b-hf --use_auth_token True\n",
    "\n",
    "# Create TorchServe model artifacts\n",
    "!torch-model-archiver --model-name llama-2-70b --version 1.0 --handler ts/torch_handler/distributed/base_neuronx_continuous_batching_handler.py -r examples/large_models/inferentia2/llama2/requirements.txt --config-file examples/large_models/inferentia2/llama2/continuous_batching/model-config.yaml --archive-format no-archive\n",
    "\n",
    "!mkdir -p model_store\n",
    "!mv llama-2-70b model_store\n",
    "!mv model model_store/llama-2-70b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Start TorchServe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torchserve --ncs --start --model-store model_store --models llama-2-70b --ts-config examples/large_models/inferentia2/llama2/config.properties"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run single inference request\n",
    "!python examples/large_models/utils/test_llm_streaming_response.py -m llama-2-70b -o 50 -t 2 -n 4 --prompt-text \"Today the weather is really nice and I am planning on \" --prompt-randomize"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
