# TorchServe frontend parameters
minWorkers: 1
maxWorkers: 1
maxBatchDelay: 100
responseTimeout: 1200
deviceType: "gpu"
asyncCommunication: true

handler:
    model_path: "model/models--mistralai--Mistral-7B-v0.1/snapshots/26bca36bde8333b5d7f72e9ed20ccda6a618af24"
    vllm_engine_config:
        max_model_len: 250
        max_num_seqs: 16
        tensor_parallel_size: 4
        served_model_name:
            - "mistral"
