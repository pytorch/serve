transformers
llama-cpp-python
streamlit>=1.26.0
requests_futures
