


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Batch Inference with TorchServe &mdash; PyTorch/Serve master documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Code Coverage" href="code_coverage.html" />
    <link rel="prev" title="Performance Guide" href="performance_guide.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  master 
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">TorchServe</a></li>
<li class="toctree-l1"><a class="reference internal" href="Troubleshooting.html">Troubleshooting Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_guide.html">Performance Guide</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Batch Inference with TorchServe</a></li>
<li class="toctree-l1"><a class="reference internal" href="code_coverage.html">Code Coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="configuration.html">Advanced configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_service.html">Custom Service</a></li>
<li class="toctree-l1"><a class="reference internal" href="default_handlers.html">TorchServe default inference handlers</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging in Torchserve</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">TorchServe Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="request_envelopes.html">Request Envelopes</a></li>
<li class="toctree-l1"><a class="reference internal" href="server.html">Running TorchServe</a></li>
<li class="toctree-l1"><a class="reference internal" href="mps.html">Running TorchServe with NVIDIA MPS</a></li>
<li class="toctree-l1"><a class="reference internal" href="snapshot.html">TorchServe model snapshot</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchserve_on_win_native.html">TorchServe on Windows</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchserve_on_wsl.html">TorchServe on Windows Subsystem for Linux (WSL)</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_cases.html">Torchserve Use Cases</a></li>
<li class="toctree-l1"><a class="reference internal" href="workflows.html">TorchServe Workflows</a></li>
<li class="toctree-l1"><a class="reference internal" href="large_model_inference.html">Serving large models with Torchserve</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQs.html">FAQ’S</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Service APIs:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="grpc_api.html">TorchServe gRPC API</a></li>
<li class="toctree-l1"><a class="reference internal" href="inference_api.html">Inference API</a></li>
<li class="toctree-l1"><a class="reference internal" href="management_api.html">Management API</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics_api.html">Metrics API</a></li>
<li class="toctree-l1"><a class="reference internal" href="rest_api.html">TorchServe REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="workflow_inference_api.html">Workflow Inference API</a></li>
<li class="toctree-l1"><a class="reference internal" href="workflow_management_api.html">Management API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer APIs:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/ts.html">ts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/ts.torch_handler.request_envelope.html">ts.torch_handler.request_envelope package</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/ts.torch_handler.html">ts.torch_handler package</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/ts.metrics.html">ts.metrics package</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/ts.model_service.html">ts.model_service package</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/ts.protocol.html">ts.protocol package</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">serve</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="contents.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Batch Inference with TorchServe</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/batch_inference_with_ts.md.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id="
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="batch-inference-with-torchserve">
<h1>Batch Inference with TorchServe<a class="headerlink" href="#batch-inference-with-torchserve" title="Permalink to this heading">¶</a></h1>
<section id="contents-of-this-document">
<h2>Contents of this Document<a class="headerlink" href="#contents-of-this-document" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="#introduction">Introduction</a></p></li>
<li><p><a class="reference external" href="#prerequisites">Prerequisites</a></p></li>
<li><p><a class="reference external" href="#batch-inference-with-torchserves-default-handlers">Batch Inference with TorchServe’s default handlers</a></p></li>
<li><p><a class="reference external" href="#batch-inference-with-torchserve-using-resnet-152-model">Batch Inference with TorchServe using ResNet-152 model</a></p></li>
<li><p><a class="reference external" href="#demo-to-configure-torchserve-resnet-152-model-with-batch-supported-model">Demo to configure TorchServe ResNet-152 model with batch-supported model</a></p></li>
<li><p><a class="reference external" href="#demo-to-configure-torchserve-resnet-152-model-with-batch-supported-model-using-docker">Demo to configure TorchServe ResNet-152 model with batch-supported model using Docker</a></p></li>
</ul>
</section>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">¶</a></h2>
<p>Batch inference is a process of aggregating inference requests and sending this aggregated requests through the ML/DL framework for inference all at once.
TorchServe was designed to natively support batching of incoming inference requests. This functionality enables you to use your host resources optimally,
because most ML/DL frameworks are optimized for batch requests.
This optimal use of host resources in turn reduces the operational expense of hosting an inference service using TorchServe.</p>
<p>In this document we show an example of how to use batch inference in Torchserve when serving models locally or using docker containers.</p>
</section>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this heading">¶</a></h2>
<p>Before jumping into this document, read the following docs:</p>
<ol class="simple">
<li><p><a class="reference internal" href="README.html"><span class="doc">What is TorchServe?</span></a></p></li>
<li><p><a class="reference internal" href="custom_service.html"><span class="doc">What is custom service code?</span></a></p></li>
</ol>
</section>
<section id="batch-inference-with-torchserve-s-default-handlers">
<h2>Batch Inference with TorchServe’s default handlers<a class="headerlink" href="#batch-inference-with-torchserve-s-default-handlers" title="Permalink to this heading">¶</a></h2>
<p>TorchServe’s default handlers support batch inference out of box except for <code class="docutils literal notranslate"><span class="pre">text_classifier</span></code> handler.</p>
</section>
<section id="batch-inference-with-torchserve-using-resnet-152-model">
<h2>Batch Inference with TorchServe using ResNet-152 model<a class="headerlink" href="#batch-inference-with-torchserve-using-resnet-152-model" title="Permalink to this heading">¶</a></h2>
<p>To support batch inference, TorchServe needs the following:</p>
<ol class="simple">
<li><p>TorchServe model configuration: Configure <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> and <code class="docutils literal notranslate"><span class="pre">max_batch_delay</span></code> by using the  “POST /models” management API or settings in config.properties.
TorchServe needs to know the maximum batch size that the model can handle and the maximum time that TorchServe should wait to fill each batch request.</p></li>
<li><p>Model handler code: TorchServe requires the Model handler to handle batch inference requests.</p></li>
</ol>
<p>For a full working example of a custom model handler with batch processing, see <a class="reference external" href="https://github.com/pytorch/serve/blob/master/examples/Huggingface_Transformers/Transformer_handler_generalized.py">Hugging face transformer generalized handler</a></p>
<section id="torchserve-model-configuration">
<h3>TorchServe Model Configuration<a class="headerlink" href="#torchserve-model-configuration" title="Permalink to this heading">¶</a></h3>
<p>Started from Torchserve 0.4.1, there are two methods to configure TorchServe to use the batching feature:</p>
<ol class="simple">
<li><p>provide the batch configuration information through <a class="reference internal" href="management_api.html"><span class="doc">POST /models API</span></a>.</p></li>
<li><p>provide the batch configuration information through configuration file, config.properties.</p></li>
</ol>
<p>The configuration properties that we are interested in are the following:</p>
<ol class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">batch_size</span></code>: This is the maximum batch size that a model is expected to handle.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_batch_delay</span></code>: This is the maximum batch delay time in <code class="docutils literal notranslate"><span class="pre">ms</span></code> TorchServe waits to receive <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> number of requests. If TorchServe doesn’t receive <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> number of
requests before this timer time’s out, it sends what ever requests that were received to the model <code class="docutils literal notranslate"><span class="pre">handler</span></code>.</p></li>
</ol>
<p>Let’s look at an example using this configuration through management API:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># The following command will register a model &quot;resnet-152.mar&quot; and configure TorchServe to use a batch_size of 8 and a max batch delay of 50 milliseconds. </span>
curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span><span class="s2">&quot;localhost:8081/models?url=resnet-152.mar&amp;batch_size=8&amp;max_batch_delay=50&quot;</span>
</pre></div>
</div>
<p>Here is an example of using this configuration through the config.properties:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># The following command will register a model &quot;resnet-152.mar&quot; and configure TorchServe to use a batch_size of 8 and a max batch delay of 50 milli seconds, in the config.properties.

models={\
  &quot;resnet-152&quot;: {\
    &quot;1.0&quot;: {\
        &quot;defaultVersion&quot;: true,\
        &quot;marName&quot;: &quot;resnet-152.mar&quot;,\
        &quot;minWorkers&quot;: 1,\
        &quot;maxWorkers&quot;: 1,\
        &quot;batchSize&quot;: 8,\
        &quot;maxBatchDelay&quot;: 50,\
        &quot;responseTimeout&quot;: 120\
    }\
  }\
}
</pre></div>
</div>
<p>These configurations are used both in TorchServe and in the model’s custom service code (a.k.a the handler code).
TorchServe associates the batch related configuration with each model.
The frontend then tries to aggregate the batch-size number of requests and send it to the backend.</p>
</section>
</section>
<section id="demo-to-configure-torchserve-resnet-152-model-with-batch-supported-model">
<h2>Demo to configure TorchServe ResNet-152 model with batch-supported model<a class="headerlink" href="#demo-to-configure-torchserve-resnet-152-model-with-batch-supported-model" title="Permalink to this heading">¶</a></h2>
<p>In this section lets bring up model server and launch Resnet-152 model, which uses the default <code class="docutils literal notranslate"><span class="pre">image_classifier</span></code> handler for batch inferencing.</p>
<section id="setup-torchserve-and-torch-model-archiver">
<h3>Setup TorchServe and Torch Model Archiver<a class="headerlink" href="#setup-torchserve-and-torch-model-archiver" title="Permalink to this heading">¶</a></h3>
<p>First things first, follow the main <a class="reference internal" href="README.html"><span class="doc">Readme</span></a> and install all the required packages including <code class="docutils literal notranslate"><span class="pre">torchserve</span></code>.</p>
</section>
<section id="batch-inference-of-resnet-152-configured-with-management-api">
<h3>Batch inference of Resnet-152 configured with management API<a class="headerlink" href="#batch-inference-of-resnet-152-configured-with-management-api" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Start the model server. In this example, we are starting the model server to run on inference port 8080 and management port 8081.</p></li>
</ul>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>$ cat config.properties
...
inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
...
$ torchserve --start --model-store model_store
</pre></div>
</div>
<ul class="simple">
<li><p>Verify that TorchServe is up and running</p></li>
</ul>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>$ curl localhost:8080/ping
{
  &quot;status&quot;: &quot;Healthy&quot;
}
</pre></div>
</div>
<ul class="simple">
<li><p>Now let’s launch resnet-152 model, which we have built to handle batch inference. Because this is an example, we are going to launch 1 worker which handles a batch size of 3 with a <code class="docutils literal notranslate"><span class="pre">max_batch_delay</span></code> of 10ms.</p></li>
</ul>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>$ curl -X POST &quot;localhost:8081/models?url=https://torchserve.pytorch.org/mar_files/resnet-152-batch_v2.mar&amp;batch_size=3&amp;max_batch_delay=10&amp;initial_workers=1&quot;
{
  &quot;status&quot;: &quot;Processing worker updates...&quot;
}
</pre></div>
</div>
<ul class="simple">
<li><p>Verify that the workers were started properly.</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>http://localhost:8081/models/resnet-152-batch_v2
</pre></div>
</div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">[</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;modelName&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;resnet-152-batch_v2&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;modelVersion&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2.0&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;modelUrl&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;https://torchserve.pytorch.org/mar_files/resnet-152-batch_v2.mar&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;runtime&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;python&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;minWorkers&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;maxWorkers&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;batchSize&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;maxBatchDelay&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;loadedAtStartup&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;workers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;9000&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;startTime&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2021-06-14T23:18:21.793Z&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;READY&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;memoryUsage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1726554112</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;pid&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">19946</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;gpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;gpuUsage&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpuId::0 utilization.gpu [%]::0 % utilization.memory [%]::0 % memory.used [MiB]::678 MiB&quot;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">]</span>
</pre></div>
</div>
<ul>
<li><p>Now let’s test this service.</p>
<ul>
<li><p>Get an image to test this service</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>$ curl -LJO https://github.com/pytorch/serve/raw/master/examples/image_classifier/kitten.jpg
</pre></div>
</div>
</li>
<li><p>Run inference to test the model.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  $ curl http://localhost:8080/predictions/resnet-152-batch_v2 -T kitten.jpg
  {
      &quot;tiger_cat&quot;: 0.5848360657691956,
      &quot;tabby&quot;: 0.3782736361026764,
      &quot;Egyptian_cat&quot;: 0.03441936895251274,
      &quot;lynx&quot;: 0.0005633446853607893,
      &quot;quilt&quot;: 0.0002698268508538604
  }
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</section>
<section id="batch-inference-of-resnet-152-configured-through-config-properties">
<h3>Batch inference of Resnet-152 configured through config.properties<a class="headerlink" href="#batch-inference-of-resnet-152-configured-through-config-properties" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Here, we first set the <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> and <code class="docutils literal notranslate"><span class="pre">max_batch_delay</span></code>  in the config.properties, make sure the mar file is located in the model-store and the version in the models setting is consistent with version of the mar file created. To read more about configurations please refer to this <a class="reference internal" href="configuration.html"><span class="doc">document</span></a>.</p></li>
</ul>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>load_models=resnet-152-batch_v2.mar
models={\
  &quot;resnet-152-batch_v2&quot;: {\
    &quot;2.0&quot;: {\
        &quot;defaultVersion&quot;: true,\
        &quot;marName&quot;: &quot;resnet-152-batch_v2.mar&quot;,\
        &quot;minWorkers&quot;: 1,\
        &quot;maxWorkers&quot;: 1,\
        &quot;batchSize&quot;: 3,\
        &quot;maxBatchDelay&quot;: 5000,\
        &quot;responseTimeout&quot;: 120\
    }\
  }\
}
</pre></div>
</div>
<ul class="simple">
<li><p>Then will start Torchserve by passing the config.properties using <code class="docutils literal notranslate"><span class="pre">--ts-config</span></code> flag</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>torchserve<span class="w"> </span>--start<span class="w"> </span>--model-store<span class="w"> </span>model_store<span class="w">  </span>--ts-config<span class="w"> </span>config.properties
</pre></div>
</div>
<ul class="simple">
<li><p>Verify that TorchServe is up and running</p></li>
</ul>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>$ curl localhost:8080/ping
{
  &quot;status&quot;: &quot;Healthy&quot;
}
</pre></div>
</div>
<ul class="simple">
<li><p>Verify that the workers were started properly.</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>http://localhost:8081/models/resnet-152-batch_v2
</pre></div>
</div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">[</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;modelName&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;resnet-152-batch_v2&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;modelVersion&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2.0&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;modelUrl&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;resnet-152-batch_v2.mar&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;runtime&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;python&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;minWorkers&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;maxWorkers&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;batchSize&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;maxBatchDelay&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">5000</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;loadedAtStartup&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;workers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;9000&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;startTime&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2021-06-14T22:44:36.742Z&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;READY&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;memoryUsage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;pid&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">19116</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;gpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;gpuUsage&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpuId::0 utilization.gpu [%]::0 % utilization.memory [%]::0 % memory.used [MiB]::678 MiB&quot;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">]</span>
</pre></div>
</div>
<ul>
<li><p>Now let’s test this service.</p>
<ul>
<li><p>Get an image to test this service</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>$ curl -LJO https://github.com/pytorch/serve/raw/master/examples/image_classifier/kitten.jpg
</pre></div>
</div>
</li>
<li><p>Run inference to test the model.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  $ curl http://localhost:8080/predictions/resnet-152-batch_v2 -T kitten.jpg
  {
      &quot;tiger_cat&quot;: 0.5848360657691956,
      &quot;tabby&quot;: 0.3782736361026764,
      &quot;Egyptian_cat&quot;: 0.03441936895251274,
      &quot;lynx&quot;: 0.0005633446853607893,
      &quot;quilt&quot;: 0.0002698268508538604
  }
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</section>
</section>
<section id="demo-to-configure-torchserve-resnet-152-model-with-batch-supported-model-using-docker">
<h2>Demo to configure TorchServe ResNet-152 model with batch-supported model using Docker<a class="headerlink" href="#demo-to-configure-torchserve-resnet-152-model-with-batch-supported-model-using-docker" title="Permalink to this heading">¶</a></h2>
<p>Here, we show how to register a model with batch inference support when serving the model using docker containers. We set the <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> and <code class="docutils literal notranslate"><span class="pre">max_batch_delay</span></code>  in the config.properties similar to the previous section which is being used by <a class="reference external" href="../docker/dockerd-entrypoint.sh">dockered_entrypoint.sh</a>.</p>
<section id="batch-inference-of-resnet-152-using-docker-container">
<h3>Batch inference of Resnet-152 using docker container<a class="headerlink" href="#batch-inference-of-resnet-152-using-docker-container" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Set the batch <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> and <code class="docutils literal notranslate"><span class="pre">max_batch_delay</span></code>  in the config.properties as referenced in the <a class="reference external" href="../docker/dockerd-entrypoint.sh">dockered_entrypoint.sh</a></p></li>
</ul>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
metrics_address=http://0.0.0.0:8082
number_of_netty_threads=32
job_queue_size=1000
model_store=/home/model-server/model-store
load_models=resnet-152-batch_v2.mar
models={\
  &quot;resnet-152-batch_v2&quot;: {\
    &quot;1.0&quot;: {\
        &quot;defaultVersion&quot;: true,\
        &quot;marName&quot;: &quot;resnet-152-batch_v2.mar&quot;,\
        &quot;minWorkers&quot;: 1,\
        &quot;maxWorkers&quot;: 1,\
        &quot;batchSize&quot;: 3,\
        &quot;maxBatchDelay&quot;: 100,\
        &quot;responseTimeout&quot;: 120\
    }\
  }\
}
</pre></div>
</div>
<ul class="simple">
<li><p>build the targeted docker image from <a class="reference external" href="../docker">here</a>, here we use the gpu image</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build_image.sh<span class="w"> </span>-g<span class="w"> </span>-cv<span class="w"> </span>cu102
</pre></div>
</div>
<ul class="simple">
<li><p>Start serving the model with the container and pass the config.properties to the container</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="w"> </span>docker<span class="w"> </span>run<span class="w"> </span>--rm<span class="w"> </span>-it<span class="w"> </span>--gpus<span class="w"> </span>all<span class="w"> </span>-p<span class="w"> </span><span class="m">8080</span>:8080<span class="w"> </span>-p<span class="w"> </span><span class="m">8081</span>:8081<span class="w"> </span>--name<span class="w"> </span>mar<span class="w"> </span>-v<span class="w"> </span>/home/ubuntu/serve/model_store:/home/model-server/model-store<span class="w">  </span>-v<span class="w"> </span>$<span class="w"> </span>path<span class="w"> </span>to<span class="w"> </span>config.properties:/home/model-server/config.properties<span class="w">  </span>pytorch/torchserve:latest-gpu
</pre></div>
</div>
<ul class="simple">
<li><p>Verify that the workers were started properly.</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>http://localhost:8081/models/resnet-152-batch_v2
</pre></div>
</div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">[</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;modelName&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;resnet-152-batch_v2&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;modelVersion&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2.0&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;modelUrl&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;resnet-152-batch_v2.mar&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;runtime&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;python&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;minWorkers&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;maxWorkers&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;batchSize&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;maxBatchDelay&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">5000</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;loadedAtStartup&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;workers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;9000&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;startTime&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2021-06-14T22:44:36.742Z&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;READY&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;memoryUsage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;pid&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">19116</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;gpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;gpuUsage&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpuId::0 utilization.gpu [%]::0 % utilization.memory [%]::0 % memory.used [MiB]::678 MiB&quot;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">]</span>
</pre></div>
</div>
<ul>
<li><p>Now let’s test this service.</p>
<ul>
<li><p>Get an image to test this service</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>$ curl -LJO https://github.com/pytorch/serve/raw/master/examples/image_classifier/kitten.jpg
</pre></div>
</div>
</li>
<li><p>Run inference to test the model.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  $ curl http://localhost:8080/predictions/resnet-152-batch_v2 -T kitten.jpg
  {
      &quot;tiger_cat&quot;: 0.5848360657691956,
      &quot;tabby&quot;: 0.3782736361026764,
      &quot;Egyptian_cat&quot;: 0.03441936895251274,
      &quot;lynx&quot;: 0.0005633446853607893,
      &quot;quilt&quot;: 0.0002698268508538604
  }
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</section>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="code_coverage.html" class="btn btn-neutral float-right" title="Code Coverage" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="performance_guide.html" class="btn btn-neutral" title="Performance Guide" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, PyTorch Serve Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Batch Inference with TorchServe</a><ul>
<li><a class="reference internal" href="#contents-of-this-document">Contents of this Document</a></li>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li><a class="reference internal" href="#batch-inference-with-torchserve-s-default-handlers">Batch Inference with TorchServe’s default handlers</a></li>
<li><a class="reference internal" href="#batch-inference-with-torchserve-using-resnet-152-model">Batch Inference with TorchServe using ResNet-152 model</a><ul>
<li><a class="reference internal" href="#torchserve-model-configuration">TorchServe Model Configuration</a></li>
</ul>
</li>
<li><a class="reference internal" href="#demo-to-configure-torchserve-resnet-152-model-with-batch-supported-model">Demo to configure TorchServe ResNet-152 model with batch-supported model</a><ul>
<li><a class="reference internal" href="#setup-torchserve-and-torch-model-archiver">Setup TorchServe and Torch Model Archiver</a></li>
<li><a class="reference internal" href="#batch-inference-of-resnet-152-configured-with-management-api">Batch inference of Resnet-152 configured with management API</a></li>
<li><a class="reference internal" href="#batch-inference-of-resnet-152-configured-through-config-properties">Batch inference of Resnet-152 configured through config.properties</a></li>
</ul>
</li>
<li><a class="reference internal" href="#demo-to-configure-torchserve-resnet-152-model-with-batch-supported-model-using-docker">Demo to configure TorchServe ResNet-152 model with batch-supported model using Docker</a><ul>
<li><a class="reference internal" href="#batch-inference-of-resnet-152-using-docker-container">Batch inference of Resnet-152 using docker container</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/katex.min.js"></script>
         <script src="_static/auto-render.min.js"></script>
         <script src="_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>