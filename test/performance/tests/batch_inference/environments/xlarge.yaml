---
settings:
  env:
    API_LABEL : Inference
    API_SUCCESS : 80%
    API_AVG_RT : 30ms

    TOTAL_WORKERS: 4
    TOTAL_WORKERS_MEM: 3000000000
    TOTAL_WORKERS_FDS: 400

    TOTAL_MEM : 4000000000
    TOTAL_PROCS : 7
    TOTAL_FDS : 200

    FRNTEND_MEM: 1000000000

    TOTAL_ORPHANS : 0
    TOTAL_ZOMBIES : 0


    ## Percent diff values to do a compare across runs
    TOTAL_WORKERS_PREV_DIFF: 0
    TOTAL_WORKERS_MEM_PREV_DIFF: 30
    TOTAL_WORKERS_FDS_PREV_DIFF: 30
    TOTAL_MEM_PREV_DIFF: 30
    TOTAL_PROCS_PREV_DIFF: 30
    TOTAL_FDS_PREV_DIFF: 30
    FRNTEND_MEM_PREV_DIFF: 30
    TOTAL_ORPHANS_PREV_DIFF: 0
    TOTAL_ZOMBIES_PREV_DIFF: 0

    TOTAL_WORKERS_RUN_DIFF: 0
    TOTAL_WORKERS_MEM_RUN_DIFF: 40
    TOTAL_WORKERS_FDS_RUN_DIFF: 30
    TOTAL_MEM_RUN_DIFF: 45
    TOTAL_PROCS_RUN_DIFF: 30
    TOTAL_FDS_RUN_DIFF: 30
    FRNTEND_MEM_RUN_DIFF: 80
    TOTAL_ORPHANS_RUN_DIFF: 0
    TOTAL_ZOMBIES_RUN_DIFF: 0

    CONCURRENCY : 10
    RAMP-UP : 1s
    HOLD-FOR : 300s
    SCRIPT : batch_inference.jmx

    STOP : ''
    STOP_ALIAS: continue


