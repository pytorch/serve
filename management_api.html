


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Management API &mdash; PyTorch/Serve master documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Metrics API" href="metrics_api.html" />
    <link rel="prev" title="Inference API" href="inference_api.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  master 
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">TorchServe</a></li>
<li class="toctree-l1"><a class="reference internal" href="Troubleshooting.html">Troubleshooting Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_guide.html">Performance Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="batch_inference_with_ts.html">Batch Inference with TorchServe</a></li>
<li class="toctree-l1"><a class="reference internal" href="code_coverage.html">Code Coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="configuration.html">Advanced configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_service.html">Custom Service</a></li>
<li class="toctree-l1"><a class="reference internal" href="default_handlers.html">TorchServe default inference handlers</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging in Torchserve</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">TorchServe Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="request_envelopes.html">Request Envelopes</a></li>
<li class="toctree-l1"><a class="reference internal" href="server.html">Running TorchServe</a></li>
<li class="toctree-l1"><a class="reference internal" href="mps.html">Running TorchServe with NVIDIA MPS</a></li>
<li class="toctree-l1"><a class="reference internal" href="snapshot.html">TorchServe model snapshot</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchserve_on_win_native.html">TorchServe on Windows</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchserve_on_wsl.html">TorchServe on Windows Subsystem for Linux (WSL)</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_cases.html">Torchserve Use Cases</a></li>
<li class="toctree-l1"><a class="reference internal" href="workflows.html">TorchServe Workflows</a></li>
<li class="toctree-l1"><a class="reference internal" href="large_model_inference.html">Serving large models with Torchserve</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQs.html">FAQ’S</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Service APIs:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="grpc_api.html">TorchServe gRPC API</a></li>
<li class="toctree-l1"><a class="reference internal" href="inference_api.html">Inference API</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Management API</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics_api.html">Metrics API</a></li>
<li class="toctree-l1"><a class="reference internal" href="rest_api.html">TorchServe REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="workflow_inference_api.html">Workflow Inference API</a></li>
<li class="toctree-l1"><a class="reference internal" href="workflow_management_api.html">Management API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer APIs:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/ts.html">ts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/ts.torch_handler.request_envelope.html">ts.torch_handler.request_envelope package</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/ts.torch_handler.html">ts.torch_handler package</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/ts.metrics.html">ts.metrics package</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/ts.model_service.html">ts.model_service package</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/ts.protocol.html">ts.protocol package</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">serve</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="contents.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="apis.html">&lt;no title&gt;</a> &gt;</li>
        
      <li>Management API</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/management_api.md.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id="
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="management-api">
<h1><a class="reference external" href="#management-api">Management API</a><a class="headerlink" href="#management-api" title="Permalink to this heading">¶</a></h1>
<p>TorchServe provides the following APIs that allows you to manage models at runtime:</p>
<ol class="simple">
<li><p><a class="reference external" href="#register-a-model">Register a model</a></p></li>
<li><p><a class="reference external" href="#scale-workers">Increase/decrease number of workers for specific model</a></p></li>
<li><p><a class="reference external" href="#describe-model">Describe a model’s status</a></p></li>
<li><p><a class="reference external" href="#unregister-a-model">Unregister a model</a></p></li>
<li><p><a class="reference external" href="#list-models">List registered models</a></p></li>
<li><p><a class="reference external" href="#set-default-version">Set default version of a model</a></p></li>
</ol>
<p>The Management API listens on port 8081 and is only accessible from localhost by default. To change the default setting, see <a class="reference internal" href="configuration.html"><span class="doc">TorchServe Configuration</span></a>.</p>
<p>Similar to the <a class="reference internal" href="inference_api.html"><span class="doc">Inference API</span></a>, the Management API provides a <a class="reference external" href="#api-description">API description</a> to describe management APIs with the OpenAPI 3.0 specification.</p>
<p>Alternatively, if you want to use KServe, TorchServe supports both v1 and v2 API. For more details please look into this <a class="reference external" href="https://github.com/pytorch/serve/tree/master/kubernetes/kserve">kserve documentation</a></p>
<section id="register-a-model">
<h2>Register a model<a class="headerlink" href="#register-a-model" title="Permalink to this heading">¶</a></h2>
<p>This API follows the <a class="reference external" href="https://github.com/pytorch/serve/blob/master/frontend/server/src/main/resources/proto/management.proto">ManagementAPIsService.RegisterModel</a> gRPC API.</p>
<p><code class="docutils literal notranslate"><span class="pre">POST</span> <span class="pre">/models</span></code></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">url</span></code> - Model archive download url. Supports the following locations:</p>
<ul>
<li><p>a local model archive (.mar); the file must be in the <code class="docutils literal notranslate"><span class="pre">model_store</span></code> folder (and not in a subfolder).</p></li>
<li><p>a URI using the HTTP(s) protocol. TorchServe can download .mar files from the Internet.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">model_name</span></code> - the name of the model; this name will be used as {model_name} in other APIs as part of the path. If this parameter is not present, <code class="docutils literal notranslate"><span class="pre">modelName</span></code> in MANIFEST.json will be used.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">handler</span></code> - the inference handler entry-point. This value will override <code class="docutils literal notranslate"><span class="pre">handler</span></code> in MANIFEST.json if present. <strong>NOTE: Make sure that the given <code class="docutils literal notranslate"><span class="pre">handler</span></code> is in the <code class="docutils literal notranslate"><span class="pre">PYTHONPATH</span></code>. The format of handler is <code class="docutils literal notranslate"><span class="pre">module_name:method_name</span></code>.</strong></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">runtime</span></code> - the runtime for the model custom service code. This value will override runtime in MANIFEST.json if present. The default value is <code class="docutils literal notranslate"><span class="pre">PYTHON</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batch_size</span></code> - the inference batch size. The default value is <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_batch_delay</span></code> - the maximum delay for batch aggregation. The default value is 100 milliseconds.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">initial_workers</span></code> - the number of initial workers to create. The default value is <code class="docutils literal notranslate"><span class="pre">0</span></code>. TorchServe will not run inference until there is at least one work assigned.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">synchronous</span></code> - whether or not the creation of worker is synchronous. The default value is false. TorchServe will create new workers without waiting for acknowledgement that the previous worker is online.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">response_timeout</span></code> - If the model’s backend worker doesn’t respond with inference response within this timeout period, the worker will be deemed unresponsive and rebooted. The units is seconds. The default value is 120 seconds.</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w">  </span><span class="s2">&quot;http://localhost:8081/models?url=https://torchserve.pytorch.org/mar_files/squeezenet1_1.mar&quot;</span>

<span class="o">{</span>
<span class="w">  </span><span class="s2">&quot;status&quot;</span>:<span class="w"> </span><span class="s2">&quot;Model \&quot;squeezenet_v1.1\&quot; Version: 1.0 registered with 0 initial workers. Use scale workers API to add workers for the model.&quot;</span>
<span class="o">}</span>
</pre></div>
</div>
<section id="encrypted-model-serving">
<h3>Encrypted model serving<a class="headerlink" href="#encrypted-model-serving" title="Permalink to this heading">¶</a></h3>
<p>If you’d like to serve an encrypted model then you need to setup <a class="reference external" href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingKMSEncryption.html">S3 SSE-KMS</a> with the following environment variables:</p>
<ul class="simple">
<li><p>AWS_ACCESS_KEY_ID</p></li>
<li><p>AWS_SECRET_ACCESS_KEY</p></li>
<li><p>AWS_DEFAULT_REGION</p></li>
</ul>
<p>And set “s3_sse_kms=true” in HTTP request.</p>
<p>For example: model squeezenet1_1 is <a class="reference external" href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingKMSEncryption.html">encrypted on S3 under your own private account</a>. The model http url on S3 is <code class="docutils literal notranslate"><span class="pre">https://torchserve.pytorch.org/sse-test/squeezenet1_1.mar</span></code>.</p>
<ul class="simple">
<li><p>if torchserve will run on EC2 instance (e.g. OS: ubuntu)</p></li>
</ul>
<ol class="simple">
<li><p>add an IAM Role (AWSS3ReadOnlyAccess) for the EC2 instance</p></li>
<li><p>run ts_scripts/get_aws_credential.sh to export AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY</p></li>
<li><p>export AWS_DEFAULT_REGION=your_s3_bucket_region</p></li>
<li><p>start torchserve</p></li>
<li><p>Register encrypted model squeezenet1_1 by setting s3_sse_kms=true in curl command.</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w">  </span><span class="s2">&quot;http://localhost:8081/models?url=https://torchserve.pytorch.org/sse-test/squeezenet1_1.mar&amp;s3_sse_kms=true&quot;</span>

<span class="o">{</span>
<span class="w">  </span><span class="s2">&quot;status&quot;</span>:<span class="w"> </span><span class="s2">&quot;Model \&quot;squeezenet_v1.1\&quot; Version: 1.0 registered with 0 initial workers. Use scale workers API to add workers for the model.&quot;</span>
<span class="o">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>if torchserve will run on local (e.g. OS: macOS)</p></li>
</ul>
<ol class="simple">
<li><p>Find your AWS access key and secret key. You can <a class="reference external" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys_retrieve.html">reset them</a> if you forgot the keys.</p></li>
<li><p>export AWS_ACCESS_KEY_ID=your_aws_access_key</p></li>
<li><p>export AWS_SECRET_ACCESS_KEY=your_aws_secret_key</p></li>
<li><p>export AWS_DEFAULT_REGION=your_s3_bucket_region</p></li>
<li><p>start torchserve</p></li>
<li><p>Register encrypted model squeezenet1_1 by setting s3_sse_kms=true in curl command (same as EC2 example step 5).</p></li>
</ol>
<p>You might want to create workers during registration. because creating initial workers might take some time,
you can choose between synchronous or asynchronous call to make sure initial workers are created properly.</p>
<p>The asynchronous call returns with HTTP code 202 before trying to create workers.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>-v<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span><span class="s2">&quot;http://localhost:8081/models?initial_workers=1&amp;synchronous=false&amp;url=https://torchserve.pytorch.org/mar_files/squeezenet1_1.mar&quot;</span>

&lt;<span class="w"> </span>HTTP/1.1<span class="w"> </span><span class="m">202</span><span class="w"> </span>Accepted
&lt;<span class="w"> </span>content-type:<span class="w"> </span>application/json
&lt;<span class="w"> </span>x-request-id:<span class="w"> </span>4dc54158-c6de-42aa-b5dd-ebcb5f721043
&lt;<span class="w"> </span>content-length:<span class="w"> </span><span class="m">47</span>
&lt;<span class="w"> </span>connection:<span class="w"> </span>keep-alive
&lt;
<span class="o">{</span>
<span class="w">  </span><span class="s2">&quot;status&quot;</span>:<span class="w"> </span><span class="s2">&quot;Processing worker updates...&quot;</span>
<span class="o">}</span>
</pre></div>
</div>
<p>The synchronous call returns with HTTP code 200 after all workers have been adjusted.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>-v<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span><span class="s2">&quot;http://localhost:8081/models?initial_workers=1&amp;synchronous=true&amp;url=https://torchserve.pytorch.org/mar_files/squeezenet1_1.mar&quot;</span>

&lt;<span class="w"> </span>HTTP/1.1<span class="w"> </span><span class="m">200</span><span class="w"> </span>OK
&lt;<span class="w"> </span>content-type:<span class="w"> </span>application/json
&lt;<span class="w"> </span>x-request-id:<span class="w"> </span>ecd2e502-382f-4c3b-b425-519fbf6d3b85
&lt;<span class="w"> </span>content-length:<span class="w"> </span><span class="m">89</span>
&lt;<span class="w"> </span>connection:<span class="w"> </span>keep-alive
&lt;
<span class="o">{</span>
<span class="w">  </span><span class="s2">&quot;status&quot;</span>:<span class="w"> </span><span class="s2">&quot;Model \&quot;squeezenet1_1\&quot; Version: 1.0 registered with 1 initial workers&quot;</span>
<span class="o">}</span>
</pre></div>
</div>
</section>
</section>
<section id="scale-workers">
<h2>Scale workers<a class="headerlink" href="#scale-workers" title="Permalink to this heading">¶</a></h2>
<p>This API follows the <a class="reference external" href="https://github.com/pytorch/serve/blob/master/frontend/server/src/main/resources/proto/management.proto">ManagementAPIsService.ScaleWorker</a> gRPC API. It returns the status of a model in the ModelServer.</p>
<p><code class="docutils literal notranslate"><span class="pre">PUT</span> <span class="pre">/models/{model_name}</span></code></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">min_worker</span></code> - (optional) the minimum number of worker processes. TorchServe will try to maintain this minimum for specified model. The default value is <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_worker</span></code> - (optional) the maximum number of worker processes. TorchServe will make no more that this number of workers for the specified model. The default is the same as the setting for <code class="docutils literal notranslate"><span class="pre">min_worker</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">synchronous</span></code> - whether or not the call is synchronous. The default value is <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">timeout</span></code> - the specified wait time for a worker to complete all pending requests. If exceeded, the work process will be terminated. Use <code class="docutils literal notranslate"><span class="pre">0</span></code> to terminate the backend worker process immediately. Use <code class="docutils literal notranslate"><span class="pre">-1</span></code> to wait infinitely. The default value is <code class="docutils literal notranslate"><span class="pre">-1</span></code>.</p></li>
</ul>
<p>Use the Scale Worker API to dynamically adjust the number of workers for any version of a model to better serve different inference request loads.</p>
<p>There are two different flavors of this API, synchronous and asynchronous.</p>
<p>The asynchronous call will return immediately with HTTP code 202:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>-v<span class="w"> </span>-X<span class="w"> </span>PUT<span class="w"> </span><span class="s2">&quot;http://localhost:8081/models/noop?min_worker=3&quot;</span>

&lt;<span class="w"> </span>HTTP/1.1<span class="w"> </span><span class="m">202</span><span class="w"> </span>Accepted
&lt;<span class="w"> </span>content-type:<span class="w"> </span>application/json
&lt;<span class="w"> </span>x-request-id:<span class="w"> </span>42adc58e-6956-4198-ad07-db6c620c4c1e
&lt;<span class="w"> </span>content-length:<span class="w"> </span><span class="m">47</span>
&lt;<span class="w"> </span>connection:<span class="w"> </span>keep-alive
&lt;
<span class="o">{</span>
<span class="w">  </span><span class="s2">&quot;status&quot;</span>:<span class="w"> </span><span class="s2">&quot;Processing worker updates...&quot;</span>
<span class="o">}</span>
</pre></div>
</div>
<p>The synchronous call returns with HTTP code 200 after all workers have been adjusted.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>-v<span class="w"> </span>-X<span class="w"> </span>PUT<span class="w"> </span><span class="s2">&quot;http://localhost:8081/models/noop?min_worker=3&amp;synchronous=true&quot;</span>

&lt;<span class="w"> </span>HTTP/1.1<span class="w"> </span><span class="m">200</span><span class="w"> </span>OK
&lt;<span class="w"> </span>content-type:<span class="w"> </span>application/json
&lt;<span class="w"> </span>x-request-id:<span class="w"> </span>b72b1ea0-81c6-4cce-92c4-530d3cfe5d4a
&lt;<span class="w"> </span>content-length:<span class="w"> </span><span class="m">63</span>
&lt;<span class="w"> </span>connection:<span class="w"> </span>keep-alive
&lt;
<span class="o">{</span>
<span class="w">  </span><span class="s2">&quot;status&quot;</span>:<span class="w"> </span><span class="s2">&quot;Workers scaled to 3 for model: noop&quot;</span>
<span class="o">}</span>
</pre></div>
</div>
<p>To scale workers of a specific version of a model use URI : /models/{model_name}/{version}
<code class="docutils literal notranslate"><span class="pre">PUT</span> <span class="pre">/models/{model_name}/{version}</span></code></p>
<p>The following synchronous call will return after all workers for version “2.0” for model “noop” has be adjusted with HTTP code 200.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>-v<span class="w"> </span>-X<span class="w"> </span>PUT<span class="w"> </span><span class="s2">&quot;http://localhost:8081/models/noop/2.0?min_worker=3&amp;synchronous=true&quot;</span>

&lt;<span class="w"> </span>HTTP/1.1<span class="w"> </span><span class="m">200</span><span class="w"> </span>OK
&lt;<span class="w"> </span>content-type:<span class="w"> </span>application/json
&lt;<span class="w"> </span>x-request-id:<span class="w"> </span>3997ccd4-ae44-4570-b249-e361b08d3d47
&lt;<span class="w"> </span>content-length:<span class="w"> </span><span class="m">77</span>
&lt;<span class="w"> </span>connection:<span class="w"> </span>keep-alive
&lt;
<span class="o">{</span>
<span class="w">  </span><span class="s2">&quot;status&quot;</span>:<span class="w"> </span><span class="s2">&quot;Workers scaled to 3 for model: noop, version: 2.0&quot;</span>
<span class="o">}</span>
</pre></div>
</div>
</section>
<section id="describe-model">
<h2>Describe model<a class="headerlink" href="#describe-model" title="Permalink to this heading">¶</a></h2>
<p>This API follows the <a class="reference external" href="https://github.com/pytorch/serve/blob/master/frontend/server/src/main/resources/proto/management.proto">ManagementAPIsService.DescribeModel</a> gRPC API. It returns the status of a model in the ModelServer.</p>
<p><code class="docutils literal notranslate"><span class="pre">GET</span> <span class="pre">/models/{model_name}</span></code></p>
<p>Use the Describe Model API to get detail runtime status of default version of a model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>http://localhost:8081/models/noop
<span class="o">[</span>
<span class="w">    </span><span class="o">{</span>
<span class="w">      </span><span class="s2">&quot;modelName&quot;</span>:<span class="w"> </span><span class="s2">&quot;noop&quot;</span>,
<span class="w">      </span><span class="s2">&quot;modelVersion&quot;</span>:<span class="w"> </span><span class="s2">&quot;1.0&quot;</span>,
<span class="w">      </span><span class="s2">&quot;modelUrl&quot;</span>:<span class="w"> </span><span class="s2">&quot;noop.mar&quot;</span>,
<span class="w">      </span><span class="s2">&quot;engine&quot;</span>:<span class="w"> </span><span class="s2">&quot;Torch&quot;</span>,
<span class="w">      </span><span class="s2">&quot;runtime&quot;</span>:<span class="w"> </span><span class="s2">&quot;python&quot;</span>,
<span class="w">      </span><span class="s2">&quot;minWorkers&quot;</span>:<span class="w"> </span><span class="m">1</span>,
<span class="w">      </span><span class="s2">&quot;maxWorkers&quot;</span>:<span class="w"> </span><span class="m">1</span>,
<span class="w">      </span><span class="s2">&quot;batchSize&quot;</span>:<span class="w"> </span><span class="m">1</span>,
<span class="w">      </span><span class="s2">&quot;maxBatchDelay&quot;</span>:<span class="w"> </span><span class="m">100</span>,
<span class="w">      </span><span class="s2">&quot;workers&quot;</span>:<span class="w"> </span><span class="o">[</span>
<span class="w">        </span><span class="o">{</span>
<span class="w">          </span><span class="s2">&quot;id&quot;</span>:<span class="w"> </span><span class="s2">&quot;9000&quot;</span>,
<span class="w">          </span><span class="s2">&quot;startTime&quot;</span>:<span class="w"> </span><span class="s2">&quot;2018-10-02T13:44:53.034Z&quot;</span>,
<span class="w">          </span><span class="s2">&quot;status&quot;</span>:<span class="w"> </span><span class="s2">&quot;READY&quot;</span>,
<span class="w">          </span><span class="s2">&quot;gpu&quot;</span>:<span class="w"> </span>false,
<span class="w">          </span><span class="s2">&quot;memoryUsage&quot;</span>:<span class="w"> </span><span class="m">89247744</span>
<span class="w">        </span><span class="o">}</span>
<span class="w">      </span><span class="o">]</span>
<span class="w">    </span><span class="o">}</span>
<span class="o">]</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">GET</span> <span class="pre">/models/{model_name}/{version}</span></code></p>
<p>Use the Describe Model API to get detail runtime status of specific version of a model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>http://localhost:8081/models/noop/2.0
<span class="o">[</span>
<span class="w">    </span><span class="o">{</span>
<span class="w">      </span><span class="s2">&quot;modelName&quot;</span>:<span class="w"> </span><span class="s2">&quot;noop&quot;</span>,
<span class="w">      </span><span class="s2">&quot;modelVersion&quot;</span>:<span class="w"> </span><span class="s2">&quot;2.0&quot;</span>,
<span class="w">      </span><span class="s2">&quot;modelUrl&quot;</span>:<span class="w"> </span><span class="s2">&quot;noop_2.mar&quot;</span>,
<span class="w">      </span><span class="s2">&quot;engine&quot;</span>:<span class="w"> </span><span class="s2">&quot;Torch&quot;</span>,
<span class="w">      </span><span class="s2">&quot;runtime&quot;</span>:<span class="w"> </span><span class="s2">&quot;python&quot;</span>,
<span class="w">      </span><span class="s2">&quot;minWorkers&quot;</span>:<span class="w"> </span><span class="m">1</span>,
<span class="w">      </span><span class="s2">&quot;maxWorkers&quot;</span>:<span class="w"> </span><span class="m">1</span>,
<span class="w">      </span><span class="s2">&quot;batchSize&quot;</span>:<span class="w"> </span><span class="m">1</span>,
<span class="w">      </span><span class="s2">&quot;maxBatchDelay&quot;</span>:<span class="w"> </span><span class="m">100</span>,
<span class="w">      </span><span class="s2">&quot;workers&quot;</span>:<span class="w"> </span><span class="o">[</span>
<span class="w">        </span><span class="o">{</span>
<span class="w">          </span><span class="s2">&quot;id&quot;</span>:<span class="w"> </span><span class="s2">&quot;9000&quot;</span>,
<span class="w">          </span><span class="s2">&quot;startTime&quot;</span>:<span class="w"> </span><span class="s2">&quot;2018-10-02T13:44:53.034Z&quot;</span>,
<span class="w">          </span><span class="s2">&quot;status&quot;</span>:<span class="w"> </span><span class="s2">&quot;READY&quot;</span>,
<span class="w">          </span><span class="s2">&quot;gpu&quot;</span>:<span class="w"> </span>false,
<span class="w">          </span><span class="s2">&quot;memoryUsage&quot;</span>:<span class="w"> </span><span class="m">89247744</span>
<span class="w">        </span><span class="o">}</span>
<span class="w">      </span><span class="o">]</span>
<span class="w">    </span><span class="o">}</span>
<span class="o">]</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">GET</span> <span class="pre">/models/{model_name}/all</span></code></p>
<p>Use the Describe Model API to get detail runtime status of all version of a model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>http://localhost:8081/models/noop/all
<span class="o">[</span>
<span class="w">    </span><span class="o">{</span>
<span class="w">      </span><span class="s2">&quot;modelName&quot;</span>:<span class="w"> </span><span class="s2">&quot;noop&quot;</span>,
<span class="w">      </span><span class="s2">&quot;modelVersion&quot;</span>:<span class="w"> </span><span class="s2">&quot;1.0&quot;</span>,
<span class="w">      </span><span class="s2">&quot;modelUrl&quot;</span>:<span class="w"> </span><span class="s2">&quot;noop.mar&quot;</span>,
<span class="w">      </span><span class="s2">&quot;engine&quot;</span>:<span class="w"> </span><span class="s2">&quot;Torch&quot;</span>,
<span class="w">      </span><span class="s2">&quot;runtime&quot;</span>:<span class="w"> </span><span class="s2">&quot;python&quot;</span>,
<span class="w">      </span><span class="s2">&quot;minWorkers&quot;</span>:<span class="w"> </span><span class="m">1</span>,
<span class="w">      </span><span class="s2">&quot;maxWorkers&quot;</span>:<span class="w"> </span><span class="m">1</span>,
<span class="w">      </span><span class="s2">&quot;batchSize&quot;</span>:<span class="w"> </span><span class="m">1</span>,
<span class="w">      </span><span class="s2">&quot;maxBatchDelay&quot;</span>:<span class="w"> </span><span class="m">100</span>,
<span class="w">      </span><span class="s2">&quot;workers&quot;</span>:<span class="w"> </span><span class="o">[</span>
<span class="w">        </span><span class="o">{</span>
<span class="w">          </span><span class="s2">&quot;id&quot;</span>:<span class="w"> </span><span class="s2">&quot;9000&quot;</span>,
<span class="w">          </span><span class="s2">&quot;startTime&quot;</span>:<span class="w"> </span><span class="s2">&quot;2018-10-02T13:44:53.034Z&quot;</span>,
<span class="w">          </span><span class="s2">&quot;status&quot;</span>:<span class="w"> </span><span class="s2">&quot;READY&quot;</span>,
<span class="w">          </span><span class="s2">&quot;gpu&quot;</span>:<span class="w"> </span>false,
<span class="w">          </span><span class="s2">&quot;memoryUsage&quot;</span>:<span class="w"> </span><span class="m">89247744</span>
<span class="w">        </span><span class="o">}</span>
<span class="w">      </span><span class="o">]</span>
<span class="w">    </span><span class="o">}</span>,
<span class="w">    </span><span class="o">{</span>
<span class="w">      </span><span class="s2">&quot;modelName&quot;</span>:<span class="w"> </span><span class="s2">&quot;noop&quot;</span>,
<span class="w">      </span><span class="s2">&quot;modelVersion&quot;</span>:<span class="w"> </span><span class="s2">&quot;2.0&quot;</span>,
<span class="w">      </span><span class="s2">&quot;modelUrl&quot;</span>:<span class="w"> </span><span class="s2">&quot;noop_2.mar&quot;</span>,
<span class="w">      </span><span class="s2">&quot;engine&quot;</span>:<span class="w"> </span><span class="s2">&quot;Torch&quot;</span>,
<span class="w">      </span><span class="s2">&quot;runtime&quot;</span>:<span class="w"> </span><span class="s2">&quot;python&quot;</span>,
<span class="w">      </span><span class="s2">&quot;minWorkers&quot;</span>:<span class="w"> </span><span class="m">1</span>,
<span class="w">      </span><span class="s2">&quot;maxWorkers&quot;</span>:<span class="w"> </span><span class="m">1</span>,
<span class="w">      </span><span class="s2">&quot;batchSize&quot;</span>:<span class="w"> </span><span class="m">1</span>,
<span class="w">      </span><span class="s2">&quot;maxBatchDelay&quot;</span>:<span class="w"> </span><span class="m">100</span>,
<span class="w">      </span><span class="s2">&quot;workers&quot;</span>:<span class="w"> </span><span class="o">[</span>
<span class="w">        </span><span class="o">{</span>
<span class="w">          </span><span class="s2">&quot;id&quot;</span>:<span class="w"> </span><span class="s2">&quot;9000&quot;</span>,
<span class="w">          </span><span class="s2">&quot;startTime&quot;</span>:<span class="w"> </span><span class="s2">&quot;2018-10-02T13:44:53.034Z&quot;</span>,
<span class="w">          </span><span class="s2">&quot;status&quot;</span>:<span class="w"> </span><span class="s2">&quot;READY&quot;</span>,
<span class="w">          </span><span class="s2">&quot;gpu&quot;</span>:<span class="w"> </span>false,
<span class="w">          </span><span class="s2">&quot;memoryUsage&quot;</span>:<span class="w"> </span><span class="m">89247744</span>
<span class="w">        </span><span class="o">}</span>
<span class="w">      </span><span class="o">]</span>
<span class="w">    </span><span class="o">}</span>
<span class="o">]</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">GET</span> <span class="pre">/models/{model_name}/{model_version}?customized=true</span></code>
or
<code class="docutils literal notranslate"><span class="pre">GET</span> <span class="pre">/models/{model_name}?customized=true</span></code></p>
<p>Use the Describe Model API to get detail runtime status and customized metadata of a version of a model:</p>
<ul class="simple">
<li><p>Implement function describe_handle. E.g.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="nf">describe_handle</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Customized describe handler</span>
<span class="sd">        Returns:</span>
<span class="sd">            dict : A dictionary response.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output_describe</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Collect customized metadata&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output_describe</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Implement function _is_describe if handler is not inherited from BaseHandler. And then, call _is_describe and describe_handle in handle.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="nf">_is_describe</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">context</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="o">.</span><span class="n">get_request_header</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;describe&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="o">.</span><span class="n">get_request_header</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;describe&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;True&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">handle</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_describe</span><span class="p">():</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">describe_handle</span><span class="p">()]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">data_preprocess</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_explain</span><span class="p">():</span>
                <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data_preprocess</span><span class="p">)</span>
                <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">explain_handle</span><span class="p">(</span><span class="n">data_preprocess</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Call function _is_describe and describe_handle in handle. E.g.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">handle</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Entry point for default handler. It takes the data from the input request and returns</span>
<span class="sd">           the predicted outcome for the input.</span>
<span class="sd">        Args:</span>
<span class="sd">            data (list): The input data that needs to be made a prediction request on.</span>
<span class="sd">            context (Context): It is a JSON Object containing information pertaining to</span>
<span class="sd">                               the model artifacts parameters.</span>
<span class="sd">        Returns:</span>
<span class="sd">            list : Returns a list of dictionary with the predicted response.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># It can be used for pre or post processing if needed as additional request</span>
        <span class="c1"># information is available in context</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">context</span> <span class="o">=</span> <span class="n">context</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="o">.</span><span class="n">metrics</span>

        <span class="n">is_profiler_enabled</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ENABLE_TORCH_PROFILER&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_profiler_enabled</span><span class="p">:</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_infer_with_profiler</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_describe</span><span class="p">():</span>
                <span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">describe_handle</span><span class="p">()]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data_preprocess</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_explain</span><span class="p">():</span>
                    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">data_preprocess</span><span class="p">)</span>
                    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">explain_handle</span><span class="p">(</span><span class="n">data_preprocess</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

        <span class="n">stop_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">metrics</span><span class="o">.</span><span class="n">add_time</span><span class="p">(</span><span class="s1">&#39;HandlerTime&#39;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span>
            <span class="p">(</span><span class="n">stop_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;ms&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Here is an example. “customizedMetadata” shows the metadata from user’s model. These metadata can be decoded into a dictionary.</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>http://localhost:8081/models/noop-customized/1.0?customized<span class="o">=</span><span class="nb">true</span>
<span class="o">[</span>
<span class="w">    </span><span class="o">{</span>
<span class="w">        </span><span class="s2">&quot;modelName&quot;</span>:<span class="w"> </span><span class="s2">&quot;noop-customized&quot;</span>,
<span class="w">        </span><span class="s2">&quot;modelVersion&quot;</span>:<span class="w"> </span><span class="s2">&quot;1.0&quot;</span>,
<span class="w">        </span><span class="s2">&quot;modelUrl&quot;</span>:<span class="w"> </span><span class="s2">&quot;noop-customized.mar&quot;</span>,
<span class="w">        </span><span class="s2">&quot;runtime&quot;</span>:<span class="w"> </span><span class="s2">&quot;python&quot;</span>,
<span class="w">        </span><span class="s2">&quot;minWorkers&quot;</span>:<span class="w"> </span><span class="m">1</span>,
<span class="w">        </span><span class="s2">&quot;maxWorkers&quot;</span>:<span class="w"> </span><span class="m">1</span>,
<span class="w">        </span><span class="s2">&quot;batchSize&quot;</span>:<span class="w"> </span><span class="m">1</span>,
<span class="w">        </span><span class="s2">&quot;maxBatchDelay&quot;</span>:<span class="w"> </span><span class="m">100</span>,
<span class="w">        </span><span class="s2">&quot;loadedAtStartup&quot;</span>:<span class="w"> </span>false,
<span class="w">        </span><span class="s2">&quot;workers&quot;</span>:<span class="w"> </span><span class="o">[</span>
<span class="w">          </span><span class="o">{</span>
<span class="w">            </span><span class="s2">&quot;id&quot;</span>:<span class="w"> </span><span class="s2">&quot;9010&quot;</span>,
<span class="w">            </span><span class="s2">&quot;startTime&quot;</span>:<span class="w"> </span><span class="s2">&quot;2022-02-08T11:03:20.974Z&quot;</span>,
<span class="w">            </span><span class="s2">&quot;status&quot;</span>:<span class="w"> </span><span class="s2">&quot;READY&quot;</span>,
<span class="w">            </span><span class="s2">&quot;memoryUsage&quot;</span>:<span class="w"> </span><span class="m">0</span>,
<span class="w">            </span><span class="s2">&quot;pid&quot;</span>:<span class="w"> </span><span class="m">98972</span>,
<span class="w">            </span><span class="s2">&quot;gpu&quot;</span>:<span class="w"> </span>false,
<span class="w">            </span><span class="s2">&quot;gpuUsage&quot;</span>:<span class="w"> </span><span class="s2">&quot;N/A&quot;</span>
<span class="w">          </span><span class="o">}</span>
<span class="w">        </span><span class="o">]</span>,
<span class="w">        </span><span class="s2">&quot;customizedMetadata&quot;</span>:<span class="w"> </span><span class="s2">&quot;{\n  \&quot;data1\&quot;: \&quot;1\&quot;,\n  \&quot;data2\&quot;: \&quot;2\&quot;\n}&quot;</span>
<span class="w">     </span><span class="o">}</span>
<span class="o">]</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Decode customizedMetadata on client side. For example:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;http://localhost:8081/models/noop-customized/?customized=true&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
<span class="n">customizedMetadata</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;customizedMetadata&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">customizedMetadata</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="unregister-a-model">
<h2>Unregister a model<a class="headerlink" href="#unregister-a-model" title="Permalink to this heading">¶</a></h2>
<p>This API follows the <a class="reference external" href="https://github.com/pytorch/serve/blob/master/frontend/server/src/main/resources/proto/management.proto">ManagementAPIsService.UnregisterModel</a> gRPC API. It returns the status of a model in the ModelServer.</p>
<p><code class="docutils literal notranslate"><span class="pre">DELETE</span> <span class="pre">/models/{model_name}/{version}</span></code></p>
<p>Use the Unregister Model API to free up system resources by unregistering specific version of a model from TorchServe:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>-X<span class="w"> </span>DELETE<span class="w"> </span>http://localhost:8081/models/noop/1.0

<span class="o">{</span>
<span class="w">  </span><span class="s2">&quot;status&quot;</span>:<span class="w"> </span><span class="s2">&quot;Model \&quot;noop\&quot; unregistered&quot;</span>
<span class="o">}</span>
</pre></div>
</div>
</section>
<section id="list-models">
<h2>List models<a class="headerlink" href="#list-models" title="Permalink to this heading">¶</a></h2>
<p>This API follows the <a class="reference external" href="https://github.com/pytorch/serve/blob/master/frontend/server/src/main/resources/proto/management.proto">ManagementAPIsService.ListModels</a> gRPC API. It returns the status of a model in the ModelServer.</p>
<p><code class="docutils literal notranslate"><span class="pre">GET</span> <span class="pre">/models</span></code></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">limit</span></code> - (optional) the maximum number of items to return. It is passed as a query parameter. The default value is <code class="docutils literal notranslate"><span class="pre">100</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">next_page_token</span></code> - (optional) queries for next page. It is passed as a query parameter. This value is return by a previous API call.</p></li>
</ul>
<p>Use the Models API to query default versions of current registered models:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span><span class="s2">&quot;http://localhost:8081/models&quot;</span>
</pre></div>
</div>
<p>This API supports pagination:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span><span class="s2">&quot;http://localhost:8081/models?limit=2&amp;next_page_token=2&quot;</span>

<span class="o">{</span>
<span class="w">  </span><span class="s2">&quot;nextPageToken&quot;</span>:<span class="w"> </span><span class="s2">&quot;4&quot;</span>,
<span class="w">  </span><span class="s2">&quot;models&quot;</span>:<span class="w"> </span><span class="o">[</span>
<span class="w">    </span><span class="o">{</span>
<span class="w">      </span><span class="s2">&quot;modelName&quot;</span>:<span class="w"> </span><span class="s2">&quot;noop&quot;</span>,
<span class="w">      </span><span class="s2">&quot;modelUrl&quot;</span>:<span class="w"> </span><span class="s2">&quot;noop-v1.0&quot;</span>
<span class="w">    </span><span class="o">}</span>,
<span class="w">    </span><span class="o">{</span>
<span class="w">      </span><span class="s2">&quot;modelName&quot;</span>:<span class="w"> </span><span class="s2">&quot;noop_v0.1&quot;</span>,
<span class="w">      </span><span class="s2">&quot;modelUrl&quot;</span>:<span class="w"> </span><span class="s2">&quot;noop-v0.1&quot;</span>
<span class="w">    </span><span class="o">}</span>
<span class="w">  </span><span class="o">]</span>
<span class="o">}</span>
</pre></div>
</div>
</section>
<section id="api-description">
<h2>API Description<a class="headerlink" href="#api-description" title="Permalink to this heading">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">OPTIONS</span> <span class="pre">/</span></code></p>
<p>To view a full list of inference and management APIs, you can use following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># To view all inference APIs:</span>
curl<span class="w"> </span>-X<span class="w"> </span>OPTIONS<span class="w"> </span>http://localhost:8080

<span class="c1"># To view all management APIs:</span>
curl<span class="w"> </span>-X<span class="w"> </span>OPTIONS<span class="w"> </span>http://localhost:8081
</pre></div>
</div>
<p>The out is OpenAPI 3.0.1 json format. You use it to generate client code, see <a class="reference external" href="https://swagger.io/swagger-codegen/">swagger codegen</a> for detail.</p>
<p>Example outputs of the Inference and Management APIs:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/pytorch/serve/blob/master/frontend/server/src/test/resources/inference_open_api.json">Inference API description output</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/serve/blob/master/frontend/server/src/test/resources/management_open_api.json">Management API description output</a></p></li>
</ul>
</section>
<section id="set-default-version">
<h2>Set Default Version<a class="headerlink" href="#set-default-version" title="Permalink to this heading">¶</a></h2>
<p>This API follows the <a class="reference external" href="https://github.com/pytorch/serve/blob/master/frontend/server/src/main/resources/proto/management.proto">ManagementAPIsService.SetDefault</a> gRPC API. It returns the status of a model in the ModelServer.</p>
<p><code class="docutils literal notranslate"><span class="pre">PUT</span> <span class="pre">/models/{model_name}/{version}/set-default</span></code></p>
<p>To set any registered version of a model as default version use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>-v<span class="w"> </span>-X<span class="w"> </span>PUT<span class="w"> </span>http://localhost:8081/models/noop/2.0/set-default
</pre></div>
</div>
<p>The out is OpenAPI 3.0.1 json format. You use it to generate client code, see <a class="reference external" href="https://swagger.io/swagger-codegen/">swagger codegen</a> for detail.</p>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="metrics_api.html" class="btn btn-neutral float-right" title="Metrics API" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="inference_api.html" class="btn btn-neutral" title="Inference API" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, PyTorch Serve Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Management API</a><ul>
<li><a class="reference internal" href="#register-a-model">Register a model</a><ul>
<li><a class="reference internal" href="#encrypted-model-serving">Encrypted model serving</a></li>
</ul>
</li>
<li><a class="reference internal" href="#scale-workers">Scale workers</a></li>
<li><a class="reference internal" href="#describe-model">Describe model</a></li>
<li><a class="reference internal" href="#unregister-a-model">Unregister a model</a></li>
<li><a class="reference internal" href="#list-models">List models</a></li>
<li><a class="reference internal" href="#api-description">API Description</a></li>
<li><a class="reference internal" href="#set-default-version">Set Default Version</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/katex.min.js"></script>
         <script src="_static/auto-render.min.js"></script>
         <script src="_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>