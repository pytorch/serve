apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
 name: "torch-pred-gpu"
spec:
 predictor:
   pytorch:
     protocolVersion: v1
     storageUri: "pvc://model-store-claim"
     resources:
       limits:
         memory: 4Gi
         nvidia.com/gpu: 1
