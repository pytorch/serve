apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: "torchserve"
spec:
  predictor:
    pytorch:
      storageUri: gs://<gpt-fast-url>/v1
      image: abc/torchserve-kfs-nightly:latest-gpu
      resources:
        limits:
          memory: 20Gi
          nvidia.com/gpu: "0"
