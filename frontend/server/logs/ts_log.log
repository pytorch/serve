2019-11-20 14:18:43,793 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: N/A
Initial Models: squeezenet=https://s3.amazonaws.com/model-server/model_archive_1.0/squeezenet_v1.1.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-11-20 14:18:43,804 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: https://s3.amazonaws.com/model-server/model_archive_1.0/squeezenet_v1.1.mar
2019-11-20 14:18:45,585 [INFO ] main org.pytorch.serve.archive.ModelArchive - model folder already exists: 674bbff228fdc041fadbef6f515e86dd
2019-11-20 14:18:45,606 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-11-20 14:18:45,607 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-11-20 14:18:45,634 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-11-20 14:18:45,896 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-11-20 14:18:45,897 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-11-20 14:18:45,899 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-11-20 14:18:45,914 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-11-20 14:18:46,063 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-20 14:18:46,064 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48722
2019-11-20 14:18:46,065 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-20 14:18:46,065 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-20 14:18:46,067 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change null -> WORKER_STARTED
2019-11-20 14:18:46,076 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-20 14:18:46,088 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-20 14:18:46,089 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48719
2019-11-20 14:18:46,091 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-20 14:18:46,091 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change null -> WORKER_STARTED
2019-11-20 14:18:46,091 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-20 14:18:46,092 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-20 14:18:46,095 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-20 14:18:46,103 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-20 14:18:46,105 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48721
2019-11-20 14:18:46,105 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-20 14:18:46,105 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change null -> WORKER_STARTED
2019-11-20 14:18:46,106 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-20 14:18:46,108 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-20 14:18:46,108 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-20 14:18:46,109 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-20 14:18:46,130 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-20 14:18:46,130 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48720
2019-11-20 14:18:46,131 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-20 14:18:46,131 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-20 14:18:46,132 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change null -> WORKER_STARTED
2019-11-20 14:18:46,133 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-20 14:18:46,136 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-20 14:18:50,578 [WARN ] W-9000-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:18:50] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...
2019-11-20 14:18:50,579 [WARN ] W-9003-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:18:50] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...
2019-11-20 14:18:50,579 [WARN ] W-9001-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:18:50] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...
2019-11-20 14:18:50,580 [WARN ] W-9002-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:18:50] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...
2019-11-20 14:18:50,582 [WARN ] W-9003-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:18:50] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!
2019-11-20 14:18:50,582 [WARN ] W-9001-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:18:50] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!
2019-11-20 14:18:50,583 [WARN ] W-9000-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:18:50] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!
2019-11-20 14:18:50,583 [WARN ] W-9002-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:18:50] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!
2019-11-20 14:18:50,679 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend response time: 4530
2019-11-20 14:18:50,679 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend response time: 4530
2019-11-20 14:18:50,679 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend response time: 4530
2019-11-20 14:18:50,680 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_MODEL_LOADED
2019-11-20 14:18:50,680 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_MODEL_LOADED
2019-11-20 14:18:50,680 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_MODEL_LOADED
2019-11-20 14:18:50,683 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend response time: 4534
2019-11-20 14:18:50,683 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_MODEL_LOADED
2019-11-20 14:20:17,240 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: N/A
Initial Models: squeezenet=https://s3.amazonaws.com/model-server/model_archive_1.0/squeezenet_v1.1.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-11-20 14:20:17,247 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: https://s3.amazonaws.com/model-server/model_archive_1.0/squeezenet_v1.1.mar
2019-11-20 14:20:18,957 [INFO ] main org.pytorch.serve.archive.ModelArchive - model folder already exists: 674bbff228fdc041fadbef6f515e86dd
2019-11-20 14:20:18,981 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-11-20 14:20:18,981 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-11-20 14:20:18,998 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-11-20 14:20:19,193 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-11-20 14:20:19,195 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-11-20 14:20:19,198 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-11-20 14:20:19,213 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-11-20 14:20:19,343 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-20 14:20:19,343 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48738
2019-11-20 14:20:19,344 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-20 14:20:19,344 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change null -> WORKER_STARTED
2019-11-20 14:20:19,344 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-20 14:20:19,351 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-20 14:20:19,366 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-20 14:20:19,373 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-20 14:20:19,373 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48735
2019-11-20 14:20:19,374 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-20 14:20:19,374 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change null -> WORKER_STARTED
2019-11-20 14:20:19,374 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-20 14:20:19,374 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-20 14:20:19,376 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-20 14:20:20,305 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-20 14:20:20,307 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48737
2019-11-20 14:20:20,307 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-20 14:20:20,307 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change null -> WORKER_STARTED
2019-11-20 14:20:20,307 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-20 14:20:20,323 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-20 14:20:20,323 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-20 14:20:20,343 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-20 14:20:20,349 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48736
2019-11-20 14:20:20,350 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-20 14:20:20,350 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change null -> WORKER_STARTED
2019-11-20 14:20:20,350 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-20 14:20:20,350 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-20 14:20:20,365 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-20 14:20:21,981 [WARN ] W-9002-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:20:21] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...
2019-11-20 14:20:21,982 [WARN ] W-9002-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:20:21] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!
2019-11-20 14:20:22,015 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend response time: 2604
2019-11-20 14:20:22,016 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_MODEL_LOADED
2019-11-20 14:20:22,024 [WARN ] W-9003-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:20:22] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...
2019-11-20 14:20:22,026 [WARN ] W-9003-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:20:22] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!
2019-11-20 14:20:22,057 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend response time: 2645
2019-11-20 14:20:22,057 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_MODEL_LOADED
2019-11-20 14:20:22,664 [WARN ] W-9000-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:20:22] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...
2019-11-20 14:20:22,665 [WARN ] W-9000-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:20:22] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!
2019-11-20 14:20:22,688 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend response time: 2334
2019-11-20 14:20:22,688 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_MODEL_LOADED
2019-11-20 14:20:22,693 [WARN ] W-9001-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:20:22] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...
2019-11-20 14:20:22,694 [WARN ] W-9001-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:20:22] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!
2019-11-20 14:20:22,712 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend response time: 2402
2019-11-20 14:20:22,712 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_MODEL_LOADED
2019-11-20 14:21:51,047 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend response time: 134
2019-11-20 14:21:51,051 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.Job - Waiting time: 0, Backend time: 139
2019-11-29 14:45:16,029 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: N/A
Initial Models: squeezenet=https://s3.amazonaws.com/model-server/model_archive_1.0/squeezenet_v1.1.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-11-29 14:45:16,039 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: https://s3.amazonaws.com/model-server/model_archive_1.0/squeezenet_v1.1.mar
2019-11-29 14:45:20,335 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-11-29 14:45:20,335 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-11-29 14:45:20,364 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-11-29 14:45:20,785 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-11-29 14:45:20,786 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-11-29 14:45:20,788 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-11-29 14:45:20,805 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-11-29 14:45:21,001 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 14:45:21,001 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1070
2019-11-29 14:45:21,002 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 14:45:21,002 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 14:45:21,003 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change null -> WORKER_STARTED
2019-11-29 14:45:21,003 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 14:45:21,003 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1072
2019-11-29 14:45:21,003 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 14:45:21,003 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change null -> WORKER_STARTED
2019-11-29 14:45:21,004 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 14:45:21,012 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 14:45:21,012 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 14:45:21,033 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 14:45:21,034 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 14:45:21,072 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 14:45:21,072 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1069
2019-11-29 14:45:21,072 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 14:45:21,072 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change null -> WORKER_STARTED
2019-11-29 14:45:21,073 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 14:45:21,075 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 14:45:21,076 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 14:45:21,076 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 14:45:21,077 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1071
2019-11-29 14:45:21,077 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 14:45:21,077 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change null -> WORKER_STARTED
2019-11-29 14:45:21,077 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 14:45:21,078 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 14:45:21,081 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 14:45:25,615 [WARN ] W-9002-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:45:25] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...
2019-11-29 14:45:25,615 [WARN ] W-9003-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:45:25] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...
2019-11-29 14:45:25,616 [WARN ] W-9001-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:45:25] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...
2019-11-29 14:45:25,618 [WARN ] W-9000-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:45:25] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...
2019-11-29 14:45:25,618 [WARN ] W-9001-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:45:25] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!
2019-11-29 14:45:25,620 [WARN ] W-9000-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:45:25] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!
2019-11-29 14:45:25,622 [WARN ] W-9003-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:45:25] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!
2019-11-29 14:45:25,623 [WARN ] W-9002-squeezenet-stderr org.pytorch.serve.wlm.WorkerLifeCycle - [14:45:25] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!
2019-11-29 14:45:25,759 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend response time: 4669
2019-11-29 14:45:25,759 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_MODEL_LOADED
2019-11-29 14:45:25,779 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend response time: 4685
2019-11-29 14:45:25,780 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_MODEL_LOADED
2019-11-29 14:45:25,780 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend response time: 4690
2019-11-29 14:45:25,780 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_MODEL_LOADED
2019-11-29 14:45:25,781 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend response time: 4692
2019-11-29 14:45:25,781 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_MODEL_LOADED
2019-11-29 14:48:31,458 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: N/A
Initial Models: squeezenet=https://s3.amazonaws.com/model-server/model_archive_1.0/squeezenet_v1.1.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-11-29 14:48:31,475 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: https://s3.amazonaws.com/model-server/model_archive_1.0/squeezenet_v1.1.mar
2019-11-29 14:49:06,718 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend response time: 114
2019-11-29 14:49:06,719 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.Job - Waiting time: 0, Backend time: 117
2019-11-29 15:43:27,665 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store
Initial Models: squeezenet=squeezenet_v1.1.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-11-29 15:43:27,712 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: squeezenet_v1.1.mar
2019-11-29 15:44:03,947 [WARN ] main org.pytorch.serve.ModelServer - Failed to load model: squeezenet_v1.1.mar
org.pytorch.serve.archive.InvalidModelException: Model handler is not defined.
	at org.pytorch.serve.archive.ModelArchive.validate(ModelArchive.java:300)
	at org.pytorch.serve.wlm.ModelManager.registerModel(ModelManager.java:100)
	at org.pytorch.serve.ModelServer.initModelStore(ModelServer.java:184)
	at org.pytorch.serve.ModelServer.start(ModelServer.java:273)
	at org.pytorch.serve.ModelServer.startAndWait(ModelServer.java:88)
	at org.pytorch.serve.ModelServer.main(ModelServer.java:71)
2019-11-29 15:44:03,979 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-11-29 15:44:04,381 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-11-29 15:44:04,381 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-11-29 15:44:04,384 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-11-29 15:45:18,496 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store
Initial Models: squeezenet=squeezenet_v1.1.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-11-29 15:45:18,515 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: squeezenet_v1.1.mar
2019-11-29 15:45:18,785 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-11-29 15:45:18,785 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-11-29 15:45:18,807 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-11-29 15:45:18,812 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:18,813 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:18,816 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change null -> WORKER_STOPPED
2019-11-29 15:45:18,813 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:18,813 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:18,819 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change null -> WORKER_STOPPED
2019-11-29 15:45:18,819 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change null -> WORKER_STOPPED
2019-11-29 15:45:18,816 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change null -> WORKER_STOPPED
2019-11-29 15:45:18,820 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-11-29 15:45:18,821 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-11-29 15:45:18,821 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-11-29 15:45:18,822 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-11-29 15:45:18,925 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-11-29 15:45:18,925 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-11-29 15:45:18,926 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-11-29 15:45:18,949 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-11-29 15:45:19,828 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:19,829 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:19,829 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:19,829 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:19,829 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:19,830 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:19,830 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-11-29 15:45:19,829 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:19,829 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-11-29 15:45:19,830 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:19,829 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-11-29 15:45:19,831 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-11-29 15:45:20,832 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:20,832 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:20,832 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:20,832 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:20,834 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:20,833 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:20,833 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:20,835 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:20,835 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2019-11-29 15:45:20,835 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2019-11-29 15:45:20,835 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2019-11-29 15:45:20,835 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2019-11-29 15:45:22,839 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:22,839 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:22,839 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:22,839 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:22,841 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:22,840 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:22,840 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:22,839 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:22,841 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2019-11-29 15:45:22,841 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2019-11-29 15:45:22,841 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2019-11-29 15:45:22,841 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2019-11-29 15:45:25,848 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:25,848 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:25,848 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:25,848 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
java.lang.NullPointerException
	at org.pytorch.serve.wlm.WorkerLifeCycle.getEnvString(WorkerLifeCycle.java:46)
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:102)
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:212)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:120)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:45:25,849 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:25,849 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:25,849 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:25,850 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2019-11-29 15:45:25,849 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STOPPED
2019-11-29 15:45:25,850 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2019-11-29 15:45:25,850 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2019-11-29 15:45:25,850 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2019-11-29 15:51:21,926 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store
Initial Models: squeezenet=squeezenet_v1.1.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-11-29 15:51:21,934 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: squeezenet_v1.1.mar
2019-11-29 15:51:22,234 [INFO ] main org.pytorch.serve.archive.ModelArchive - model folder already exists: e63f36427280deadbd76f956ac5253309b7658d3
2019-11-29 15:51:22,239 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-11-29 15:51:22,239 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-11-29 15:51:22,264 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-11-29 15:51:22,606 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:51:22,606 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:51:22,606 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3199
2019-11-29 15:51:22,606 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3200
2019-11-29 15:51:22,606 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:22,607 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:22,607 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:22,607 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:22,608 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change null -> WORKER_STARTED
2019-11-29 15:51:22,608 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change null -> WORKER_STARTED
2019-11-29 15:51:22,619 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:51:22,619 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:51:22,626 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:51:22,627 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3198
2019-11-29 15:51:22,627 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:22,627 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change null -> WORKER_STARTED
2019-11-29 15:51:22,628 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:51:22,628 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:22,637 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:51:22,637 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3201
2019-11-29 15:51:22,638 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:22,638 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:22,638 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change null -> WORKER_STARTED
2019-11-29 15:51:22,638 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:51:22,687 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 15:51:22,688 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 15:51:22,688 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 15:51:22,689 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 15:51:22,692 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-11-29 15:51:22,692 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-11-29 15:51:22,693 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-11-29 15:51:22,743 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:22,747 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:22,744 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:22,744 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:22,743 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:22,747 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:22,755 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:22,756 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:22,758 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:22,760 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-11-29 15:51:22,761 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:22,762 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:22,763 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:22,764 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-11-29 15:51:22,764 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-11-29 15:51:22,764 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-11-29 15:51:22,771 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:22,772 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:22,773 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:22,777 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:22,912 [ERROR] Thread-1 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---
Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 340, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 343, in wrapper
    return fun(self)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 388, in _get_kinfo_proc
    ret = cext.proc_kinfo_oneshot(self.pid)
ProcessLookupError: [Errno 3] No such process

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 474, in _init
    self.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 824, in create_time
    self._create_time = self._proc.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 491, in create_time
    return self._get_kinfo_proc()[kinfo_proc_map['ctime']]
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 340, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=3201)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 447, in __init__
    self._init(pid)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 487, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 3201

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('3201',)
--- Logging error ---
Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('3201', 0)
--- Logging error ---
Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 340, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 343, in wrapper
    return fun(self)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 388, in _get_kinfo_proc
    ret = cext.proc_kinfo_oneshot(self.pid)
ProcessLookupError: [Errno 3] No such process

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 474, in _init
    self.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 824, in create_time
    self._create_time = self._proc.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 491, in create_time
    return self._get_kinfo_proc()[kinfo_proc_map['ctime']]
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 340, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=3198)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 447, in __init__
    self._init(pid)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 487, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 3198

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('3198',)
--- Logging error ---
Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('3198', 0)
--- Logging error ---
Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 340, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 343, in wrapper
    return fun(self)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 388, in _get_kinfo_proc
    ret = cext.proc_kinfo_oneshot(self.pid)
ProcessLookupError: [Errno 3] No such process

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 474, in _init
    self.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 824, in create_time
    self._create_time = self._proc.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 491, in create_time
    return self._get_kinfo_proc()[kinfo_proc_map['ctime']]
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 340, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=3199)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 447, in __init__
    self._init(pid)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 487, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 3199

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('3199',)
--- Logging error ---
Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('3199', 0)
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>
BrokenPipeError: [Errno 32] Broken pipe

2019-11-29 15:51:23,944 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:51:23,946 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3204
2019-11-29 15:51:23,946 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:23,946 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:23,946 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:23,946 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:51:23,948 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:23,949 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:23,949 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:23,950 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-11-29 15:51:23,958 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:51:23,958 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3206
2019-11-29 15:51:23,958 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:23,958 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:23,958 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:23,958 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:51:23,960 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:23,961 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:23,961 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:23,962 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:23,962 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-11-29 15:51:23,964 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:51:23,964 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3203
2019-11-29 15:51:23,966 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:23,968 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:23,969 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:23,969 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:51:23,970 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:23,971 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:23,971 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:23,972 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-11-29 15:51:23,976 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:51:23,977 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3205
2019-11-29 15:51:23,977 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:23,977 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:23,977 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:23,977 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:51:23,979 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 15:51:23,979 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:23,980 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:23,980 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:23,980 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-11-29 15:51:23,982 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:23,983 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:25,151 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:51:25,151 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3207
2019-11-29 15:51:25,152 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:25,152 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:25,152 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:51:25,152 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:25,153 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:25,154 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:25,154 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:25,155 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2019-11-29 15:51:25,159 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:25,183 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:51:25,183 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3208
2019-11-29 15:51:25,184 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:25,184 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:25,184 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:25,184 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:51:25,186 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:25,187 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:25,187 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:25,188 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2019-11-29 15:51:25,191 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:25,197 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:51:25,197 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3209
2019-11-29 15:51:25,197 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:25,197 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:25,197 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:51:25,199 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:25,199 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:25,200 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:25,201 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2019-11-29 15:51:25,204 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:25,229 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:51:25,229 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3210
2019-11-29 15:51:25,229 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:25,229 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:25,229 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:51:25,230 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:25,230 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:25,231 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:25,231 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 15:51:25,231 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:25,232 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2019-11-29 15:51:25,239 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:27,367 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:51:27,368 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3211
2019-11-29 15:51:27,368 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:27,368 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:27,368 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:27,368 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:51:27,370 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:27,371 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:27,371 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:27,372 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2019-11-29 15:51:27,375 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:27,408 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:51:27,408 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3212
2019-11-29 15:51:27,408 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:27,408 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:27,408 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:27,408 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:51:27,409 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 15:51:27,409 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:27,410 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:27,410 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:27,411 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2019-11-29 15:51:27,413 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:27,436 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:51:27,436 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3213
2019-11-29 15:51:27,437 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:27,437 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:27,437 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:51:27,437 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:27,438 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 15:51:27,438 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:27,439 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:27,439 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:27,440 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2019-11-29 15:51:27,441 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:27,464 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:51:27,464 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3215
2019-11-29 15:51:27,464 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:27,464 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:27,464 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:27,464 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:51:27,465 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 15:51:27,465 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:27,466 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:27,466 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:27,467 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2019-11-29 15:51:27,469 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:30,592 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:51:30,594 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3216
2019-11-29 15:51:30,595 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:30,595 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:30,595 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:51:30,600 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:30,601 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:30,601 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:30,601 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2019-11-29 15:51:30,605 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:30,629 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:51:30,629 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3217
2019-11-29 15:51:30,630 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:30,630 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:30,630 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:51:30,631 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:30,632 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 15:51:30,632 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:30,632 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:30,632 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:30,633 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2019-11-29 15:51:30,636 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:30,691 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:51:30,691 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3219
2019-11-29 15:51:30,691 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:30,691 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:30,691 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:30,691 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:51:30,693 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:30,693 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:30,694 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:30,694 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2019-11-29 15:51:30,697 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:30,699 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:51:30,700 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3218
2019-11-29 15:51:30,700 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:30,700 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:30,700 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:51:30,701 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:30,703 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:30,704 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:30,704 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:30,703 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 15:51:30,704 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2019-11-29 15:51:30,707 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:35,724 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:51:35,724 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3220
2019-11-29 15:51:35,724 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:35,724 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:35,725 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:35,725 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:51:35,728 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 15:51:35,731 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:35,736 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:35,736 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:35,740 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2019-11-29 15:51:35,743 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:35,767 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:51:35,767 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3221
2019-11-29 15:51:35,768 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:35,768 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:35,768 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:35,768 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:51:35,770 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:35,770 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 15:51:35,770 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:35,770 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:35,773 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2019-11-29 15:51:35,774 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:35,947 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:51:35,948 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3222
2019-11-29 15:51:35,949 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:35,949 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:35,949 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:51:35,950 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:35,952 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:35,952 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 15:51:35,953 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:35,953 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:35,953 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2019-11-29 15:51:35,956 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:35,983 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:51:35,984 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3223
2019-11-29 15:51:35,984 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:35,984 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:35,984 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:35,984 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:51:35,985 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 15:51:35,985 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:35,986 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:35,986 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:35,986 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2019-11-29 15:51:35,990 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:43,901 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:51:43,902 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3225
2019-11-29 15:51:43,902 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:43,902 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:43,902 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:43,902 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:51:43,904 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 15:51:43,906 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:43,907 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:43,907 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:43,907 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2019-11-29 15:51:43,909 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:43,915 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:51:43,915 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3226
2019-11-29 15:51:43,915 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:43,915 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:43,915 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:43,915 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:51:43,916 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 15:51:43,916 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:43,917 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:43,917 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:43,918 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2019-11-29 15:51:43,919 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:44,151 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:51:44,152 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3227
2019-11-29 15:51:44,152 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:44,152 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:44,152 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:51:44,153 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:44,154 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 15:51:44,155 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:44,155 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:44,155 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:44,156 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2019-11-29 15:51:44,158 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STOPPED
2019-11-29 15:51:44,176 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:51:44,176 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3228
2019-11-29 15:51:44,176 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:51:44,176 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:51:44,176 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:51:44,176 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:51:44,177 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 15:51:44,177 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker thread exception.
io.netty.handler.codec.EncoderException: java.lang.NullPointerException
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:125)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.kqueue.KQueueEventLoop.run(KQueueEventLoop.java:273)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:38)
	at org.pytorch.serve.util.codec.ModelRequestEncoder.encode(ModelRequestEncoder.java:1)
	at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107)
	... 12 more
2019-11-29 15:51:44,178 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:51:44,178 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:51:44,178 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2019-11-29 15:51:44,180 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STOPPED
2019-11-29 15:54:15,526 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store
Initial Models: squeezenet=squeezenet_v1.1.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-11-29 15:54:15,539 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: squeezenet_v1.1.mar
2019-11-29 15:54:15,848 [INFO ] main org.pytorch.serve.archive.ModelArchive - model folder already exists: e63f36427280deadbd76f956ac5253309b7658d3
2019-11-29 15:54:15,853 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-11-29 15:54:15,853 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-11-29 15:54:15,880 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-11-29 15:54:16,307 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-11-29 15:54:16,308 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-11-29 15:54:16,310 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-11-29 15:54:16,320 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:54:16,320 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4158
2019-11-29 15:54:16,322 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:54:16,322 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:54:16,323 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change null -> WORKER_STARTED
2019-11-29 15:54:16,330 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:54:16,331 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-11-29 15:54:16,347 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:54:16,347 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4159
2019-11-29 15:54:16,347 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:54:16,348 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change null -> WORKER_STARTED
2019-11-29 15:54:16,348 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:54:16,349 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:54:16,362 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:54:16,364 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4157
2019-11-29 15:54:16,364 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:54:16,364 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change null -> WORKER_STARTED
2019-11-29 15:54:16,364 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:54:16,364 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:54:16,380 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 15:54:16,382 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 15:54:16,383 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 15:54:16,390 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:54:16,391 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4160
2019-11-29 15:54:16,391 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:54:16,391 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change null -> WORKER_STARTED
2019-11-29 15:54:16,391 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:54:16,395 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:54:16,395 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 15:54:16,401 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 15:54:16,402 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 15:54:16,402 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 15:54:16,402 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 15:54:16,402 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 15:54:16,403 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 15:54:16,403 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 15:54:16,403 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 15:54:16,403 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 15:54:16,403 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 15:54:16,404 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 15:54:16,404 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 15:54:16,404 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 15:54:16,404 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 15:54:16,404 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 15:54:16,404 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 15:54:16,405 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 15:54:16,405 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 15:54:16,407 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 15:54:16,407 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:54:16,410 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:54:16,410 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:54:16,413 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-11-29 15:54:16,427 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 15:54:16,427 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 15:54:16,427 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 15:54:16,427 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 15:54:16,427 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 15:54:16,427 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 15:54:16,428 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:54:16,428 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 15:54:16,428 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 15:54:16,428 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:54:16,428 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 15:54:16,428 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 15:54:16,428 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:54:16,428 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 15:54:16,428 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 15:54:16,429 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 15:54:16,429 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 15:54:16,429 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 15:54:16,429 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 15:54:16,429 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 15:54:16,429 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-11-29 15:54:16,430 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 15:54:16,430 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 15:54:16,431 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 15:54:16,431 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 15:54:16,432 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 15:54:16,432 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 15:54:16,432 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 15:54:16,432 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 15:54:16,432 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 15:54:16,432 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 15:54:16,432 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 15:54:16,432 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 15:54:16,432 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 15:54:16,432 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 15:54:16,432 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 15:54:16,432 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 15:54:16,432 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 15:54:16,433 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 15:54:16,433 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 15:54:16,433 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 15:54:16,435 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 15:54:16,435 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:54:16,436 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:54:16,436 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:54:16,436 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-11-29 15:54:16,439 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 15:54:16,439 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 15:54:16,440 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 15:54:16,440 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 15:54:16,440 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 15:54:16,440 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 15:54:16,440 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 15:54:16,440 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:54:16,440 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 15:54:16,440 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:54:16,440 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 15:54:16,440 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:54:16,441 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 15:54:16,441 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 15:54:16,441 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-11-29 15:54:16,441 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 15:54:16,441 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 15:54:16,441 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 15:54:16,441 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 15:54:16,441 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 15:54:16,441 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 15:54:16,442 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 15:54:16,442 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 15:54:17,619 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:54:17,620 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4171
2019-11-29 15:54:17,620 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:54:17,621 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:54:17,621 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:54:17,621 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:54:17,626 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 15:54:17,629 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 15:54:17,629 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 15:54:17,629 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 15:54:17,629 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 15:54:17,629 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:54:17,629 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 15:54:17,630 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:54:17,630 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 15:54:17,630 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:54:17,630 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 15:54:17,630 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 15:54:17,630 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 15:54:17,630 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 15:54:17,630 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-11-29 15:54:17,630 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 15:54:17,630 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 15:54:17,631 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 15:54:17,631 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 15:54:17,631 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 15:54:17,631 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 15:54:17,631 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 15:54:17,631 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 15:54:17,631 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 15:54:17,637 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:54:17,638 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4172
2019-11-29 15:54:17,638 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:54:17,638 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:54:17,638 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:54:17,638 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:54:17,639 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 15:54:17,642 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 15:54:17,642 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 15:54:17,642 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 15:54:17,642 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 15:54:17,642 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 15:54:17,642 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:54:17,642 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 15:54:17,643 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:54:17,643 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 15:54:17,643 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:54:17,643 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 15:54:17,643 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 15:54:17,643 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 15:54:17,643 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 15:54:17,643 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 15:54:17,644 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 15:54:17,644 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 15:54:17,644 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 15:54:17,644 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 15:54:17,644 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 15:54:17,644 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 15:54:17,644 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 15:54:17,647 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-11-29 15:54:17,657 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:54:17,658 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4173
2019-11-29 15:54:17,658 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:54:17,658 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:54:17,658 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:54:17,658 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:54:17,659 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 15:54:17,659 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:54:17,660 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4174
2019-11-29 15:54:17,660 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:54:17,660 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:54:17,660 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:54:17,661 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:54:17,662 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 15:54:17,663 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 15:54:17,664 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 15:54:17,664 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 15:54:17,664 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 15:54:17,664 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:54:17,664 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:54:17,664 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 15:54:17,664 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:54:17,664 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 15:54:17,664 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 15:54:17,665 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 15:54:17,665 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 15:54:17,665 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-11-29 15:54:17,665 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 15:54:17,665 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 15:54:17,665 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 15:54:17,665 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 15:54:17,665 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 15:54:17,665 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 15:54:17,665 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 15:54:17,665 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 15:54:17,665 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 15:54:17,666 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 15:54:17,667 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 15:54:17,667 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 15:54:17,668 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 15:54:17,668 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 15:54:17,668 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 15:54:17,668 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 15:54:17,668 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 15:54:17,668 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 15:54:17,668 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 15:54:17,668 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:54:17,668 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 15:54:17,669 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:54:17,669 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 15:54:17,669 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:54:17,669 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 15:54:17,669 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 15:54:17,669 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 15:54:17,669 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 15:54:17,669 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 15:54:17,669 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 15:54:17,669 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 15:54:17,669 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 15:54:17,669 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-11-29 15:54:18,777 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:54:18,782 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4183
2019-11-29 15:54:18,782 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:54:18,782 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:54:18,782 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:54:18,782 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 15:54:18,786 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 15:54:18,788 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 15:54:18,788 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 15:54:18,788 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 15:54:18,788 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 15:54:18,788 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 15:54:18,788 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 15:54:18,788 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 15:54:18,788 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 15:54:18,788 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 15:54:18,788 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 15:54:18,788 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 15:54:18,788 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:54:18,789 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 15:54:18,789 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:54:18,789 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:54:18,789 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 15:54:18,789 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 15:54:18,789 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 15:54:18,789 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 15:54:18,789 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 15:54:18,789 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 15:54:18,789 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2019-11-29 15:54:18,789 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 15:54:18,819 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:54:18,819 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4184
2019-11-29 15:54:18,820 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:54:18,820 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:54:18,820 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 15:54:18,820 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:54:18,821 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 15:54:18,823 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 15:54:18,823 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 15:54:18,824 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 15:54:18,824 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 15:54:18,824 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 15:54:18,824 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 15:54:18,824 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 15:54:18,824 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 15:54:18,824 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 15:54:18,824 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 15:54:18,824 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 15:54:18,824 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 15:54:18,824 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 15:54:18,824 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:54:18,824 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 15:54:18,824 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:54:18,824 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 15:54:18,824 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:54:18,824 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 15:54:18,825 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 15:54:18,825 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 15:54:18,825 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 15:54:18,825 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2019-11-29 15:54:18,888 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:54:18,888 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4185
2019-11-29 15:54:18,888 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:54:18,888 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:54:18,889 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 15:54:18,899 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:54:18,899 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 15:54:18,902 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 15:54:18,902 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 15:54:18,902 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 15:54:18,902 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 15:54:18,902 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 15:54:18,902 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 15:54:18,902 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 15:54:18,902 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 15:54:18,902 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 15:54:18,902 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 15:54:18,903 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 15:54:18,903 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 15:54:18,903 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 15:54:18,903 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 15:54:18,903 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 15:54:18,903 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 15:54:18,903 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 15:54:18,903 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 15:54:18,904 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 15:54:18,905 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:54:18,905 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:54:18,905 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:54:18,907 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2019-11-29 15:54:18,917 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:54:18,918 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4186
2019-11-29 15:54:18,919 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 15:54:18,919 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 15:54:18,919 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 15:54:18,921 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 15:54:18,921 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 15:54:18,925 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 15:54:18,925 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 15:54:18,925 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 15:54:18,925 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 15:54:18,925 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 15:54:18,925 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 15:54:18,925 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 15:54:18,925 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 15:54:18,925 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 15:54:18,925 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 15:54:18,925 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 15:54:18,926 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 15:54:18,926 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 15:54:18,926 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 15:54:18,926 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 15:54:18,926 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 15:54:18,926 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 15:54:18,926 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 15:54:18,926 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 15:54:18,927 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 15:54:18,927 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 15:54:18,927 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 15:54:18,928 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2019-11-29 16:10:14,901 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store
Initial Models: squeezenet=squeezenet_v1.1.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-11-29 16:10:14,911 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: squeezenet_v1.1.mar
2019-11-29 16:10:15,233 [INFO ] main org.pytorch.serve.archive.ModelArchive - model folder already exists: e63f36427280deadbd76f956ac5253309b7658d3
2019-11-29 16:10:15,238 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-11-29 16:10:15,238 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-11-29 16:10:15,265 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-11-29 16:10:15,576 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:10:15,577 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4286
2019-11-29 16:10:15,578 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:15,578 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:15,579 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change null -> WORKER_STARTED
2019-11-29 16:10:15,588 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:10:15,619 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:10:15,619 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4285
2019-11-29 16:10:15,619 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:15,619 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change null -> WORKER_STARTED
2019-11-29 16:10:15,619 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:10:15,620 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:15,647 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:10:15,648 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4284
2019-11-29 16:10:15,649 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:15,649 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change null -> WORKER_STARTED
2019-11-29 16:10:15,649 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:15,649 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:10:15,693 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:10:15,693 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4283
2019-11-29 16:10:15,694 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:15,694 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change null -> WORKER_STARTED
2019-11-29 16:10:15,694 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:15,694 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:10:15,748 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-11-29 16:10:15,749 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-11-29 16:10:15,755 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:10:15,762 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-11-29 16:10:15,762 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:10:15,777 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:10:15,778 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:10:15,822 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:15,822 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:15,822 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:15,822 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:15,822 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:15,822 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:15,822 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:15,822 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:15,822 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:15,823 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:15,823 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:15,823 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:15,823 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:15,823 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:15,823 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:15,823 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:15,823 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:15,823 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:15,823 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:15,823 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:15,823 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:15,824 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:15,824 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:15,824 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:15,824 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:15,824 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:15,824 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:15,824 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:15,824 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:15,824 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:15,824 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:15,824 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:15,824 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:15,824 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:15,825 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:15,825 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:15,830 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:15,830 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:15,830 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:15,830 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:15,830 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:15,831 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:15,831 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:15,831 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:15,833 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:15,831 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:15,834 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:15,834 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:15,834 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:15,834 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:15,834 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:15,835 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:15,835 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:15,835 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:15,835 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:15,835 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:15,836 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:15,836 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:15,836 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:15,836 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-11-29 16:10:15,837 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:15,838 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:15,838 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:15,839 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-11-29 16:10:15,842 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:15,843 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:15,843 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:15,843 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:15,844 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-11-29 16:10:15,846 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:15,846 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:15,847 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:15,847 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:15,847 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:15,847 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:15,847 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:15,847 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:15,847 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:15,848 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:15,848 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:15,848 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:15,848 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:15,848 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:15,849 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:15,849 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:15,849 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:15,849 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:15,852 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:15,852 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:15,853 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:15,853 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:15,853 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-11-29 16:10:16,000 [ERROR] Thread-1 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---
Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 340, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 343, in wrapper
    return fun(self)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 388, in _get_kinfo_proc
    ret = cext.proc_kinfo_oneshot(self.pid)
ProcessLookupError: [Errno 3] No such process

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 474, in _init
    self.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 824, in create_time
    self._create_time = self._proc.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 491, in create_time
    return self._get_kinfo_proc()[kinfo_proc_map['ctime']]
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 340, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=4284)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 447, in __init__
    self._init(pid)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 487, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 4284

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('4284',)
--- Logging error ---
Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('4284', 0)
--- Logging error ---
Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 340, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 343, in wrapper
    return fun(self)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 388, in _get_kinfo_proc
    ret = cext.proc_kinfo_oneshot(self.pid)
ProcessLookupError: [Errno 3] No such process

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 474, in _init
    self.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 824, in create_time
    self._create_time = self._proc.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 491, in create_time
    return self._get_kinfo_proc()[kinfo_proc_map['ctime']]
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 340, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=4285)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 447, in __init__
    self._init(pid)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 487, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 4285

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('4285',)
--- Logging error ---
Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('4285', 0)
--- Logging error ---
Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 340, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 343, in wrapper
    return fun(self)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 388, in _get_kinfo_proc
    ret = cext.proc_kinfo_oneshot(self.pid)
ProcessLookupError: [Errno 3] No such process

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 474, in _init
    self.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 824, in create_time
    self._create_time = self._proc.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 491, in create_time
    return self._get_kinfo_proc()[kinfo_proc_map['ctime']]
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 340, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=4286)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 447, in __init__
    self._init(pid)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 487, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 4286

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('4286',)
--- Logging error ---
Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('4286', 0)
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>
BrokenPipeError: [Errno 32] Broken pipe

2019-11-29 16:10:17,055 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:10:17,056 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4290
2019-11-29 16:10:17,056 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:17,057 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:17,057 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:10:17,057 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:17,060 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:10:17,066 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:17,066 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:17,066 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:17,066 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:17,066 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:17,066 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:17,067 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:17,067 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:17,067 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:17,067 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:17,067 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:17,067 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:17,067 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:17,068 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:17,068 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-11-29 16:10:17,068 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:17,068 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:17,068 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:17,068 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:17,068 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:17,068 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:17,069 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:17,069 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:17,076 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:10:17,077 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4289
2019-11-29 16:10:17,077 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:17,077 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:17,077 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:17,077 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:10:17,080 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:10:17,087 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:10:17,092 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:17,093 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:17,093 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:17,093 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:17,093 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:17,093 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:17,098 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:17,098 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:17,098 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:17,098 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:17,098 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:17,098 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:17,099 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:17,099 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:17,099 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:17,099 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:17,099 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:17,099 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:17,102 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:17,102 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:17,103 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:17,103 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:17,103 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-11-29 16:10:17,123 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4288
2019-11-29 16:10:17,123 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:17,123 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:17,124 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:10:17,124 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:17,125 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:10:17,128 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:17,129 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:17,129 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:17,130 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:17,130 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:17,130 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:17,131 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:17,131 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:17,131 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:17,131 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:17,131 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:17,131 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:17,131 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:17,132 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:17,132 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:17,132 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:17,132 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:17,132 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:17,132 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:17,132 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:17,132 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:17,132 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:17,132 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-11-29 16:10:17,137 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:10:17,137 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4291
2019-11-29 16:10:17,137 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:17,137 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:17,137 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:17,137 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:10:17,139 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:10:17,141 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:17,141 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:17,141 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:17,141 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:17,141 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:17,141 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:17,141 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:17,141 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:17,141 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:17,141 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:17,141 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:17,141 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:17,141 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:17,142 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:17,142 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:17,142 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:17,142 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:17,142 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-11-29 16:10:17,142 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:17,142 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:17,142 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:17,142 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:17,142 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:18,226 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:10:18,227 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4292
2019-11-29 16:10:18,227 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:18,227 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:18,228 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:18,228 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:10:18,243 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:10:18,248 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:18,248 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:18,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:18,252 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:18,255 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:18,255 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:18,255 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:18,261 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2019-11-29 16:10:18,298 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:10:18,298 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4293
2019-11-29 16:10:18,298 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:18,298 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:18,298 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:18,298 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:10:18,299 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:10:18,302 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:18,303 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:18,303 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:18,303 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:18,303 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:18,303 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:18,303 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:18,303 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:18,303 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:18,303 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:18,303 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:18,303 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:18,303 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:18,303 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:18,303 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:18,304 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:18,304 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:18,304 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:18,304 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:18,304 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:18,304 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:18,304 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2019-11-29 16:10:18,304 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:18,328 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:10:18,328 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4294
2019-11-29 16:10:18,328 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:18,328 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:18,328 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:10:18,328 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:18,330 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:10:18,331 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:18,331 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:18,331 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:18,331 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:18,331 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:18,332 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:18,332 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:18,332 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:18,332 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:18,332 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:18,332 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:18,332 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:18,332 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:18,332 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:18,333 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:18,333 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:18,332 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:18,333 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:18,333 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:18,333 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:18,333 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:18,333 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:18,334 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2019-11-29 16:10:18,351 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:10:18,351 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4295
2019-11-29 16:10:18,352 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:18,352 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:18,352 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:10:18,352 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:18,353 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:10:18,354 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:18,354 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:18,354 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:18,355 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:18,355 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:18,355 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:18,355 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:18,355 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:18,355 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:18,355 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:18,355 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:18,355 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:18,355 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:18,355 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:18,355 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:18,355 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2019-11-29 16:10:18,355 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:18,355 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:18,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:18,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:18,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:18,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:18,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:53,989 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store
Initial Models: squeezenet=squeezenet_v1.1.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-11-29 16:10:54,000 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: squeezenet_v1.1.mar
2019-11-29 16:10:54,290 [INFO ] main org.pytorch.serve.archive.ModelArchive - model folder already exists: e63f36427280deadbd76f956ac5253309b7658d3
2019-11-29 16:10:54,294 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-11-29 16:10:54,295 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-11-29 16:10:54,317 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-11-29 16:10:54,620 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-11-29 16:10:54,621 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-11-29 16:10:54,623 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-11-29 16:10:54,637 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-11-29 16:10:54,751 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:10:54,752 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4302
2019-11-29 16:10:54,752 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:54,753 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:54,754 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change null -> WORKER_STARTED
2019-11-29 16:10:54,762 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:10:54,766 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:10:54,767 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4301
2019-11-29 16:10:54,767 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:54,767 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change null -> WORKER_STARTED
2019-11-29 16:10:54,768 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:10:54,769 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:54,771 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:10:54,772 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4300
2019-11-29 16:10:54,773 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:54,774 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change null -> WORKER_STARTED
2019-11-29 16:10:54,774 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:10:54,783 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:10:54,784 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:10:54,810 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:54,810 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:10:54,823 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:54,823 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:54,823 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:54,824 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:54,824 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:54,824 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:54,824 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:54,824 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:54,825 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:54,825 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:54,825 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:54,825 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:54,826 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:54,826 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:54,826 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:54,826 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:54,826 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:54,827 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:54,827 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:54,828 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:54,830 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:54,831 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:54,833 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-11-29 16:10:54,842 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:54,842 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:54,842 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:54,842 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:54,842 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:54,842 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:54,843 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:54,843 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:54,843 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:54,843 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:54,843 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:54,843 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:54,844 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:54,844 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:54,844 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:54,844 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:54,844 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:54,844 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:54,845 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:54,845 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:54,845 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:54,845 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:54,845 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:54,846 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:54,846 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:54,846 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:54,846 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:54,846 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:54,846 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:54,846 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:54,847 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:54,847 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:54,848 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-11-29 16:10:54,847 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:54,848 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:54,848 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:54,848 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:54,848 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-11-29 16:10:54,848 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:54,848 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:54,849 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:54,849 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:54,849 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:54,849 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:54,849 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:54,849 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:54,879 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:10:54,880 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4303
2019-11-29 16:10:54,880 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:54,880 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change null -> WORKER_STARTED
2019-11-29 16:10:54,880 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:54,880 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:10:54,882 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:10:54,886 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:54,886 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:54,886 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:54,886 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:54,886 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:54,886 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:54,886 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:54,886 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:54,887 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:54,887 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:54,887 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:54,887 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:54,887 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:54,887 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:54,887 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-11-29 16:10:54,888 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:54,888 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:54,888 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:54,888 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:54,888 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:54,888 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:54,889 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:54,889 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:56,026 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:10:56,026 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4307
2019-11-29 16:10:56,027 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:56,027 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:56,027 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:56,027 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:10:56,028 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:10:56,032 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:56,032 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:56,032 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:56,032 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:56,032 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:56,032 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:56,032 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:56,032 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:56,032 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:56,032 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:56,033 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:56,033 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:56,033 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:56,033 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:56,033 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:56,033 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:56,033 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:56,033 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:56,033 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:56,033 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:56,034 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:56,034 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:56,037 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-11-29 16:10:56,042 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:10:56,042 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4305
2019-11-29 16:10:56,043 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:56,043 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:56,043 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:10:56,045 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:56,046 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:10:56,049 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:56,049 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:56,049 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:56,049 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:56,049 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:56,049 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:56,049 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:56,049 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:56,049 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:56,049 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:56,049 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:56,050 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:56,050 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:56,050 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:56,050 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:56,052 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-11-29 16:10:56,054 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:56,054 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:56,054 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:56,054 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:56,054 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:56,054 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:56,054 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:56,077 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:10:56,077 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4306
2019-11-29 16:10:56,077 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:56,077 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:56,077 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:56,077 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:10:56,078 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:10:56,080 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:56,080 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:56,081 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:56,081 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:56,081 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:56,081 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:56,081 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:56,081 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:56,081 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:56,081 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:56,081 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:56,081 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:56,081 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:56,082 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:56,082 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-11-29 16:10:56,082 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:56,082 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:56,082 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:56,082 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:56,082 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:56,082 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:56,082 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:56,082 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:56,106 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:10:56,106 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4308
2019-11-29 16:10:56,106 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:56,106 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:56,106 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:56,106 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:10:56,108 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:10:56,110 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:56,110 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:56,110 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:56,110 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:56,111 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:56,111 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:56,111 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:56,111 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:56,111 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:56,111 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:56,111 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:56,111 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:56,111 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:56,111 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:56,111 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:56,111 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:56,111 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:56,111 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-11-29 16:10:56,111 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:56,111 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:56,112 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:56,112 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:56,112 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:57,226 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:10:57,227 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4309
2019-11-29 16:10:57,227 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:57,228 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:57,229 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:57,229 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:10:57,231 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:10:57,234 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:57,234 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:57,234 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:57,234 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:57,234 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:57,234 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:57,235 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:57,235 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:57,235 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:57,235 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:57,235 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:57,235 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:57,235 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:57,235 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:57,235 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2019-11-29 16:10:57,235 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:57,236 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:57,236 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:57,236 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:57,236 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:57,236 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:57,236 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:57,236 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:57,241 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:10:57,242 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4310
2019-11-29 16:10:57,242 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:57,242 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:57,242 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:57,242 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:10:57,244 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:10:57,247 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:57,247 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:57,247 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:57,247 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:57,247 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:57,247 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:57,247 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:57,247 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:57,247 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:57,247 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:57,247 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:57,247 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:57,248 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:57,248 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:57,248 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:57,248 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:57,248 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:57,248 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:57,248 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:57,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:57,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:57,249 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:57,249 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2019-11-29 16:10:57,275 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:10:57,275 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4311
2019-11-29 16:10:57,276 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:57,276 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:57,276 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:57,276 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:10:57,277 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:10:57,279 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:57,279 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:57,279 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:57,279 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:57,279 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:57,279 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:57,280 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:57,280 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:57,280 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:57,280 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:57,280 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:57,280 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:57,280 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2019-11-29 16:10:57,280 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:57,280 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:57,280 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:57,280 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:57,280 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:57,281 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:57,281 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:57,281 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:57,281 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:57,281 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:57,309 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:10:57,310 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4312
2019-11-29 16:10:57,310 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:57,310 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:57,310 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:57,310 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:10:57,311 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:10:57,313 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:57,313 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:57,313 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:57,313 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:57,313 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:57,313 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:57,313 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:57,313 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:57,313 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:57,313 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:57,313 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:57,313 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:57,313 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:57,313 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:57,313 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:57,313 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:57,313 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2019-11-29 16:10:57,313 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:57,314 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:57,314 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:57,314 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:57,314 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:57,314 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:59,401 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:10:59,401 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4313
2019-11-29 16:10:59,402 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:59,402 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:59,402 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:59,402 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:10:59,403 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:10:59,406 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:59,406 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:59,406 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:59,406 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:59,406 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:59,406 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:59,406 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:59,406 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:59,406 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:59,406 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:59,406 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:59,406 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:59,407 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:59,407 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:59,407 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:59,407 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:59,407 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:59,407 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:59,407 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:59,407 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:59,408 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:59,408 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:59,408 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2019-11-29 16:10:59,417 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:10:59,417 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4314
2019-11-29 16:10:59,417 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:59,417 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:59,417 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:59,418 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:10:59,420 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:10:59,422 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:59,422 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:59,422 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:59,422 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:59,422 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:59,422 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:59,422 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:59,422 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:59,422 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:59,422 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:59,423 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:59,423 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:59,423 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:59,423 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:59,423 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:59,423 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:59,423 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:59,423 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:59,425 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:59,425 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:59,426 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:59,426 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:59,426 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2019-11-29 16:10:59,458 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:10:59,459 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4315
2019-11-29 16:10:59,459 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:59,460 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:59,460 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:59,460 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:10:59,461 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:10:59,464 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:59,464 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:59,464 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:59,464 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:59,464 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:59,464 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:59,464 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:59,464 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:59,464 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:59,464 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:59,464 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:59,464 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:59,464 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:59,464 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:59,464 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:59,465 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:59,465 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:59,465 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2019-11-29 16:10:59,465 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:59,465 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:59,465 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:59,465 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:59,465 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:59,492 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:10:59,492 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4316
2019-11-29 16:10:59,493 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:10:59,493 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:10:59,493 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:10:59,493 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:10:59,498 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:10:59,501 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:10:59,501 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:10:59,501 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:10:59,501 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:10:59,501 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:10:59,501 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:10:59,501 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:10:59,501 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:10:59,501 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:10:59,501 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:10:59,501 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:10:59,501 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:10:59,501 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:10:59,502 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:10:59,502 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:10:59,502 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:10:59,502 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:10:59,502 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:10:59,503 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:10:59,504 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:10:59,504 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:10:59,505 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:10:59,507 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2019-11-29 16:11:02,553 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:11:02,553 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4317
2019-11-29 16:11:02,553 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:02,553 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:02,554 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:02,554 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:11:02,562 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:11:02,568 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:02,568 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:02,568 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:02,568 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:02,568 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:02,568 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:02,568 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:02,568 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:02,569 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:02,569 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:02,569 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:02,569 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:02,569 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:02,569 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:02,569 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:02,569 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:02,569 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:02,569 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:02,577 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:02,579 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:02,580 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:02,580 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:02,588 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2019-11-29 16:11:02,589 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:11:02,589 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4318
2019-11-29 16:11:02,589 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:02,589 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:02,590 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:02,590 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:11:02,595 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:11:02,598 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:02,598 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:02,598 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:02,598 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:02,598 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:02,598 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:02,598 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:02,598 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:02,598 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:02,598 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:02,598 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:02,599 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:02,599 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:02,599 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:02,599 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:02,599 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:02,599 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:02,599 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:02,605 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:02,609 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:02,609 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:02,609 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:02,630 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2019-11-29 16:11:02,667 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:11:02,668 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4319
2019-11-29 16:11:02,668 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:02,668 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:02,669 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:11:02,669 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:02,670 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:11:02,674 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:02,674 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:02,674 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:02,674 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:02,674 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:02,674 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:02,674 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:02,676 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:02,676 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:02,676 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:02,676 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:02,676 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:02,676 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:02,677 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:02,677 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:02,677 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:02,677 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:02,677 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:02,679 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:02,679 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:02,680 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:02,680 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:02,684 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2019-11-29 16:11:02,775 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:11:02,776 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4320
2019-11-29 16:11:02,776 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:02,776 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:02,776 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:11:02,776 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:02,778 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:11:02,780 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:02,780 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:02,781 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:02,781 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:02,781 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:02,782 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:02,782 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:02,782 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2019-11-29 16:11:07,730 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:11:07,731 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4321
2019-11-29 16:11:07,731 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:07,731 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:07,731 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:07,731 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:11:07,732 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:11:07,739 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:07,740 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:07,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:07,741 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:07,742 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:07,742 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:07,742 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:07,744 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2019-11-29 16:11:07,772 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:11:07,773 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4322
2019-11-29 16:11:07,773 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:07,773 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:07,773 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:07,773 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:11:07,774 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:07,776 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:07,777 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:07,777 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:07,777 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:07,777 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:07,777 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:07,777 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2019-11-29 16:11:07,829 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:11:07,829 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4323
2019-11-29 16:11:07,829 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:07,829 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:07,829 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:07,829 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:11:07,830 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:11:07,832 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:07,832 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:07,833 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:07,833 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:07,833 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:07,833 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:07,833 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:07,833 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:07,833 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:07,833 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:07,833 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:07,833 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:07,833 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:07,834 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:07,834 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:07,834 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:07,834 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:07,834 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:07,834 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:07,834 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:07,834 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:07,834 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:07,836 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2019-11-29 16:11:07,940 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:11:07,940 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4324
2019-11-29 16:11:07,940 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:07,940 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:07,940 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:07,940 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:11:07,941 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:11:07,942 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:07,943 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:07,943 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:07,943 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:07,943 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:07,943 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:07,943 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:07,943 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:07,944 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:07,944 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:07,944 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:07,945 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:07,945 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:07,945 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:07,945 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:07,945 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:07,945 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:07,947 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:07,947 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:07,947 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:07,948 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:07,948 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:07,948 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2019-11-29 16:11:15,874 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:11:15,875 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4325
2019-11-29 16:11:15,875 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:15,875 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:15,875 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:15,875 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:11:15,877 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:15,880 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:15,881 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:15,882 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:15,882 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:15,882 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:15,883 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2019-11-29 16:11:15,904 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:11:15,904 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4326
2019-11-29 16:11:15,904 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:15,904 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:15,904 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:15,904 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:11:15,905 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:11:15,907 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:15,907 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:15,907 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:15,907 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:15,907 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:15,907 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:15,908 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:15,908 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:15,908 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:15,908 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:15,908 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:15,908 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:15,908 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:15,908 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:15,908 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:15,908 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:15,908 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:15,908 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:15,908 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:15,908 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:15,908 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:15,908 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:15,909 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2019-11-29 16:11:15,969 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:11:15,969 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4327
2019-11-29 16:11:15,969 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:15,969 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:15,969 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:15,969 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:11:15,970 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:11:15,973 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:15,973 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:15,973 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:15,973 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:15,973 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:15,973 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:15,973 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:15,973 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:15,973 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:15,973 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:15,973 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:15,974 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:15,974 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:15,974 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:15,974 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:15,974 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:15,974 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:15,974 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:15,974 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:15,974 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:15,974 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:15,974 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:15,975 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2019-11-29 16:11:16,084 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:11:16,084 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4328
2019-11-29 16:11:16,084 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:16,084 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:16,084 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:16,084 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:11:16,085 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:11:16,090 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:16,091 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:16,091 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:16,091 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:16,091 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:16,091 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:16,091 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:16,091 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:16,091 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:16,091 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:16,092 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:16,092 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:16,092 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:16,092 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:16,092 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:16,092 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:16,092 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:16,092 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:16,093 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:16,093 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:16,093 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:16,092 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:16,093 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2019-11-29 16:11:29,092 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:11:29,092 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4333
2019-11-29 16:11:29,092 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:29,092 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:29,093 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:29,093 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:11:29,102 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:11:29,120 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:29,121 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:29,121 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:29,121 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:29,121 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:29,121 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:29,121 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:29,121 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:29,121 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:29,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:29,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:29,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:29,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:29,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:29,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:29,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:29,123 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:29,123 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:29,150 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:29,150 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:11:29,150 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4334
2019-11-29 16:11:29,150 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:29,150 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:29,151 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:29,153 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:29,153 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:29,152 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:29,153 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:11:29,156 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2019-11-29 16:11:29,159 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:29,173 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:29,174 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:29,174 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:29,175 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:29,176 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:29,184 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2019-11-29 16:11:29,409 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:11:29,409 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4335
2019-11-29 16:11:29,410 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:29,410 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:29,410 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:11:29,410 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:29,411 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:11:29,413 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:29,413 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:29,413 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:29,413 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:29,413 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:29,413 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:29,413 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:29,413 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:29,413 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:29,413 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:29,413 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:29,414 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:29,414 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:29,414 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:29,414 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:29,414 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:29,414 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:29,414 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:29,414 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:29,415 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:29,416 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:29,417 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:29,418 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2019-11-29 16:11:29,461 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:11:29,461 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4336
2019-11-29 16:11:29,461 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:29,461 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:29,461 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:11:29,461 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:29,463 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:11:29,466 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:29,466 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:29,466 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:29,466 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:29,466 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:29,466 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:29,466 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:29,467 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:29,467 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:29,467 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:29,467 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:29,467 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:29,467 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:29,467 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:29,467 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:29,467 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:29,467 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:29,467 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:29,467 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:29,468 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:29,468 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:29,468 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:29,469 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2019-11-29 16:11:50,314 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:11:50,314 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4341
2019-11-29 16:11:50,314 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:50,314 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:50,314 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:50,314 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:11:50,315 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:11:50,315 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4342
2019-11-29 16:11:50,315 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:50,315 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:50,315 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:11:50,315 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:50,316 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:11:50,316 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:11:50,319 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:50,319 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:50,319 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:50,319 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:50,319 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:50,319 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:50,319 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:50,319 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:50,320 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:50,320 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:50,320 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:50,320 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:50,320 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:50,320 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:50,320 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:50,320 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:50,320 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:50,320 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:50,320 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:50,320 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:50,320 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:50,320 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:50,320 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:50,321 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:50,320 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:50,321 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:50,321 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:50,321 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:50,321 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:50,321 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:50,321 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:50,321 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:50,321 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:50,322 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:50,322 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:50,322 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:50,322 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:50,322 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2019-11-29 16:11:50,321 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:50,323 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:50,323 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:50,323 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:50,323 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:50,323 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:50,323 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:50,322 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2019-11-29 16:11:50,550 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:11:50,550 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4343
2019-11-29 16:11:50,550 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:50,550 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:50,550 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:50,551 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:11:50,551 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:11:50,554 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:50,554 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:50,554 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:50,554 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:50,554 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:50,554 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:50,554 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:50,554 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:50,554 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:50,554 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:50,554 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:50,554 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:50,555 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:50,555 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:50,555 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:50,555 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:50,555 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:50,555 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:50,555 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:50,555 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:50,555 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:50,555 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:50,555 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2019-11-29 16:11:50,584 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:11:50,585 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4344
2019-11-29 16:11:50,585 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:11:50,585 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:11:50,585 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:11:50,585 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:11:50,586 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:11:50,587 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:11:50,587 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:11:50,587 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:11:50,588 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:11:50,588 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:11:50,588 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:11:50,588 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:11:50,588 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:11:50,588 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:11:50,588 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:11:50,588 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:11:50,588 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:11:50,588 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:11:50,588 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:11:50,588 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:11:50,588 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:11:50,589 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:11:50,589 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:11:50,589 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:11:50,589 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:11:50,589 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:11:50,589 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:11:50,589 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2019-11-29 16:11:54,774 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---
Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 340, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 343, in wrapper
    return fun(self)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 388, in _get_kinfo_proc
    ret = cext.proc_kinfo_oneshot(self.pid)
ProcessLookupError: [Errno 3] No such process

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 474, in _init
    self.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 824, in create_time
    self._create_time = self._proc.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 491, in create_time
    return self._get_kinfo_proc()[kinfo_proc_map['ctime']]
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 340, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=4342)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 447, in __init__
    self._init(pid)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 487, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 4342

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('4342',)
--- Logging error ---
Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('4342', 0)
--- Logging error ---
Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 340, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 343, in wrapper
    return fun(self)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 388, in _get_kinfo_proc
    ret = cext.proc_kinfo_oneshot(self.pid)
ProcessLookupError: [Errno 3] No such process

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 474, in _init
    self.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 824, in create_time
    self._create_time = self._proc.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 491, in create_time
    return self._get_kinfo_proc()[kinfo_proc_map['ctime']]
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 340, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=4343)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 447, in __init__
    self._init(pid)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 487, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 4343

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('4343',)
--- Logging error ---
Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('4343', 0)
--- Logging error ---
Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 340, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_common.py", line 343, in wrapper
    return fun(self)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 388, in _get_kinfo_proc
    ret = cext.proc_kinfo_oneshot(self.pid)
ProcessLookupError: [Errno 3] No such process

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 474, in _init
    self.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 824, in create_time
    self._create_time = self._proc.create_time()
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 338, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 491, in create_time
    return self._get_kinfo_proc()[kinfo_proc_map['ctime']]
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/_psosx.py", line 340, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=4344)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 447, in __init__
    self._init(pid)
  File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/site-packages/psutil/__init__.py", line 487, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 4344

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('4344',)
--- Logging error ---
Traceback (most recent call last):
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1038, in emit
    self.flush()
  File "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/logging/__init__.py", line 1018, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('4344', 0)
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>
BrokenPipeError: [Errno 32] Broken pipe

2019-11-29 16:12:24,455 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:12:24,455 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:12:24,456 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4350
2019-11-29 16:12:24,456 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4349
2019-11-29 16:12:24,456 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:12:24,456 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:12:24,456 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:12:24,456 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:12:24,456 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:12:24,456 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:12:24,457 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:12:24,457 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:12:24,458 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:12:24,458 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:12:24,460 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:12:24,460 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:12:24,460 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:12:24,460 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:12:24,461 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:12:24,461 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:12:24,461 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:12:24,461 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:12:24,461 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:12:24,461 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:12:24,461 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:12:24,461 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:12:24,461 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:12:24,461 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:12:24,461 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:12:24,461 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:12:24,462 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:12:24,462 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:12:24,462 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:12:24,462 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:12:24,462 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:12:24,461 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:12:24,462 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:12:24,462 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:12:24,462 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:12:24,462 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:12:24,462 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:12:24,462 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:12:24,462 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:12:24,462 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:12:24,462 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:12:24,462 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:12:24,462 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:12:24,462 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:12:24,463 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:12:24,463 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:12:24,463 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:12:24,463 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:12:24,464 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:12:24,464 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:12:24,464 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.
2019-11-29 16:12:24,465 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:12:24,466 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:12:24,466 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:12:24,466 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:12:24,467 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.
2019-11-29 16:12:24,817 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:12:24,817 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4351
2019-11-29 16:12:24,817 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:12:24,817 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:12:24,817 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:12:24,818 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:12:24,818 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:12:24,821 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:12:24,821 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:12:24,821 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:12:24,821 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:12:24,821 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:12:24,821 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:12:24,821 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:12:24,821 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:12:24,821 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:12:24,821 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:12:24,822 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:12:24,822 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:12:24,822 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:12:24,822 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:12:24,822 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:12:24,822 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:12:24,822 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:12:24,822 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:12:24,822 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:12:24,822 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:12:24,822 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:12:24,822 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:12:24,823 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2019-11-29 16:12:24,834 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:12:24,834 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4352
2019-11-29 16:12:24,834 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:12:24,835 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:12:24,835 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:12:24,835 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:12:24,835 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:12:24,838 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:12:24,838 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:12:24,838 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:12:24,838 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:12:24,838 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:12:24,838 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:12:24,838 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:12:24,838 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:12:24,839 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:12:24,839 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:12:24,839 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:12:24,839 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:12:24,839 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:12:24,839 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:12:24,839 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:12:24,839 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:12:24,839 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:12:24,839 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:12:24,839 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:12:24,839 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:12:24,839 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:12:24,839 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:12:24,840 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.
2019-11-29 16:13:19,664 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:13:19,664 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:13:19,665 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4440
2019-11-29 16:13:19,665 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4441
2019-11-29 16:13:19,665 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:13:19,665 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:13:19,665 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:13:19,665 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:13:19,665 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:13:19,665 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:13:19,665 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:13:19,665 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:13:19,666 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:13:19,666 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:13:19,669 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:13:19,670 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:13:19,670 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:13:19,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:13:19,672 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:13:19,672 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:13:19,673 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:13:19,673 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:13:19,673 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:13:19,674 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:13:19,674 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:13:19,674 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:13:19,676 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 89 seconds.
2019-11-29 16:13:19,676 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 89 seconds.
2019-11-29 16:13:19,992 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:13:19,992 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4444
2019-11-29 16:13:19,992 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:13:19,992 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:13:19,992 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:13:19,993 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:13:19,993 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:13:19,995 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:13:19,996 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:13:19,996 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:13:19,996 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:13:19,996 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:13:19,996 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:13:19,996 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:13:19,996 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:13:19,996 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:13:19,996 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:13:19,996 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:13:19,996 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:13:19,997 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:13:19,997 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:13:19,997 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:13:19,997 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:13:19,997 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:13:19,997 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:13:19,997 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:13:19,997 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:13:19,998 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:13:19,998 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:13:19,999 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2019-11-29 16:13:20,008 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:13:20,008 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4446
2019-11-29 16:13:20,008 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:13:20,008 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:13:20,008 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:13:20,009 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:13:20,009 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:13:20,011 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:13:20,011 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:13:20,011 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:13:20,011 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:13:20,011 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:13:20,011 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:13:20,011 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:13:20,011 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:13:20,011 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:13:20,011 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:13:20,011 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:13:20,012 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:13:20,012 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:13:20,012 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:13:20,012 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:13:20,012 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:13:20,012 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:13:20,012 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:13:20,012 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:13:20,012 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:13:20,012 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:13:20,012 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:13:20,012 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 89 seconds.
2019-11-29 16:14:48,913 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:14:48,913 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:14:48,914 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4898
2019-11-29 16:14:48,914 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:14:48,914 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:14:48,914 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4899
2019-11-29 16:14:48,914 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:14:48,914 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:14:48,914 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:14:48,914 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:14:48,914 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:14:48,914 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:14:48,915 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:14:48,915 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:14:48,919 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:14:48,919 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:14:48,919 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:14:48,919 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:14:48,919 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:14:48,919 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:14:48,920 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:14:48,920 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:14:48,920 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:14:48,921 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:14:48,920 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:14:48,921 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:14:48,921 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:14:48,921 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:14:48,921 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:14:48,921 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:14:48,921 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:14:48,921 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:14:48,921 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:14:48,921 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:14:48,921 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 144 seconds.
2019-11-29 16:14:48,921 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:14:48,922 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:14:48,922 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:14:48,922 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:14:48,922 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:14:48,923 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:14:48,923 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:14:48,923 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:14:48,923 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:14:48,923 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:14:48,923 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:14:48,923 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:14:48,923 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:14:48,923 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:14:48,923 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:14:48,921 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:14:48,926 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:14:48,926 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:14:48,926 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:14:48,926 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:14:48,926 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:14:48,926 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:14:48,923 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:14:48,926 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:14:48,927 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 144 seconds.
2019-11-29 16:14:49,142 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:14:49,142 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4900
2019-11-29 16:14:49,142 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:14:49,142 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:14:49,142 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:14:49,142 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:14:49,143 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:14:49,145 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:14:49,145 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:14:49,145 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:14:49,146 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:14:49,146 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:14:49,146 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:14:49,146 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:14:49,146 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:14:49,146 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:14:49,147 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:14:49,146 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:14:49,147 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:14:49,147 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:14:49,147 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:14:49,147 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:14:49,147 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:14:49,147 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:14:49,147 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:14:49,147 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:14:49,147 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:14:49,147 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:14:49,147 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:14:49,149 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 144 seconds.
2019-11-29 16:14:49,151 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:14:49,152 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4901
2019-11-29 16:14:49,152 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:14:49,152 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:14:49,152 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:14:49,152 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:14:49,152 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:14:49,154 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:14:49,154 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:14:49,154 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:14:49,154 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:14:49,154 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:14:49,154 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:14:49,154 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:14:49,154 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:14:49,154 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:14:49,155 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:14:49,155 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:14:49,155 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:14:49,155 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:14:49,155 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:14:49,155 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:14:49,155 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:14:49,155 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:14:49,155 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:14:49,155 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:14:49,155 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 144 seconds.
2019-11-29 16:14:49,155 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:14:49,155 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:14:49,155 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:17:13,115 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:17:13,115 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:17:13,115 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4907
2019-11-29 16:17:13,115 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4906
2019-11-29 16:17:13,115 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:17:13,115 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:17:13,116 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:17:13,116 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:17:13,115 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:17:13,115 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:17:13,116 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:17:13,116 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:17:13,117 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:17:13,119 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:17:13,121 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:17:13,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:17:13,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:17:13,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:17:13,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:17:13,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:17:13,122 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:17:13,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:17:13,123 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:17:13,123 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:17:13,123 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:17:13,123 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:17:13,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:17:13,123 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:17:13,123 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:17:13,123 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:17:13,123 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:17:13,124 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:17:13,124 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:17:13,124 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:17:13,124 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:17:13,124 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:17:13,124 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:17:13,124 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 233 seconds.
2019-11-29 16:17:13,124 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:17:13,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:17:13,124 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:17:13,124 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:17:13,125 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:17:13,125 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:17:13,125 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:17:13,125 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:17:13,125 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:17:13,125 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:17:13,125 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:17:13,125 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:17:13,125 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:17:13,125 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:17:13,125 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:17:13,125 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:17:13,125 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:17:13,125 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:17:13,125 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:17:13,126 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:17:13,126 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:17:13,126 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 233 seconds.
2019-11-29 16:17:13,359 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:17:13,360 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4909
2019-11-29 16:17:13,360 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:17:13,360 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:17:13,360 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:17:13,360 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:17:13,361 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:17:13,364 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:17:13,365 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:17:13,365 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:17:13,365 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:17:13,365 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:17:13,365 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:17:13,365 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:17:13,365 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:17:13,366 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:17:13,366 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:17:13,366 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:17:13,366 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:17:13,366 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:17:13,366 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:17:13,366 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:17:13,366 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:17:13,366 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:17:13,366 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:17:13,370 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:17:13,371 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:17:13,371 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:17:13,371 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:17:13,374 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 233 seconds.
2019-11-29 16:17:13,378 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:17:13,378 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4908
2019-11-29 16:17:13,378 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:17:13,379 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:17:13,379 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:17:13,379 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:17:13,379 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:17:13,381 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:17:13,381 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:17:13,381 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:17:13,381 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:17:13,381 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:17:13,381 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:17:13,382 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:17:13,382 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:17:13,382 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:17:13,382 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:17:13,382 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:17:13,382 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:17:13,382 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:17:13,382 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:17:13,382 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:17:13,382 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:17:13,382 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:17:13,382 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:17:13,382 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:17:13,382 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:17:13,382 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:17:13,382 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:17:13,383 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 233 seconds.
2019-11-29 16:21:06,331 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:21:06,331 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:21:06,331 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4916
2019-11-29 16:21:06,331 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4917
2019-11-29 16:21:06,331 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:21:06,331 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:21:06,331 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:21:06,331 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:21:06,331 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:21:06,331 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:21:06,331 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:21:06,331 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:21:06,333 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:21:06,333 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:21:06,336 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:21:06,336 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:21:06,336 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:21:06,336 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:21:06,336 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:21:06,336 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:21:06,336 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:21:06,336 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:21:06,336 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:21:06,336 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:21:06,336 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:21:06,336 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:21:06,336 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:21:06,336 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:21:06,336 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:21:06,337 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:21:06,337 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:21:06,337 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:21:06,338 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:21:06,338 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:21:06,338 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:21:06,338 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:21:06,338 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:21:06,338 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:21:06,338 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:21:06,338 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:21:06,338 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:21:06,349 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:21:06,350 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:21:06,350 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:21:06,337 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:21:06,349 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:21:06,351 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:21:06,351 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:21:06,338 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:21:06,351 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:21:06,352 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:21:06,351 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:21:06,352 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:21:06,353 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:21:06,353 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:21:06,353 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:21:06,353 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:21:06,353 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:21:06,352 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 377 seconds.
2019-11-29 16:21:06,354 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 377 seconds.
2019-11-29 16:21:06,573 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:21:06,573 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4918
2019-11-29 16:21:06,574 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:21:06,574 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:21:06,574 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:21:06,574 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:21:06,575 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:21:06,576 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:21:06,577 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:21:06,577 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:21:06,577 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:21:06,577 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:21:06,577 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:21:06,577 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:21:06,577 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:21:06,577 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:21:06,577 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:21:06,577 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:21:06,577 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:21:06,577 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:21:06,577 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:21:06,577 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:21:06,577 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:21:06,578 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:21:06,578 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:21:06,578 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:21:06,578 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:21:06,578 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:21:06,578 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 377 seconds.
2019-11-29 16:21:06,578 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:21:06,580 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:21:06,581 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4919
2019-11-29 16:21:06,581 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:21:06,581 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:21:06,581 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:21:06,581 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:21:06,582 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:21:06,584 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:21:06,584 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:21:06,584 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:21:06,584 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:21:06,584 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:21:06,584 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:21:06,584 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:21:06,584 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:21:06,584 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:21:06,584 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:21:06,584 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:21:06,584 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:21:06,584 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:21:06,585 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:21:06,585 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:21:06,585 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:21:06,585 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:21:06,585 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:21:06,585 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:21:06,585 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:21:06,585 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 377 seconds.
2019-11-29 16:21:06,585 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:21:06,585 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:27:23,559 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:27:23,560 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:27:23,560 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4941
2019-11-29 16:27:23,560 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4942
2019-11-29 16:27:23,560 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:27:23,560 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:27:23,560 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:27:23,560 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:27:23,560 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:27:23,560 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:27:23,560 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:27:23,560 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:27:23,561 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:27:23,561 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:27:23,565 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:27:23,565 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:27:23,565 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:27:23,565 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:27:23,565 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:27:23,565 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:27:23,565 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:27:23,566 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:27:23,566 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:27:23,566 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:27:23,566 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:27:23,566 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:27:23,566 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:27:23,566 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:27:23,566 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:27:23,566 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:27:23,566 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:27:23,566 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:27:23,566 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:27:23,566 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:27:23,566 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:27:23,566 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:27:23,566 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:27:23,566 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:27:23,566 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:27:23,566 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:27:23,567 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:27:23,567 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:27:23,567 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:27:23,567 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:27:23,567 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:27:23,567 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:27:23,567 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 610 seconds.
2019-11-29 16:27:23,566 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:27:23,567 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:27:23,567 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:27:23,567 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:27:23,568 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 610 seconds.
2019-11-29 16:27:23,568 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:27:23,568 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:27:23,568 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:27:23,568 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:27:23,568 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:27:23,568 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:27:23,568 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:27:23,568 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:27:23,751 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:27:23,751 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4943
2019-11-29 16:27:23,751 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:27:23,751 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:27:23,752 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:27:23,752 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:27:23,752 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:27:23,754 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:27:23,754 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:27:23,754 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:27:23,754 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4944
2019-11-29 16:27:23,754 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:27:23,754 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:27:23,754 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:27:23,754 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:27:23,754 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:27:23,754 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:27:23,754 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:27:23,754 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:27:23,754 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:27:23,754 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:27:23,754 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:27:23,754 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:27:23,754 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:27:23,754 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:27:23,754 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:27:23,754 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:27:23,755 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:27:23,755 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:27:23,755 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:27:23,755 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:27:23,755 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:27:23,755 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:27:23,755 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:27:23,755 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:27:23,755 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 610 seconds.
2019-11-29 16:27:23,756 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:27:23,758 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:27:23,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:27:23,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:27:23,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:27:23,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:27:23,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:27:23,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:27:23,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:27:23,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:27:23,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:27:23,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:27:23,759 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:27:23,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:27:23,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:27:23,759 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:27:23,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:27:23,760 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:27:23,760 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:27:23,760 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:27:23,760 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:27:23,760 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:27:23,760 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:27:23,760 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 610 seconds.
2019-11-29 16:37:33,810 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:37:33,810 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:37:33,812 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5492
2019-11-29 16:37:33,812 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5491
2019-11-29 16:37:33,812 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:37:33,812 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:37:33,812 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:37:33,812 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:37:33,812 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:37:33,812 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:37:33,813 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:37:33,814 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:37:33,814 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:37:33,815 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:37:33,819 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:37:33,819 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:37:33,819 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:37:33,819 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:37:33,819 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:37:33,819 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:37:33,819 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:37:33,819 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:37:33,819 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:37:33,819 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:37:33,819 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:37:33,819 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:37:33,819 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:37:33,819 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:37:33,820 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:37:33,820 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:37:33,820 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:37:33,820 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:37:33,820 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:37:33,821 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:37:33,822 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:37:33,822 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:37:33,822 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:37:33,825 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 987 seconds.
2019-11-29 16:37:33,827 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:37:33,827 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:37:33,827 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:37:33,827 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:37:33,828 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 987 seconds.
2019-11-29 16:37:33,975 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:37:33,975 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5493
2019-11-29 16:37:33,975 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:37:33,975 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:37:33,975 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:37:33,975 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:37:33,976 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:37:33,979 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:37:33,979 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:37:33,980 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:37:33,980 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5494
2019-11-29 16:37:33,980 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:37:33,980 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:37:33,980 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:37:33,980 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:37:33,980 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:37:33,980 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:37:33,980 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:37:33,980 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:37:33,981 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 987 seconds.
2019-11-29 16:37:33,982 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:37:33,984 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:37:33,985 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:37:33,985 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:37:33,985 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:37:33,985 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:37:33,986 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:37:33,987 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 987 seconds.
2019-11-29 16:54:01,103 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:54:01,104 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:54:01,104 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]6061
2019-11-29 16:54:01,105 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:54:01,105 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:54:01,105 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:54:01,105 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]6060
2019-11-29 16:54:01,105 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:54:01,105 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:54:01,105 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-11-29 16:54:01,105 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:54:01,105 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-11-29 16:54:01,110 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-11-29 16:54:01,110 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-11-29 16:54:01,121 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:54:01,121 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:54:01,121 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:54:01,121 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:54:01,121 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:54:01,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:54:01,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:54:01,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:54:01,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:54:01,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:54:01,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:54:01,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:54:01,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:54:01,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:54:01,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:54:01,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:54:01,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:54:01,122 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:54:01,122 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:54:01,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:54:01,124 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-11-29 16:54:01,124 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:54:01,125 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:54:01,125 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:54:01,125 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-11-29 16:54:01,125 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:54:01,125 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:54:01,125 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:54:01,126 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1597 seconds.
2019-11-29 16:54:01,128 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1597 seconds.
2019-11-29 16:54:01,223 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:54:01,224 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]6062
2019-11-29 16:54:01,224 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:54:01,224 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:54:01,224 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-11-29 16:54:01,224 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:54:01,226 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:54:01,229 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:54:01,230 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:54:01,230 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:54:01,230 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-11-29 16:54:01,231 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:54:01,231 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:54:01,231 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:54:01,232 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1597 seconds.
2019-11-29 16:54:01,257 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:54:01,257 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]6063
2019-11-29 16:54:01,257 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-11-29 16:54:01,257 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-11-29 16:54:01,257 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-11-29 16:54:01,257 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-11-29 16:54:01,258 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-11-29 16:54:01,259 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-11-29 16:54:01,259 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-11-29 16:54:01,259 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-11-29 16:54:01,259 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-11-29 16:54:01,260 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-11-29 16:54:01,260 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-11-29 16:54:01,260 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-11-29 16:54:01,260 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-11-29 16:54:01,260 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-11-29 16:54:01,260 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-11-29 16:54:01,260 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-11-29 16:54:01,260 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-11-29 16:54:01,260 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-11-29 16:54:01,260 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-11-29 16:54:01,260 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-11-29 16:54:01,260 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-11-29 16:54:01,260 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-11-29 16:54:01,260 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-11-29 16:54:01,260 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-11-29 16:54:01,260 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-11-29 16:54:01,260 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-11-29 16:54:01,260 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-11-29 16:54:01,260 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1597 seconds.
2019-12-02 08:32:29,424 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store
Initial Models: squeezenet=squeezenet_v1.1.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-12-02 08:32:29,437 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: squeezenet_v1.1.mar
2019-12-02 08:32:29,764 [INFO ] main org.pytorch.serve.archive.ModelArchive - model folder already exists: e63f36427280deadbd76f956ac5253309b7658d3
2019-12-02 08:32:29,771 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-12-02 08:32:29,771 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-12-02 08:32:29,803 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-12-02 08:32:30,075 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:32:30,075 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:32:30,077 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62232
2019-12-02 08:32:30,077 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62231
2019-12-02 08:32:30,077 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:30,077 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:30,077 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:30,078 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:30,078 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:32:30,078 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:32:30,085 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:32:30,085 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:32:30,089 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-12-02 08:32:30,089 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-12-02 08:32:30,091 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-12-02 08:32:30,101 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-12-02 08:32:30,104 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:32:30,106 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:32:30,164 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:30,165 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:30,165 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:30,165 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:30,165 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:30,165 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:30,165 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:30,165 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:30,165 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:30,165 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:30,165 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:30,165 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:30,165 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:30,166 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:30,166 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:30,166 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:30,166 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:30,166 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:30,166 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:30,166 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:30,167 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:30,167 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:30,167 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:30,167 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:30,168 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:30,168 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:30,168 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:30,169 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:30,169 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:30,169 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:30,169 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:30,169 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:30,169 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:30,169 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:30,169 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:30,169 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:30,172 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:30,172 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:30,174 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:30,174 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:30,180 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:30,181 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:30,181 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:30,181 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:30,183 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-12-02 08:32:30,184 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-12-02 08:32:30,928 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:32:30,928 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:32:30,929 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62233
2019-12-02 08:32:30,929 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62234
2019-12-02 08:32:30,929 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:30,929 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:32:30,930 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:32:30,929 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:30,929 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:30,930 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:32:30,930 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:32:30,932 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:32:30,933 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:30,934 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:32:30,935 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:30,935 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:30,935 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:30,935 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:30,936 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:30,936 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:30,936 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:30,936 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:30,936 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:30,936 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:30,936 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:30,937 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:30,937 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:30,936 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:30,938 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:30,938 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:30,938 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:30,938 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:30,938 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:30,938 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:30,938 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:30,938 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:30,939 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:30,939 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-12-02 08:32:30,937 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:30,936 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:30,941 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:30,941 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:30,941 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:30,941 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:30,942 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:30,942 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:30,942 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:30,942 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:30,942 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:30,941 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:30,943 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:30,943 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:30,944 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-12-02 08:32:30,945 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:30,945 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:30,945 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:30,945 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:30,945 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:30,945 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:30,945 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:31,299 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:32:31,299 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:32:31,300 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62240
2019-12-02 08:32:31,300 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62241
2019-12-02 08:32:31,300 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:31,300 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:31,300 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:31,300 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:31,300 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:32:31,300 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:32:31,301 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:32:31,301 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:32:31,302 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:32:31,302 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:32:31,305 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:31,305 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:31,305 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:31,305 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:31,305 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:31,305 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:31,305 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:31,306 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:31,306 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:31,306 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:31,306 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:31,306 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:31,306 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:31,306 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:31,306 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:31,307 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:31,307 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:31,307 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:31,307 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:31,307 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:31,308 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:31,308 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:31,308 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:31,308 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:31,308 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:31,308 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:31,309 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:31,309 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:31,309 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:31,309 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:31,309 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:31,309 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:31,309 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:31,309 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:31,309 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:31,309 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:31,309 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:31,309 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:31,309 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:31,310 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:31,310 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:31,312 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:31,313 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:31,313 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:31,313 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-12-02 08:32:31,315 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-12-02 08:32:32,068 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:32:32,068 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62254
2019-12-02 08:32:32,068 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:32,068 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:32,069 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:32:32,069 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:32:32,069 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:32:32,070 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62253
2019-12-02 08:32:32,070 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:32:32,070 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:32,070 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:32:32,070 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:32:32,070 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:32,071 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:32:32,073 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:32,073 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:32,073 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:32,074 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:32,074 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:32,074 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:32,074 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:32,074 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:32,074 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:32,074 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:32,074 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:32,075 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:32,075 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:32,075 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:32,075 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:32,075 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:32,075 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:32,075 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:32,075 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:32,075 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:32,075 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:32,075 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:32,075 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:32,075 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:32,075 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:32,075 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:32,074 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:32,076 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:32,075 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:32,077 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:32,077 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:32,078 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:32,078 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:32,078 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:32,078 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:32,082 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:32,082 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:32,082 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:32,084 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:32,084 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:32,082 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:32,085 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:32,085 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:32,085 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-12-02 08:32:32,085 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:32,087 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-12-02 08:32:32,528 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:32:32,528 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62261
2019-12-02 08:32:32,528 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:32,529 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:32:32,529 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:32:32,529 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:32,530 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:32:32,534 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:32,534 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:32,534 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:32,534 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:32,534 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:32,534 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:32,534 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:32,535 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:32,535 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:32,535 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:32,535 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:32,535 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:32,535 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:32,535 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:32,535 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:32,535 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:32,535 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:32,536 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:32,536 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:32,536 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2019-12-02 08:32:32,536 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:32,536 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:32,536 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:32,537 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:32:32,537 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62262
2019-12-02 08:32:32,538 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:32,538 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:32:32,538 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:32:32,538 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:32,541 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:32:32,543 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:32,543 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:32,543 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:32,543 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:32,543 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:32,543 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:32,543 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:32,543 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:32,543 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:32,543 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:32,544 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:32,544 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:32,544 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:32,544 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:32,544 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:32,544 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:32,544 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:32,544 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:32,544 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:32,544 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:32,544 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:32,544 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:32,545 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2019-12-02 08:32:33,226 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:32:33,226 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:32:33,226 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62274
2019-12-02 08:32:33,227 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62273
2019-12-02 08:32:33,227 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:33,227 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:32:33,227 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:32:33,227 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:32:33,227 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:32:33,227 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:33,227 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:33,228 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:33,228 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:32:33,229 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:32:33,231 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:33,232 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:33,232 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:33,232 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:33,232 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:33,232 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:33,232 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:33,232 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:33,232 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:33,232 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:33,232 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:33,232 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:33,232 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:33,233 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:33,233 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:33,233 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:33,233 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:33,233 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:33,233 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:33,233 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:33,233 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:33,233 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:33,233 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:33,233 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:33,233 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:33,233 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:33,233 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:33,233 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:33,233 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:33,233 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:33,233 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:33,233 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:33,233 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:33,234 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:33,234 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:33,234 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:33,235 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:33,235 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:33,235 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:33,235 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:33,235 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:33,236 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:33,236 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:33,236 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:33,237 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2019-12-02 08:32:33,237 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2019-12-02 08:32:34,695 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:32:34,695 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62283
2019-12-02 08:32:34,696 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:34,696 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:32:34,696 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:34,696 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:32:34,697 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:32:34,700 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:34,700 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:34,700 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:34,700 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:34,700 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:34,700 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:34,700 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:34,700 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:34,700 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:34,700 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:34,700 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:34,700 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:34,701 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:34,701 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:34,701 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:34,701 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:34,701 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:34,701 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:34,701 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:34,701 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:34,701 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:34,701 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:34,701 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2019-12-02 08:32:34,703 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:32:34,703 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62282
2019-12-02 08:32:34,703 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:34,703 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:34,703 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:32:34,704 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:32:34,705 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:32:34,706 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:34,707 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:34,707 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:34,707 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:34,707 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:34,707 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:34,707 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:34,707 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:34,707 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:34,707 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:34,707 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:34,707 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:34,707 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:34,707 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:34,707 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:34,707 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:34,707 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:34,708 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:34,708 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:34,708 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2019-12-02 08:32:34,708 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:34,708 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:34,708 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:35,350 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:32:35,350 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:32:35,350 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62289
2019-12-02 08:32:35,350 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62290
2019-12-02 08:32:35,350 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:35,350 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:35,350 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:32:35,350 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:35,351 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:32:35,350 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:35,350 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:32:35,351 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:32:35,352 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:32:35,352 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:32:35,354 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:35,354 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:35,355 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:35,355 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:35,355 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:35,355 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:35,355 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:35,355 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:35,356 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:35,356 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:35,356 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:35,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:35,356 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:35,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:35,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:35,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:35,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:35,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:35,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:35,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:35,357 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:35,357 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:35,357 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:35,357 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:35,357 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:35,357 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:35,357 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:35,356 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:35,357 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:35,357 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:35,357 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2019-12-02 08:32:35,356 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:35,358 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:35,358 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:35,358 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:35,358 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:35,358 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:35,358 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:35,358 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:35,359 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:35,359 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:35,359 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:35,359 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:35,359 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:35,359 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:35,359 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2019-12-02 08:32:37,865 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:32:37,865 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:32:37,865 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62311
2019-12-02 08:32:37,865 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62310
2019-12-02 08:32:37,866 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:37,866 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:37,866 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:32:37,865 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:32:37,866 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:32:37,866 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:32:37,866 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:32:37,866 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:32:37,872 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:32:37,873 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:32:37,875 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:37,875 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:37,875 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:37,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:37,875 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:37,875 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:32:37,879 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:32:37,879 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:32:37,877 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:37,881 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:37,881 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:37,877 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:32:37,880 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:32:37,881 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:32:37,881 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:32:37,881 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:32:37,881 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:32:37,881 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 109, in load
2019-12-02 08:32:37,881 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:32:37,881 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:32:37,881 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:32:37,881 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:32:37,881 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:32:37,881 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:32:37,881 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:32:37,882 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:32:37,882 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:32:37,882 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:32:37,883 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2019-12-02 08:32:37,884 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2019-12-02 08:33:45,187 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store
Initial Models: squeezenet=squeezenet_v1.1.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-12-02 08:33:45,196 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: squeezenet_v1.1.mar
2019-12-02 08:33:45,534 [INFO ] main org.pytorch.serve.archive.ModelArchive - model folder already exists: e63f36427280deadbd76f956ac5253309b7658d3
2019-12-02 08:33:45,543 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-12-02 08:33:45,543 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-12-02 08:33:45,584 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-12-02 08:33:45,828 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-12-02 08:33:45,829 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-12-02 08:33:45,830 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-12-02 08:33:45,841 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-12-02 08:33:45,877 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:33:45,877 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62765
2019-12-02 08:33:45,878 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:33:45,878 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:33:45,879 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:33:45,879 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:33:45,879 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62767
2019-12-02 08:33:45,880 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:33:45,880 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:33:45,882 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:33:45,887 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:33:45,887 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:33:45,907 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:33:45,908 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:33:45,957 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/e63f36427280deadbd76f956ac5253309b7658d3
2019-12-02 08:33:45,958 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:33:45,958 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:33:45,958 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:33:45,958 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:33:45,959 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:33:45,959 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:33:45,959 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:33:45,959 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:33:45,960 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:33:45,960 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:33:45,960 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 110, in load
2019-12-02 08:33:45,961 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:33:45,961 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:33:45,961 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:33:45,961 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:33:45,961 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:33:45,962 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:33:45,962 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:33:45,962 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:33:45,970 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:33:45,974 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:33:45,977 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:33:45,982 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-12-02 08:33:45,991 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/e63f36427280deadbd76f956ac5253309b7658d3
2019-12-02 08:33:45,992 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:33:45,992 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:33:45,992 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:33:45,992 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:33:45,992 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:33:45,992 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:33:45,993 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:33:45,993 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:33:45,993 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:33:45,994 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:33:45,994 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:33:45,994 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:33:45,994 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:33:45,995 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:33:45,995 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 110, in load
2019-12-02 08:33:45,995 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:33:45,995 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-12-02 08:33:45,995 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:33:45,996 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:33:45,996 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:33:45,996 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:33:45,997 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:33:45,997 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:33:46,751 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:33:46,751 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:33:46,752 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62768
2019-12-02 08:33:46,752 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62766
2019-12-02 08:33:46,752 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:33:46,752 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:33:46,752 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:33:46,752 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:33:46,752 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:33:46,752 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:33:46,753 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:33:46,752 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:33:46,754 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:33:46,754 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:33:46,757 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/e63f36427280deadbd76f956ac5253309b7658d3
2019-12-02 08:33:46,757 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:33:46,757 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 08:33:46,757 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:33:46,757 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:33:46,757 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:33:46,757 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:33:46,758 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:33:46,758 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:33:46,757 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/e63f36427280deadbd76f956ac5253309b7658d3
2019-12-02 08:33:46,758 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:33:46,758 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:33:46,758 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:33:46,758 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:33:46,758 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:33:46,758 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:33:46,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:33:46,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 110, in load
2019-12-02 08:33:46,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:33:46,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:33:46,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:33:46,759 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:33:46,760 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:33:46,760 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:33:46,760 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:33:46,758 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:33:46,760 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:33:46,760 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:33:46,760 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:33:46,761 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:33:46,761 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:33:46,761 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:33:46,761 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 110, in load
2019-12-02 08:33:46,761 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:33:46,761 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:33:46,761 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:33:46,762 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:33:46,762 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:33:46,765 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:33:46,765 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:33:46,758 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:33:46,765 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:33:46,765 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:33:46,758 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:33:46,766 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:33:46,766 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:33:46,767 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-12-02 08:33:46,769 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-12-02 08:33:47,150 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:33:47,151 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62770
2019-12-02 08:33:47,151 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:33:47,151 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:33:47,151 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:33:47,151 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:33:47,152 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:33:47,157 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/e63f36427280deadbd76f956ac5253309b7658d3
2019-12-02 08:33:47,157 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:33:47,157 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:33:47,157 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:33:47,158 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:33:47,158 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:33:47,158 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:33:47,158 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:33:47,158 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:33:47,158 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:33:47,158 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:33:47,158 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 110, in load
2019-12-02 08:33:47,158 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:33:47,158 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:33:47,159 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:33:47,159 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:33:47,160 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:33:47,160 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:33:47,161 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:33:47,165 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:33:47,165 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:33:47,165 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:33:47,165 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:33:47,166 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-12-02 08:33:47,175 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:33:47,175 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62771
2019-12-02 08:33:47,176 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:33:47,176 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:33:47,176 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:33:47,176 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:33:47,177 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:33:47,181 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/e63f36427280deadbd76f956ac5253309b7658d3
2019-12-02 08:33:47,182 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:33:47,182 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:33:47,182 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:33:47,182 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:33:47,182 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:33:47,182 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:33:47,182 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:33:47,183 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:33:47,183 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:33:47,183 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:33:47,183 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:33:47,183 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:33:47,183 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:33:47,184 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:33:47,184 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 110, in load
2019-12-02 08:33:47,184 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:33:47,184 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:33:47,184 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:33:47,184 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:33:47,184 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:33:47,184 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:33:47,185 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-12-02 08:33:47,189 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:33:47,921 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:33:47,922 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62772
2019-12-02 08:33:47,922 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:33:47,922 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:33:47,922 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:33:47,922 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:33:47,924 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:33:47,927 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/e63f36427280deadbd76f956ac5253309b7658d3
2019-12-02 08:33:47,927 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:33:47,927 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:33:47,927 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 08:33:47,927 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:33:47,928 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:33:47,928 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:33:47,928 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:33:47,928 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:33:47,928 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:33:47,928 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:33:47,928 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:33:47,928 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:33:47,929 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:33:47,931 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:33:47,931 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 110, in load
2019-12-02 08:33:47,931 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:33:47,931 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-12-02 08:33:47,931 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:33:47,932 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:33:47,932 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62773
2019-12-02 08:33:47,932 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:33:47,932 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:33:47,932 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:33:47,932 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:33:47,932 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:33:47,932 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:33:47,932 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:33:47,932 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:33:47,932 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:33:47,933 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:33:47,936 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/e63f36427280deadbd76f956ac5253309b7658d3
2019-12-02 08:33:47,936 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:33:47,936 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:33:47,936 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:33:47,936 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:33:47,936 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:33:47,937 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:33:47,937 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:33:47,937 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:33:47,937 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:33:47,937 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:33:47,937 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:33:47,937 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:33:47,937 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:33:47,938 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:33:47,937 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-12-02 08:33:47,938 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 110, in load
2019-12-02 08:33:47,938 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:33:47,938 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:33:47,938 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:33:47,939 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:33:47,939 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:33:47,939 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:33:47,939 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:33:48,347 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:33:48,348 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62774
2019-12-02 08:33:48,348 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:33:48,348 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:33:48,348 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:33:48,348 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:33:48,350 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:33:48,352 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/e63f36427280deadbd76f956ac5253309b7658d3
2019-12-02 08:33:48,352 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:33:48,352 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:33:48,352 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:33:48,352 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:33:48,352 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:33:48,352 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:33:48,352 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:33:48,353 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:33:48,353 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:33:48,353 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:33:48,353 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:33:48,354 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:33:48,354 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 110, in load
2019-12-02 08:33:48,354 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:33:48,354 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:33:48,354 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:33:48,354 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:33:48,354 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:33:48,354 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:33:48,354 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:33:48,355 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:33:48,355 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:33:48,355 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2019-12-02 08:33:48,362 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:33:48,363 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62775
2019-12-02 08:33:48,363 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:33:48,363 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:33:48,363 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:33:48,363 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:33:48,364 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:33:48,366 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/e63f36427280deadbd76f956ac5253309b7658d3
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:33:48,367 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 110, in load
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/py_env/tvmstack/lib/python3.7/importlib/__init__.py", line 127, in import_module
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2019-12-02 08:33:48,367 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2019-12-02 08:33:48,368 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2019-12-02 08:33:48,368 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'e63f36427280deadbd76f956ac5253309b7658d3'
2019-12-02 08:33:48,368 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:33:48,368 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:33:48,368 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:33:48,371 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2019-12-02 08:35:37,801 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store
Initial Models: squeezenet=squeezenet_v1.1.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-12-02 08:35:37,809 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: squeezenet_v1.1.mar
2019-12-02 08:35:38,106 [INFO ] main org.pytorch.serve.archive.ModelArchive - model folder already exists: e63f36427280deadbd76f956ac5253309b7658d3
2019-12-02 08:35:38,110 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-12-02 08:35:38,111 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-12-02 08:35:38,138 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-12-02 08:35:38,503 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:35:38,503 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62814
2019-12-02 08:35:38,503 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:35:38,503 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:35:38,505 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:35:38,513 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:35:38,516 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:35:38,516 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62812
2019-12-02 08:35:38,517 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:35:38,517 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:35:38,517 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:35:38,517 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:35:38,537 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:35:38,537 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62811
2019-12-02 08:35:38,537 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:35:38,537 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:35:38,537 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:35:38,537 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:35:38,548 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-12-02 08:35:38,548 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-12-02 08:35:38,549 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-12-02 08:35:38,551 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:35:38,577 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:35:38,588 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-12-02 08:35:38,594 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:35:38,629 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:35:38,633 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62813
2019-12-02 08:35:38,641 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:35:38,641 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:35:38,641 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:35:38,646 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:35:38,650 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:35:40,604 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:35:40,604 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:35:40,604 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:35:40,604 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:35:40,604 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:35:40,604 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:35:40,604 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:35:40,605 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:35:40,605 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:35:40,605 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:35:40,605 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:35:40,605 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:35:40,605 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:35:40,605 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:35:40,605 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:35:40,606 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:35:40,606 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:35:40,606 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:35:40,607 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:35:40,607 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:35:40,607 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 117, in load
2019-12-02 08:35:40,607 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 117, in load
2019-12-02 08:35:40,607 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:35:40,607 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     if function_name is None:
2019-12-02 08:35:40,607 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - UnboundLocalError: local variable 'function_name' referenced before assignment
2019-12-02 08:35:40,607 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     if function_name is None:
2019-12-02 08:35:40,608 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - UnboundLocalError: local variable 'function_name' referenced before assignment
2019-12-02 08:35:40,608 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:35:40,612 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:35:40,610 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 08:35:40,612 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:35:40,612 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:35:40,612 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:35:40,613 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:35:40,610 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:35:40,610 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:35:40,614 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:35:40,617 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-12-02 08:35:40,609 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:35:40,618 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:35:40,618 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:35:40,618 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:35:40,617 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:35:40,618 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:35:40,618 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:35:40,619 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:35:40,619 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:35:40,619 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:35:40,619 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:35:40,619 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:35:40,619 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:35:40,620 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 117, in load
2019-12-02 08:35:40,620 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     if function_name is None:
2019-12-02 08:35:40,620 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - UnboundLocalError: local variable 'function_name' referenced before assignment
2019-12-02 08:35:40,613 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:35:40,622 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:35:40,622 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:35:40,624 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:35:40,612 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:35:40,625 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:35:40,625 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:35:40,624 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:35:40,625 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-12-02 08:35:40,625 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:35:40,625 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:35:40,625 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:35:40,626 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 117, in load
2019-12-02 08:35:40,626 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     if function_name is None:
2019-12-02 08:35:40,626 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - UnboundLocalError: local variable 'function_name' referenced before assignment
2019-12-02 08:35:40,618 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:35:40,628 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-12-02 08:35:40,630 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-12-02 08:35:41,852 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:35:41,853 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:35:41,854 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62827
2019-12-02 08:35:41,854 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:35:41,855 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:35:41,855 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:35:41,855 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:35:41,859 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:35:41,862 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62826
2019-12-02 08:35:41,862 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:35:41,862 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:35:41,862 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:35:41,862 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:35:41,866 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:35:41,867 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62825
2019-12-02 08:35:41,868 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:35:41,868 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:35:41,868 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:35:41,869 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:35:41,871 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:35:41,872 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:35:41,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:35:41,877 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62824
2019-12-02 08:35:41,878 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:35:41,878 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:35:41,879 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:35:41,884 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:35:41,885 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:35:42,891 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:35:42,891 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:35:42,892 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:35:42,891 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:35:42,892 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:35:42,892 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:35:42,892 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:35:42,892 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:35:42,892 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:35:42,892 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:35:42,892 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:35:42,892 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:35:42,893 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-12-02 08:35:42,893 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:35:42,893 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:35:42,894 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 117, in load
2019-12-02 08:35:42,894 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     if function_name is None:
2019-12-02 08:35:42,894 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - UnboundLocalError: local variable 'function_name' referenced before assignment
2019-12-02 08:35:42,906 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:35:42,907 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 08:35:42,907 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:35:42,907 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:35:42,907 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:35:42,907 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:35:42,907 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:35:42,907 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:35:42,907 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:35:42,907 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:35:42,907 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:35:42,907 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:35:42,908 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-12-02 08:35:42,911 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:35:42,911 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:35:42,911 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 117, in load
2019-12-02 08:35:42,912 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     if function_name is None:
2019-12-02 08:35:42,912 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - UnboundLocalError: local variable 'function_name' referenced before assignment
2019-12-02 08:35:42,934 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:35:42,935 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:35:42,935 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:35:42,935 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:35:42,935 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:35:42,935 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:35:42,935 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:35:42,936 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:35:42,936 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:35:42,936 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:35:42,936 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:35:42,936 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:35:42,936 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:35:42,936 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:35:42,936 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 117, in load
2019-12-02 08:35:42,937 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     if function_name is None:
2019-12-02 08:35:42,937 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - UnboundLocalError: local variable 'function_name' referenced before assignment
2019-12-02 08:35:42,937 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-12-02 08:35:42,981 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:35:42,981 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:35:42,981 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:35:42,981 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:35:42,981 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:35:42,981 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:35:42,982 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:35:42,982 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:35:42,981 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:35:42,982 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:35:42,982 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:35:42,982 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:35:42,982 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:35:42,983 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:35:42,983 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-12-02 08:35:42,983 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 117, in load
2019-12-02 08:35:42,983 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     if function_name is None:
2019-12-02 08:35:42,983 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - UnboundLocalError: local variable 'function_name' referenced before assignment
2019-12-02 08:36:56,436 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store
Initial Models: squeezenet=squeezenet_v1.1.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-12-02 08:36:56,453 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: squeezenet_v1.1.mar
2019-12-02 08:36:56,763 [INFO ] main org.pytorch.serve.archive.ModelArchive - model folder already exists: e63f36427280deadbd76f956ac5253309b7658d3
2019-12-02 08:36:56,769 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-12-02 08:36:56,769 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-12-02 08:36:56,795 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-12-02 08:36:57,175 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:36:57,175 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62862
2019-12-02 08:36:57,176 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:36:57,176 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:36:57,177 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:36:57,186 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:36:57,191 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:36:57,191 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62863
2019-12-02 08:36:57,192 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:36:57,192 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:36:57,192 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:36:57,192 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:36:57,219 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:36:57,220 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62860
2019-12-02 08:36:57,220 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:36:57,220 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:36:57,220 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:36:57,220 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:36:57,259 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:36:57,259 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:36:57,260 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:36:57,261 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-12-02 08:36:57,262 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-12-02 08:36:57,263 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:36:57,263 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-12-02 08:36:57,264 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62861
2019-12-02 08:36:57,264 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:36:57,264 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:36:57,264 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:36:57,264 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:36:57,266 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:36:59,204 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:36:59,204 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:36:59,204 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:36:59,205 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:36:59,205 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:36:59,205 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:36:59,205 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:36:59,205 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:36:59,205 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:36:59,205 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:36:59,205 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:36:59,204 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:36:59,205 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:36:59,205 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:36:59,204 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:36:59,206 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:36:59,205 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:36:59,206 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:36:59,206 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:36:59,206 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:36:59,206 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:36:59,207 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:36:59,206 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:36:59,207 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:36:59,207 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:36:59,207 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:36:59,207 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:36:59,207 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:36:59,207 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:36:59,207 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:36:59,208 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:36:59,208 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:36:59,208 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:36:59,209 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:36:59,209 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:36:59,209 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:36:59,209 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:36:59,209 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:36:59,209 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:36:59,210 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:36:59,210 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:36:59,210 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:36:59,210 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:36:59,210 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:36:59,208 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:36:59,217 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:36:59,217 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:36:59,217 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:36:59,208 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:36:59,224 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:36:59,225 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:36:59,225 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:36:59,226 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:36:59,226 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:36:59,226 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:36:59,226 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:36:59,226 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:36:59,226 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:36:59,226 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:36:59,207 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:36:59,228 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:36:59,207 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:36:59,228 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:36:59,229 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:36:59,229 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:36:59,229 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:36:59,229 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:36:59,229 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:36:59,230 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:36:59,232 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:36:59,234 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:36:59,234 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:36:59,236 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-12-02 08:36:59,237 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:36:59,237 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:36:59,238 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:36:59,238 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:36:59,242 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-12-02 08:36:59,249 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 08:36:59,250 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:36:59,250 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:36:59,250 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:36:59,250 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:36:59,250 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:36:59,251 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:36:59,251 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:36:59,252 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-12-02 08:36:59,253 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-12-02 08:37:00,487 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:37:00,488 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62873
2019-12-02 08:37:00,489 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:37:00,489 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:37:00,489 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:37:00,490 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:37:00,493 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:37:00,510 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:37:00,510 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62874
2019-12-02 08:37:00,510 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:37:00,510 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:37:00,510 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:37:00,510 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:37:00,512 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:37:01,430 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:37:01,430 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:37:01,431 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:37:01,431 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:37:01,431 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:37:01,432 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:37:01,432 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:37:01,432 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:37:01,432 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:37:01,432 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:37:01,432 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:37:01,432 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:37:01,432 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:37:01,432 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:37:01,433 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-12-02 08:37:01,433 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:37:01,433 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:37:01,433 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:37:01,433 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:37:01,433 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:37:01,433 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:37:01,434 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:37:01,445 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:37:01,445 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:37:01,445 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:37:01,445 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:37:01,446 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:37:01,446 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:37:01,446 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:37:01,446 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:37:01,446 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:37:01,446 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:37:01,446 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:37:01,447 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:37:01,448 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:37:01,448 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:37:01,448 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:37:01,449 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:37:01,449 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:37:01,462 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:37:01,463 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:37:01,470 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:37:01,470 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:37:01,471 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-12-02 08:37:01,479 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:37:01,480 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62876
2019-12-02 08:37:01,482 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:37:01,482 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:37:01,482 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:37:01,493 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:37:01,494 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:37:01,495 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:37:01,496 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]62875
2019-12-02 08:37:01,496 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:37:01,496 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:37:01,496 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:37:01,496 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:37:01,498 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:49:30,877 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store/denmar
Initial Models: squeezenet=densenet161.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-12-02 08:49:30,907 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: densenet161.mar
2019-12-02 08:49:42,657 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-12-02 08:49:42,659 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-12-02 08:49:42,826 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-12-02 08:49:43,350 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-12-02 08:49:43,350 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-12-02 08:49:43,352 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-12-02 08:49:43,376 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-12-02 08:50:00,007 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:50:00,010 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63514
2019-12-02 08:50:00,010 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:00,011 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:00,012 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:50:00,036 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:50:00,260 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:50:00,730 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:50:00,731 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63516
2019-12-02 08:50:00,731 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:00,731 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:50:00,732 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:50:00,732 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:00,735 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:50:02,006 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:50:02,006 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63527
2019-12-02 08:50:02,006 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:02,007 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:50:02,007 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:50:02,007 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:02,009 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:50:02,315 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:50:02,316 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:50:02,316 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:50:02,316 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:50:02,316 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:50:02,316 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:50:02,316 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:50:02,317 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:50:02,317 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:50:02,317 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:50:02,318 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:50:02,318 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:50:02,318 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:50:02,318 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:50:02,318 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:50:02,318 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:50:02,318 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:50:02,320 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 08:50:02,321 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:50:02,326 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:50:02,326 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:50:02,328 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-12-02 08:50:02,353 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:50:02,354 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:50:02,354 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:50:02,354 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:50:02,354 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:50:02,354 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:50:02,354 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:50:02,355 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:50:02,355 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:50:02,355 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:50:02,355 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-12-02 08:50:02,355 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:50:02,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:50:02,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:50:02,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:50:02,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:50:02,356 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:50:02,357 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:50:02,357 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:50:02,357 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:50:02,357 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:50:02,360 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:50:02,836 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:50:02,836 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63534
2019-12-02 08:50:02,836 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:02,836 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:50:02,836 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:02,836 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:50:02,842 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:50:02,943 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:50:02,943 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:50:02,943 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:50:02,943 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:50:02,943 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:50:02,944 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:50:02,944 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:50:02,944 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:50:02,944 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:50:02,944 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:50:02,944 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:50:02,945 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:50:02,945 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:50:02,945 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:50:02,945 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:50:02,945 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:50:02,945 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:50:02,947 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:50:02,948 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:50:02,954 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:50:02,954 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:50:02,957 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-12-02 08:50:03,470 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:50:03,470 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:50:03,470 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:50:03,471 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:50:03,471 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:50:03,471 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:50:03,471 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:50:03,471 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:50:03,471 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:50:03,471 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:50:03,471 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:50:03,471 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:50:03,472 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:50:03,472 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:50:03,472 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:50:03,472 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:50:03,473 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-12-02 08:50:03,473 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:50:03,473 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:50:03,473 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:50:03,473 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:50:03,473 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:50:03,501 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:50:03,501 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63541
2019-12-02 08:50:03,502 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:03,502 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:50:03,502 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:03,502 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:50:03,507 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:50:03,511 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:50:03,511 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63542
2019-12-02 08:50:03,511 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:03,512 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:50:03,512 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:50:03,517 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:03,517 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:50:04,120 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:50:04,121 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63551
2019-12-02 08:50:04,121 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:04,121 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:50:04,122 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:04,122 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:50:04,123 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:50:04,211 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:50:04,211 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:50:04,211 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:50:04,212 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:50:04,212 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:50:04,212 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:50:04,212 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:50:04,212 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:50:04,212 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:50:04,212 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:50:04,212 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:50:04,213 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:50:04,213 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:50:04,213 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:50:04,213 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-12-02 08:50:04,213 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:50:04,213 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:50:04,214 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:50:04,214 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:50:04,214 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:50:04,214 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:50:04,215 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:50:04,271 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:50:04,271 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:50:04,271 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:50:04,271 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:50:04,272 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 08:50:04,272 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:50:04,272 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:50:04,272 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:50:04,272 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:50:04,272 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:50:04,273 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:50:04,273 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:50:04,273 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:50:04,273 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:50:04,273 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:50:04,273 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:50:04,273 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:50:04,273 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:50:04,276 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:50:04,278 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:50:04,278 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:50:04,286 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-12-02 08:50:04,602 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:50:04,603 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63556
2019-12-02 08:50:04,603 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:04,603 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:04,603 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:50:04,603 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:50:04,604 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:50:04,863 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:50:04,863 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:50:04,863 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:50:04,864 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:50:04,864 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:50:04,864 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:50:04,864 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:50:04,864 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:50:04,865 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:50:04,865 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:50:04,865 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:50:04,865 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:50:04,865 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:50:04,865 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:50:04,865 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:50:04,865 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:50:04,865 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:50:04,866 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:50:04,866 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:50:04,866 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:50:04,866 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:50:04,866 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-12-02 08:50:05,237 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:50:05,237 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:50:05,238 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:50:05,238 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:50:05,238 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:50:05,238 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:50:05,238 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:50:05,238 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:50:05,238 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:50:05,238 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:50:05,239 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:50:05,239 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:50:05,239 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:50:05,239 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:50:05,239 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:50:05,239 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:50:05,239 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:50:05,241 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:50:05,241 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:50:05,241 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:50:05,241 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:50:05,242 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-12-02 08:50:05,472 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:50:05,473 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63566
2019-12-02 08:50:05,473 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:05,473 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:50:05,473 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:50:05,473 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:05,478 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:50:05,497 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:50:05,502 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63564
2019-12-02 08:50:05,502 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:05,502 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:05,503 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:50:05,503 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:50:05,521 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:50:06,091 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:50:06,092 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63573
2019-12-02 08:50:06,092 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:06,092 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:50:06,092 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:50:06,092 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:06,094 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:50:06,446 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:50:06,446 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63580
2019-12-02 08:50:06,447 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:06,447 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:50:06,447 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:06,447 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:50:06,448 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:50:06,721 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:50:06,721 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:50:06,722 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:50:06,722 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 08:50:06,722 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:50:06,722 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:50:06,722 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:50:06,722 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:50:06,722 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:50:06,722 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:50:06,722 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:50:06,722 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:50:06,722 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:50:06,723 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:50:06,723 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:50:06,723 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2019-12-02 08:50:06,724 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:50:06,724 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:50:06,724 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:50:06,724 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:50:06,724 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:50:06,724 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:50:06,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:50:06,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:50:06,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:50:06,741 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:50:06,741 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:50:06,742 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:50:06,742 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:50:06,742 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:50:06,742 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:50:06,742 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:50:06,742 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:50:06,742 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:50:06,742 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:50:06,742 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:50:06,742 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:50:06,742 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2019-12-02 08:50:06,742 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:50:06,742 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:50:06,743 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:50:06,743 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:50:06,743 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:50:06,743 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:50:07,194 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:50:07,194 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:50:07,194 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:50:07,194 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:50:07,194 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:50:07,194 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:50:07,194 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:50:07,194 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:50:07,194 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:50:07,195 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:50:07,195 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:50:07,195 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:50:07,195 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:50:07,195 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:50:07,195 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:50:07,195 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:50:07,195 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:50:07,195 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:50:07,195 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:50:07,195 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:50:07,195 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:50:07,195 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2019-12-02 08:50:07,338 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:50:07,338 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:50:07,338 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:50:07,338 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:50:07,338 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:50:07,338 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:50:07,338 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:50:07,339 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:50:07,339 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:50:07,339 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:50:07,339 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:50:07,339 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:50:07,339 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:50:07,339 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:50:07,339 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:50:07,339 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file.")
2019-12-02 08:50:07,339 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file.
2019-12-02 08:50:07,340 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:50:07,341 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:50:07,342 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:50:07,342 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:50:07,343 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2019-12-02 08:50:08,893 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:50:08,894 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63595
2019-12-02 08:50:08,894 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:08,894 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:08,894 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:50:08,894 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:50:08,895 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:50:08,920 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:50:08,920 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63596
2019-12-02 08:50:08,920 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:08,920 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:50:08,920 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:08,920 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:50:08,921 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:50:09,414 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:50:09,415 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63601
2019-12-02 08:50:09,415 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:09,415 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:09,415 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:50:09,415 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:50:09,417 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:50:09,540 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:50:09,540 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63602
2019-12-02 08:50:09,540 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:50:09,541 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:50:09,541 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:50:09,543 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:50:09,544 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:56:36,955 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store/denmar
Initial Models: squeezenet=densenet161.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-12-02 08:56:36,962 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: densenet161.mar
2019-12-02 08:56:40,372 [INFO ] main org.pytorch.serve.archive.ModelArchive - model folder already exists: 5d52891c2f0939519601a3b5e4f532215135dccf
2019-12-02 08:56:40,376 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-12-02 08:56:40,376 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-12-02 08:56:40,404 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-12-02 08:56:40,696 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-12-02 08:56:40,696 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-12-02 08:56:40,700 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-12-02 08:56:40,716 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-12-02 08:56:40,779 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:56:40,779 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63671
2019-12-02 08:56:40,780 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:56:40,780 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:56:40,781 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:56:40,789 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:56:40,848 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:56:40,853 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63674
2019-12-02 08:56:40,854 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:56:40,854 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:56:40,854 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:56:40,855 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:56:40,857 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:56:40,860 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:56:40,882 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:56:40,882 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63673
2019-12-02 08:56:40,882 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:56:40,883 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:56:40,883 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:56:40,883 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:56:40,917 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:56:40,926 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:56:40,928 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63672
2019-12-02 08:56:40,929 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:56:40,929 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change null -> WORKER_STARTED
2019-12-02 08:56:40,929 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:56:40,929 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:56:40,931 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:56:42,645 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:56:42,646 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:56:42,646 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:56:42,646 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:56:42,647 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:56:42,646 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:56:42,647 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:56:42,647 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:56:42,647 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:56:42,647 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:56:42,647 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:56:42,647 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:56:42,647 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:56:42,647 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:56:42,647 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:56:42,647 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:56:42,647 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:56:42,648 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:56:42,648 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:56:42,648 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:56:42,648 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:56:42,648 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:56:42,645 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:56:42,648 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:56:42,648 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:56:42,648 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:56:42,648 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:56:42,648 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:56:42,646 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:56:42,649 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:56:42,649 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 08:56:42,649 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:56:42,649 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:56:42,650 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:56:42,649 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:56:42,650 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:56:42,649 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:56:42,650 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 08:56:42,650 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:56:42,649 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:56:42,649 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:56:42,652 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:56:42,653 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:56:42,652 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:56:42,652 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 08:56:42,653 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:56:42,651 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:56:42,651 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:56:42,651 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:56:42,658 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:56:42,658 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:56:42,657 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:56:42,657 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:56:42,656 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:56:42,659 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:56:42,653 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:56:42,659 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:56:42,660 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:56:42,660 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-12-02 08:56:42,653 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:56:42,660 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-12-02 08:56:42,652 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:56:42,664 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:56:42,664 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:56:42,664 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:56:42,665 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:56:42,665 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:56:42,665 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:56:42,665 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:56:42,660 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:56:42,666 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:56:42,667 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 08:56:42,667 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 08:56:42,670 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 08:56:42,670 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 08:56:42,660 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:56:42,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:56:42,659 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:56:42,671 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:56:42,672 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:56:42,672 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:56:42,658 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:56:42,672 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:56:42,672 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:56:42,672 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 08:56:42,672 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 08:56:42,673 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-12-02 08:56:42,673 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-12-02 08:56:43,869 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:56:43,871 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63685
2019-12-02 08:56:43,872 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:56:43,872 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:56:43,872 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:56:43,874 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:56:43,875 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63684
2019-12-02 08:56:43,875 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:56:43,875 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:56:43,875 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:56:43,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:56:43,877 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:56:43,878 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:56:43,878 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:56:43,892 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:56:43,893 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63687
2019-12-02 08:56:43,893 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:56:43,893 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:56:43,893 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:56:43,893 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:56:43,896 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 08:56:43,911 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:56:43,911 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63686
2019-12-02 08:56:43,911 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:56:43,911 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:56:43,911 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:56:43,912 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:56:43,919 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:56:44,875 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:56:44,875 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:56:44,875 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:56:44,875 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:56:44,875 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:56:44,875 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:56:44,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:56:44,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:56:44,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:56:44,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:56:44,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:56:44,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:56:44,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:56:44,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:56:44,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:56:44,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 08:56:44,876 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 08:56:44,877 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 08:56:44,877 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:56:44,878 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:56:44,878 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:56:44,878 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-12-02 08:56:44,895 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:56:44,895 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:56:44,895 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 08:56:44,895 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:56:44,895 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:56:44,895 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:56:44,895 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:56:44,895 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:56:44,896 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:56:44,898 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:56:44,898 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:56:44,898 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:56:44,898 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:56:44,899 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:56:44,899 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-12-02 08:56:44,899 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:56:44,899 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:56:44,899 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:56:44,899 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:56:44,899 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:56:44,899 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 08:56:44,899 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 08:56:44,938 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:56:44,938 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:56:44,939 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:56:44,939 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 08:56:44,939 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:56:44,939 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:56:44,939 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:56:44,939 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:56:44,939 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:56:44,939 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:56:44,939 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:56:44,940 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:56:44,940 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:56:44,940 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:56:44,940 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-12-02 08:56:44,940 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:56:44,940 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:56:44,940 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:56:44,940 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:56:44,940 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:56:44,940 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 08:56:44,940 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 08:56:44,962 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 08:56:44,963 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 08:56:44,963 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 163, in <module>
2019-12-02 08:56:44,963 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 08:56:44,963 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 141, in run_server
2019-12-02 08:56:44,963 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 08:56:44,963 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 08:56:44,963 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 105, in handle_connection
2019-12-02 08:56:44,964 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 08:56:44,964 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 08:56:44,964 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 83, in load_model
2019-12-02 08:56:44,964 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 08:56:44,964 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 08:56:44,964 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 08:56:44,964 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 08:56:44,965 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 08:56:44,965 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-12-02 08:56:44,965 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 08:56:44,965 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 08:56:44,965 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 08:56:44,965 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 08:56:44,965 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 08:56:46,122 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:56:46,122 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63696
2019-12-02 08:56:46,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:56:46,123 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:56:46,123 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:56:46,123 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 08:56:46,125 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 08:56:46,130 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:56:46,131 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63697
2019-12-02 08:56:46,131 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:56:46,131 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:56:46,131 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:56:46,131 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 08:56:46,133 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 08:56:46,206 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:56:46,207 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63698
2019-12-02 08:56:46,207 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:56:46,207 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:56:46,207 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:56:46,207 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 08:56:46,209 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 08:56:46,216 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:56:46,217 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63699
2019-12-02 08:56:46,217 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 08:56:46,217 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 08:56:46,217 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 08:56:46,221 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 08:56:46,223 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 09:04:00,221 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store/denmar
Initial Models: squeezenet=densenet161.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-12-02 09:04:00,286 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: densenet161.mar
2019-12-02 09:04:03,849 [INFO ] main org.pytorch.serve.archive.ModelArchive - model folder already exists: 5d52891c2f0939519601a3b5e4f532215135dccf
2019-12-02 09:04:03,858 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-12-02 09:04:03,858 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-12-02 09:04:03,904 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-12-02 09:04:04,211 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 09:04:04,212 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63751
2019-12-02 09:04:04,212 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:04:04,212 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:04:04,213 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change null -> WORKER_STARTED
2019-12-02 09:04:04,226 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 09:04:04,255 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-12-02 09:04:04,256 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-12-02 09:04:04,265 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-12-02 09:04:04,270 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 09:04:04,297 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-12-02 09:04:05,106 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 09:04:05,107 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63750
2019-12-02 09:04:05,107 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:04:05,107 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:04:05,108 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change null -> WORKER_STARTED
2019-12-02 09:04:05,108 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 09:04:05,110 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 09:04:05,116 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 09:04:05,116 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63752
2019-12-02 09:04:05,117 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:04:05,117 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:04:05,117 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change null -> WORKER_STARTED
2019-12-02 09:04:05,117 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 09:04:05,120 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 09:04:05,125 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 09:04:05,125 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63753
2019-12-02 09:04:05,126 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:04:05,126 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:04:05,126 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change null -> WORKER_STARTED
2019-12-02 09:04:05,126 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 09:04:05,130 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 09:04:06,075 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 09:04:06,075 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 09:04:06,076 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 09:04:06,076 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 09:04:06,076 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 164, in <module>
2019-12-02 09:04:06,076 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 164, in <module>
2019-12-02 09:04:06,076 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 09:04:06,076 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 09:04:06,076 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 142, in run_server
2019-12-02 09:04:06,077 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 142, in run_server
2019-12-02 09:04:06,077 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 09:04:06,077 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 09:04:06,077 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 106, in handle_connection
2019-12-02 09:04:06,077 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 106, in handle_connection
2019-12-02 09:04:06,077 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 09:04:06,077 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 09:04:06,077 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 84, in load_model
2019-12-02 09:04:06,077 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 84, in load_model
2019-12-02 09:04:06,077 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 09:04:06,078 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 09:04:06,078 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 09:04:06,078 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 09:04:06,077 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 09:04:06,079 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 09:04:06,079 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 09:04:06,079 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 09:04:06,079 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 09:04:06,079 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 09:04:06,079 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 09:04:06,080 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 09:04:06,080 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 09:04:06,080 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 09:04:06,080 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 09:04:06,080 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 09:04:06,081 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 09:04:06,081 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 09:04:06,081 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 09:04:06,081 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 09:04:06,086 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 09:04:06,086 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 09:04:06,087 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 09:04:06,087 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 09:04:06,103 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-12-02 09:04:06,103 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-12-02 09:04:06,112 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 09:04:06,112 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 09:04:06,112 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 164, in <module>
2019-12-02 09:04:06,112 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 09:04:06,112 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 142, in run_server
2019-12-02 09:04:06,112 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 09:04:06,113 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 106, in handle_connection
2019-12-02 09:04:06,113 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 09:04:06,113 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 84, in load_model
2019-12-02 09:04:06,113 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 09:04:06,114 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 09:04:06,114 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 09:04:06,114 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 09:04:06,114 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 09:04:06,114 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 09:04:06,114 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 09:04:06,114 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 09:04:06,119 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 09:04:06,119 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 09:04:06,120 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 09:04:06,120 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 09:04:06,120 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 09:04:06,120 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 09:04:06,120 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 164, in <module>
2019-12-02 09:04:06,121 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-12-02 09:04:06,121 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 09:04:06,121 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 142, in run_server
2019-12-02 09:04:06,121 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 09:04:06,121 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 106, in handle_connection
2019-12-02 09:04:06,122 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 09:04:06,122 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 84, in load_model
2019-12-02 09:04:06,122 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 09:04:06,122 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 09:04:06,122 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 09:04:06,122 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 09:04:06,122 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 09:04:06,123 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 09:04:06,123 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 09:04:06,123 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 09:04:06,123 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 09:04:06,124 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 09:04:06,124 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 09:04:06,124 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 09:04:06,125 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-12-02 09:04:07,329 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 09:04:07,329 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63763
2019-12-02 09:04:07,330 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:04:07,330 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 09:04:07,330 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:04:07,330 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 09:04:07,336 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 09:04:07,340 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 09:04:07,340 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63764
2019-12-02 09:04:07,341 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:04:07,341 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 09:04:07,341 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:04:07,341 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 09:04:07,348 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 09:04:07,403 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 09:04:07,404 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63766
2019-12-02 09:04:07,404 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:04:07,404 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 09:04:07,404 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 09:04:07,409 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:04:07,412 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 09:04:07,434 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 09:04:07,434 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]63765
2019-12-02 09:04:07,434 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:04:07,434 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 09:04:07,435 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 09:04:07,484 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:04:07,485 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 09:04:08,556 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 09:04:08,557 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 09:04:08,557 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 164, in <module>
2019-12-02 09:04:08,557 [INFO ] KQueueEventLoopGroup-4-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 09:04:08,557 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 09:04:08,557 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 142, in run_server
2019-12-02 09:04:08,557 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 09:04:08,557 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 09:04:08,557 [WARN ] W-9002-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 09:04:08,557 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 106, in handle_connection
2019-12-02 09:04:08,557 [DEBUG] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9002-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 09:04:08,558 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 09:04:08,558 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 84, in load_model
2019-12-02 09:04:08,558 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 09:04:08,558 [INFO ] W-9002-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-12-02 09:04:08,558 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 09:04:08,561 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 09:04:08,562 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 09:04:08,562 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 09:04:08,562 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 09:04:08,562 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 09:04:08,562 [INFO ] W-9002-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 09:04:08,572 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 09:04:08,573 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 09:04:08,573 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 164, in <module>
2019-12-02 09:04:08,573 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 09:04:08,573 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 142, in run_server
2019-12-02 09:04:08,573 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 09:04:08,573 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 106, in handle_connection
2019-12-02 09:04:08,573 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 09:04:08,573 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 84, in load_model
2019-12-02 09:04:08,574 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 09:04:08,574 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 09:04:08,574 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 09:04:08,574 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 09:04:08,575 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 09:04:08,575 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 09:04:08,575 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 09:04:08,575 [INFO ] W-9003-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 09:04:08,578 [INFO ] KQueueEventLoopGroup-4-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 09:04:08,578 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 09:04:08,578 [WARN ] W-9003-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 09:04:08,578 [DEBUG] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9003-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 09:04:08,579 [INFO ] W-9003-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-12-02 09:04:08,587 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 09:04:08,587 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 09:04:08,587 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 164, in <module>
2019-12-02 09:04:08,587 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 09:04:08,587 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 142, in run_server
2019-12-02 09:04:08,587 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 09:04:08,588 [INFO ] KQueueEventLoopGroup-4-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 09:04:08,588 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 106, in handle_connection
2019-12-02 09:04:08,588 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 09:04:08,588 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 84, in load_model
2019-12-02 09:04:08,588 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 09:04:08,588 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 09:04:08,588 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 09:04:08,588 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 09:04:08,589 [WARN ] W-9001-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 09:04:08,589 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 09:04:08,589 [DEBUG] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9001-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 09:04:08,589 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 09:04:08,589 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 09:04:08,589 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 09:04:08,589 [INFO ] W-9001-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 09:04:08,590 [INFO ] W-9001-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-12-02 09:04:08,615 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 09:04:08,615 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 09:04:08,615 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 164, in <module>
2019-12-02 09:04:08,615 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 09:04:08,615 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 142, in run_server
2019-12-02 09:04:08,615 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 09:04:08,615 [INFO ] KQueueEventLoopGroup-4-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 09:04:08,615 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 106, in handle_connection
2019-12-02 09:04:08,616 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 09:04:08,616 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 09:04:08,616 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 84, in load_model
2019-12-02 09:04:08,616 [WARN ] W-9000-squeezenet org.pytorch.serve.wlm.BatchAggregator - Load model failed: squeezenet, error: Worker died.
2019-12-02 09:04:08,616 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 09:04:08,616 [DEBUG] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - W-9000-squeezenet State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 09:04:08,616 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 09:04:08,616 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 09:04:08,616 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 09:04:08,616 [INFO ] W-9000-squeezenet org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-12-02 09:04:08,617 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 09:04:08,617 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 09:04:08,617 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 09:04:08,618 [INFO ] W-9000-squeezenet-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 09:07:11,127 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store/denmar
Initial Models: squeezenet=densenet161.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-12-02 09:07:11,152 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: densenet161.mar
2019-12-02 09:07:14,542 [INFO ] main org.pytorch.serve.archive.ModelArchive - model folder already exists: 5d52891c2f0939519601a3b5e4f532215135dccf
2019-12-02 09:07:14,549 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model squeezenet loaded.
2019-12-02 09:07:14,549 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: squeezenet, count: 4
2019-12-02 09:07:14,628 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-12-02 09:07:15,025 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-12-02 09:07:15,025 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-12-02 09:07:15,050 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-12-02 09:07:15,090 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-12-02 09:08:15,079 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-12-02 09:09:15,087 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-12-02 09:10:15,102 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-12-02 09:10:22,837 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store/denmar
Initial Models: squeezenet=densenet161.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-12-02 09:10:22,858 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: densenet161.mar
2019-12-02 09:13:02,338 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store/denmar
Initial Models: squeezenet=densenet161.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-12-02 09:13:02,347 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: densenet161.mar
2019-12-02 09:13:44,731 [INFO ] main org.pytorch.serve.ModelServer - 
TS Home: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve
Current directory: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server
Temp directory: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 1820 M
Python executable: /Users/dhaniram_kshirsagar/py_env/tvmstack/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/model-store/denmar
Initial Models: dense=densenet161.mar
Log dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Metrics dir: /Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/frontend/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-12-02 09:13:44,740 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: densenet161.mar
2019-12-02 09:13:48,350 [INFO ] main org.pytorch.serve.archive.ModelArchive - model folder already exists: 5d52891c2f0939519601a3b5e4f532215135dccf
2019-12-02 09:13:48,355 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model dense loaded.
2019-12-02 09:13:48,355 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: dense, count: 4
2019-12-02 09:13:48,381 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-12-02 09:13:48,661 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-12-02 09:13:48,661 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-12-02 09:13:48,662 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2019-12-02 09:13:48,676 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2019-12-02 09:13:48,691 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 09:13:48,691 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 09:13:48,691 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]64364
2019-12-02 09:13:48,692 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:13:48,692 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]64365
2019-12-02 09:13:48,692 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:13:48,692 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:13:48,693 [DEBUG] W-9003-dense org.pytorch.serve.wlm.WorkerThread - W-9003-dense State change null -> WORKER_STARTED
2019-12-02 09:13:48,693 [DEBUG] W-9002-dense org.pytorch.serve.wlm.WorkerThread - W-9002-dense State change null -> WORKER_STARTED
2019-12-02 09:13:48,693 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:13:48,700 [INFO ] W-9002-dense org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 09:13:48,700 [INFO ] W-9003-dense org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 09:13:48,733 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 09:13:48,734 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 09:13:49,548 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 09:13:49,549 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]64363
2019-12-02 09:13:49,549 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:13:49,549 [DEBUG] W-9001-dense org.pytorch.serve.wlm.WorkerThread - W-9001-dense State change null -> WORKER_STARTED
2019-12-02 09:13:49,549 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:13:49,549 [INFO ] W-9001-dense org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 09:13:49,549 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 09:13:49,550 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]64362
2019-12-02 09:13:49,550 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:13:49,550 [DEBUG] W-9000-dense org.pytorch.serve.wlm.WorkerThread - W-9000-dense State change null -> WORKER_STARTED
2019-12-02 09:13:49,550 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:13:49,550 [INFO ] W-9000-dense org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 09:13:49,551 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
2019-12-02 09:13:49,553 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 09:13:50,514 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 09:13:50,514 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 09:13:50,514 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 09:13:50,515 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 164, in <module>
2019-12-02 09:13:50,515 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 09:13:50,515 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 09:13:50,515 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 142, in run_server
2019-12-02 09:13:50,515 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 164, in <module>
2019-12-02 09:13:50,515 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 09:13:50,516 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 142, in run_server
2019-12-02 09:13:50,516 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 09:13:50,516 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 106, in handle_connection
2019-12-02 09:13:50,516 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 09:13:50,516 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 84, in load_model
2019-12-02 09:13:50,516 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 09:13:50,515 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 09:13:50,517 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 09:13:50,518 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 106, in handle_connection
2019-12-02 09:13:50,518 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 09:13:50,518 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 09:13:50,518 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 09:13:50,518 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 84, in load_model
2019-12-02 09:13:50,518 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 09:13:50,518 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 09:13:50,518 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 09:13:50,519 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 09:13:50,519 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 09:13:50,519 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 09:13:50,519 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 09:13:50,518 [INFO ] KQueueEventLoopGroup-4-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-12-02 09:13:50,519 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 09:13:50,519 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 09:13:50,519 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 09:13:50,519 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 09:13:50,519 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 09:13:50,520 [INFO ] KQueueEventLoopGroup-4-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-12-02 09:13:50,521 [DEBUG] W-9003-dense org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 09:13:50,521 [DEBUG] W-9002-dense org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 09:13:50,524 [WARN ] W-9003-dense org.pytorch.serve.wlm.BatchAggregator - Load model failed: dense, error: Worker died.
2019-12-02 09:13:50,524 [DEBUG] W-9003-dense org.pytorch.serve.wlm.WorkerThread - W-9003-dense State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 09:13:50,524 [WARN ] W-9002-dense org.pytorch.serve.wlm.BatchAggregator - Load model failed: dense, error: Worker died.
2019-12-02 09:13:50,525 [DEBUG] W-9002-dense org.pytorch.serve.wlm.WorkerThread - W-9002-dense State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 09:13:50,534 [INFO ] W-9003-dense org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-12-02 09:13:50,540 [INFO ] W-9002-dense org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-12-02 09:13:50,611 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 09:13:50,611 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process die.
2019-12-02 09:13:50,611 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 09:13:50,611 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-12-02 09:13:50,611 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 164, in <module>
2019-12-02 09:13:50,611 [INFO ] KQueueEventLoopGroup-4-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-12-02 09:13:50,611 [INFO ] KQueueEventLoopGroup-4-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-12-02 09:13:50,612 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 09:13:50,612 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 164, in <module>
2019-12-02 09:13:50,612 [DEBUG] W-9000-dense org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 09:13:50,612 [DEBUG] W-9001-dense org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:128)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-12-02 09:13:50,612 [WARN ] W-9000-dense org.pytorch.serve.wlm.BatchAggregator - Load model failed: dense, error: Worker died.
2019-12-02 09:13:50,612 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2019-12-02 09:13:50,613 [DEBUG] W-9000-dense org.pytorch.serve.wlm.WorkerThread - W-9000-dense State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 09:13:50,612 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 142, in run_server
2019-12-02 09:13:50,613 [WARN ] W-9001-dense org.pytorch.serve.wlm.BatchAggregator - Load model failed: dense, error: Worker died.
2019-12-02 09:13:50,613 [DEBUG] W-9001-dense org.pytorch.serve.wlm.WorkerThread - W-9001-dense State change WORKER_STARTED -> WORKER_STOPPED
2019-12-02 09:13:50,613 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 142, in run_server
2019-12-02 09:13:50,616 [INFO ] W-9001-dense org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-12-02 09:13:50,617 [INFO ] W-9000-dense org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-12-02 09:13:50,617 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 09:13:50,618 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-12-02 09:13:50,618 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 106, in handle_connection
2019-12-02 09:13:50,618 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 106, in handle_connection
2019-12-02 09:13:50,618 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 09:13:50,619 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-12-02 09:13:50,619 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 84, in load_model
2019-12-02 09:13:50,619 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 09:13:50,621 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_service_worker.py", line 84, in load_model
2019-12-02 09:13:50,621 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-12-02 09:13:50,624 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 09:13:50,624 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 09:13:50,624 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 09:13:50,624 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 09:13:50,624 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 09:13:50,624 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 09:13:50,624 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 09:13:50,625 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/model_loader.py", line 126, in load
2019-12-02 09:13:50,625 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-12-02 09:13:50,625 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 141, in handle
2019-12-02 09:13:50,625 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-12-02 09:13:50,626 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/Users/dhaniram_kshirsagar/projects/neo-sagemaker/mms/code/serve/ts/torch_hanlder/image_classifier.py", line 49, in initialize
2019-12-02 09:13:50,626 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise RuntimeError("Missing model.pth file."+checkpoint_file_path)
2019-12-02 09:13:50,627 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError: Missing model.pth file./var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T/models/5d52891c2f0939519601a3b5e4f532215135dccf/model.pth
2019-12-02 09:13:51,698 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 09:13:51,698 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 09:13:51,699 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]64376
2019-12-02 09:13:51,699 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:13:51,700 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:13:51,700 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]64375
2019-12-02 09:13:51,700 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:13:51,700 [DEBUG] W-9003-dense org.pytorch.serve.wlm.WorkerThread - W-9003-dense State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 09:13:51,700 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:13:51,700 [INFO ] W-9003-dense org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003
2019-12-02 09:13:51,701 [DEBUG] W-9002-dense org.pytorch.serve.wlm.WorkerThread - W-9002-dense State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 09:13:51,701 [INFO ] W-9002-dense org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002
2019-12-02 09:13:51,706 [INFO ] W-9003-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9003.
2019-12-02 09:13:51,706 [INFO ] W-9002-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9002.
2019-12-02 09:13:51,955 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 09:13:51,955 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]64378
2019-12-02 09:13:51,956 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:13:51,956 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:13:51,956 [DEBUG] W-9000-dense org.pytorch.serve.wlm.WorkerThread - W-9000-dense State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 09:13:51,956 [INFO ] W-9000-dense org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000
2019-12-02 09:13:51,958 [INFO ] W-9000-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9000.
2019-12-02 09:13:51,962 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 09:13:51,962 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]64377
2019-12-02 09:13:51,963 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2019-12-02 09:13:51,963 [DEBUG] W-9001-dense org.pytorch.serve.wlm.WorkerThread - W-9001-dense State change WORKER_STOPPED -> WORKER_STARTED
2019-12-02 09:13:51,963 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.3
2019-12-02 09:13:51,963 [INFO ] W-9001-dense org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001
2019-12-02 09:13:51,964 [INFO ] W-9001-dense-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /var/folders/2d/ws7x9kss7hn999yxs2mflkf89ql4zn/T//.ts.sock.9001.
