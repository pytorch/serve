version: 2.1


executors:
  # AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY under 'Project Settings > Environment Variables' in CircleCI
  ubuntu18-pythn36-cpu-docker:
    docker:
      - image: 285923338299.dkr.ecr.us-east-1.amazonaws.com/torchserve-build:ubuntu18-pythn36-cpu
  ubuntu18-conda38-cpu-docker:
    docker:
      - image: 285923338299.dkr.ecr.us-east-1.amazonaws.com/torchserve-build:ubuntu18-conda38-cpu
  ubuntu18-pyenv37-cpu-docker:
    docker:
      - image: 285923338299.dkr.ecr.us-east-1.amazonaws.com/torchserve-build:ubuntu18-pyenv37-cpu
  ubuntu18-venv36-cpu-docker:
    docker:
      - image: 285923338299.dkr.ecr.us-east-1.amazonaws.com/torchserve-build:ubuntu18-venv36-cpu


commands:
  attach-torchserve-workspace:
    description: "Attach the torchserve directory which was saved into workspace"
    steps:
      - attach_workspace:
          at: .

  install-torchserve:
    description: "Install torchserve from a wheel"
    steps:
      - run:
          name: Install torchserve
          command: .circleci/scripts/linux_install.sh

  exeucute-api-tests:
    description: "Execute API tests from a collection"
    parameters:
      collection:
        type: enum
        enum: [management, inference, https]
        default: management
    steps:
      - run:
          name: Start torchserve, Execute << parameters.collection >> API Tests, Stop torchserve
          command: .circleci/scripts/linux_test_api.sh << parameters.collection >>
          when: always


jobs:
  build:
    parameters:
      executor:
        type: executor
    executor: << parameters.executor >>
    steps:
      - checkout
      - run:
          name: Build torchserve and torch model archiver
          command: .circleci/scripts/linux_build.sh
      - store_artifacts:
          name: Store torchserve wheel
          path: dist/
          destination: dist
      - store_artifacts:
          name: Store torchserve model archiver wheel
          path: model-archiver/dist
          destination: dist
      - store_artifacts:
          name: Store torchserve and model archiver conda builds
          path: binaries/conda/output/noarch
          destination: dist/conda
      - persist_to_workspace:
          root: .
          paths:
            - .

  frontend-tests:
    parameters:
      executor:
        type: executor
    executor: << parameters.executor >>
    steps:
      - attach-torchserve-workspace
      - run:
          name: Execute frontend gradle tests
          command: .circleci/scripts/linux_test_frontend.sh
      - store_artifacts:
          name: Store frontend gradle test results
          path: frontend/server/build/reports/tests/test

  python-tests:
    parameters:
      executor:
        type: executor
    executor: << parameters.executor >>
    steps:
      - attach-torchserve-workspace
      - run:
          name: Execute python lint and unit tests
          command: .circleci/scripts/linux_test_python.sh
      - store_artifacts:
          name: Store python Test results
          path: result_units
          destination: units

  sanity-tests:
    parameters:
      executor:
        type: executor
    executor: << parameters.executor >>
    steps:
      - attach-torchserve-workspace
      - install-torchserve
      - run:
          name: Execute sanity tests
          command: .circleci/scripts/linux_test_sanity.sh
      - store_artifacts:
          name: Store TS logs from sanity tests
          path: logs/

  api-tests:
    parameters:
      executor:
        type: executor
    executor: << parameters.executor >>
    steps:
      - attach-torchserve-workspace
      - install-torchserve
      - exeucute-api-tests:
          collection: management
      - exeucute-api-tests:
          collection: inference
      - exeucute-api-tests:
          collection: https
      - store_artifacts:
          name: Store server logs and test results
          path: test/artifacts/

  regression-tests:
    parameters:
      executor:
        type: executor
    executor: << parameters.executor >>
    steps:
      - attach-torchserve-workspace
      - install-torchserve
      - run:
          name: Execute regression suite
          command: .circleci/scripts/linux_test_regression.sh
      - store_artifacts:
          name: Store server logs from regression tests
          path: test/pytest/logs/

  benchmark:
    parameters:
      executor:
        type: executor
    executor: << parameters.executor >>
    steps:
      - attach-torchserve-workspace
      - install-torchserve
      - run:
          name: Start torchserve, Execute benchmark tests, Stop torchserve
          command: .circleci/scripts/linux_test_benchmark.sh
          no_output_timeout: 90m
      - store_artifacts:
          name: Store server logs from benchmark tests
          path: logs/
      - store_artifacts:
          name: Store Benchmark Latency resnet-18 results
          path: /tmp/TSBenchmark
      - store_artifacts:
          name: Store Apache Benchmark soak results
          path: /tmp/benchmark

  performance-regression:
    parameters:
      executor:
        type: executor
    executor: << parameters.executor >>
    steps:
      - attach-torchserve-workspace
      - install-torchserve
      - run:
          name: Start TS, Execute performance regression testcases, Stop TS
          command: .circleci/scripts/linux_test_perf_regression.sh
      - store_artifacts:
          name: Store server logs
          path: test/performance/logs/
      - store_artifacts:
          name: Store artifacts from performance regression run
          path: test/performance/run_artifacts/
      - store_test_results:
          name: Store performance regression test results for CircleCI
          path: test/performance/run_artifacts/report/

  modelarchiver-tests:
    parameters:
      executor:
        type: executor
    executor: << parameters.executor >>
    steps:
      - attach-torchserve-workspace
      - install-torchserve
      - run:
          name: Execute python lint, unit and integration tests
          command: .circleci/scripts/linux_test_modelarchiver.sh
      - store_artifacts:
          name: Store unit tests results from model archiver tests
          path: model-archiver/result_units
          destination: units


workflows:
  version: 2

  sanity:
    jobs:
      - &build
        build:
          name: build-<< matrix.executor >>
          matrix: &matrix
            parameters:
              executor:
                - ubuntu18-pythn36-cpu-docker
                - ubuntu18-conda38-cpu-docker
                - ubuntu18-pyenv37-cpu-docker
                - ubuntu18-venv36-cpu-docker
      - &modelarchiver-tests
        modelarchiver-tests:
          name: modelarchiver-tests-<< matrix.executor >>
          requires:
            - build-<< matrix.executor >>
          matrix: *matrix
      - &frontend-tests
        frontend-tests:
          name: frontend-tests-<< matrix.executor >>
          requires:
            - build-<< matrix.executor >>
          matrix: *matrix
      - &python-tests
        python-tests:
          name: python-tests-<< matrix.executor >>
          requires:
            - build-<< matrix.executor >>
          matrix: *matrix
      - &sanity-tests
        sanity-tests:
          name: sanity-tests-<< matrix.executor >>
          requires:
            - build-<< matrix.executor >>
          matrix: *matrix

  regression:
    triggers:
      - schedule:
          cron: "0 0 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - *build
      - *modelarchiver-tests
      - *frontend-tests
      - *python-tests
      - *sanity-tests
      - api-tests:
          name: api-tests-<< matrix.executor >>
          requires:
            - build-<< matrix.executor >>
          matrix: *matrix
      - regression-tests:
          name: regression-tests-<< matrix.executor >>
          requires:
            - build-<< matrix.executor >>
          matrix: *matrix

  performance:
    triggers:
      - schedule:
          cron: "0 0 * * 0"
          filters:
            branches:
              only:
                - master
    jobs:
      - *build
      - benchmark:
          name: benchmark-<< matrix.executor >>
          requires:
            - build-<< matrix.executor >>
          matrix: *matrix
# Uncomment once performance regression PR is merged
#      - performance-regression:
#          name: performance-regression-<< matrix.executor >>
#          requires:
#            - build-<< matrix.executor >>
#          matrix: *matrix
