


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Contents of this Document &mdash; PyTorch/Serve master documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Batch Inference with TorchServe" href="batch_inference_with_ts.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <div class="ecosystem-dropdown">
              <a id="dropdownMenuButton" data-toggle="ecosystem-dropdown">
                Ecosystem
              </a>
              <div class="ecosystem-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/hub"">
                  <span class=dropdown-title>Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class=dropdown-title>Tools & Libraries</span>
                  <p>Explore the ecosystem of tools and libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <div class="resources-dropdown">
              <a id="resourcesDropdownButton" data-toggle="resources-dropdown">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/resources"">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class=dropdown-title>About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  master 
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Core APIs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="inference_api.html">Inference API</a></li>
<li class="toctree-l1"><a class="reference internal" href="default_handlers.html">TorchServe default inference handlers</a></li>
<li class="toctree-l1"><a class="reference internal" href="default_handlers.html#common-features">Common features</a></li>
<li class="toctree-l1"><a class="reference internal" href="default_handlers.html#contributing">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging in Torchserve</a></li>
<li class="toctree-l1"><a class="reference internal" href="management_api.html">Management API</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">TorchServe Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="rest_api.html">TorchServe REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="configuration.html">Advanced configuration</a></li>
</ul>
<p class="caption"><span class="caption-text">TorchServe Usage</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="server.html">Running TorchServe</a></li>
<li class="toctree-l1"><a class="reference internal" href="batch_inference_with_ts.html">Batch Inference with TorchServe</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Contents of this Document</a></li>
<li class="toctree-l1"><a class="reference internal" href="#custom-handlers">Custom handlers</a></li>
<li class="toctree-l1"><a class="reference internal" href="#creating-a-model-archive-with-an-entry-point">Creating a model archive with an entry point</a></li>
<li class="toctree-l1"><a class="reference internal" href="#handling-model-execution-on-multiple-gpus">Handling model execution on multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="#installing-model-specific-python-dependencies">Installing model specific python dependencies</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Contents of this Document</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/custom_service.md.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="contents-of-this-document">
<h1>Contents of this Document<a class="headerlink" href="#contents-of-this-document" title="Permalink to this headline">Â¶</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="#custom-handlers">Custom handlers</a></p></li>
<li><p><a class="reference external" href="#creating-a-model-archive-with-an-entry-point">Creating model archive with entry point</a></p></li>
<li><p><a class="reference external" href="#handling-model-execution-on-multiple-gpus">Handling model execution on GPU</a></p></li>
<li><p><a class="reference external" href="#installing-model-specific-python-dependencies">Installing model specific python dependencies</a></p></li>
</ul>
</div>
<div class="section" id="custom-handlers">
<h1>Custom handlers<a class="headerlink" href="#custom-handlers" title="Permalink to this headline">Â¶</a></h1>
<p>Customize the behavior of TorchServe by writing a Python script that you package with
the model when you use the model archiver. TorchServe executes this code when it runs.</p>
<p>Provide a custom script to:</p>
<ul class="simple">
<li><p>Initialize the model instance</p></li>
<li><p>Pre-process input data before it is sent to the model for inference</p></li>
<li><p>Customize how the model is invoked for inference</p></li>
<li><p>Post-process output from the model before sending the response to the user</p></li>
</ul>
<p>Following is applicable to all types of custom handlers</p>
<ul class="simple">
<li><p><strong>data</strong> - The input data from the incoming request</p></li>
<li><p><strong>context</strong> - Is the TorchServe <a class="reference external" href="https://github.com/pytorch/serve/blob/master/ts/context.py">context</a>. You can use following information for customizaton
model_name, model_dir, manifest, batch_size, gpu etc.</p></li>
</ul>
<div class="section" id="start-with-basehandler">
<h2>Start with BaseHandler!<a class="headerlink" href="#start-with-basehandler" title="Permalink to this headline">Â¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">BaseHandler</span></code> implements most of the functionality you need. You can derive a new class from it, as shown in the examples and default handlers. Most of the time, youâ€™ll only need to override <code class="docutils literal notranslate"><span class="pre">preprocess</span></code> or <code class="docutils literal notranslate"><span class="pre">postprocess</span></code>.</p>
</div>
<div class="section" id="custom-handler-with-module-level-entry-point">
<h2>Custom handler with <code class="docutils literal notranslate"><span class="pre">module</span></code> level entry point<a class="headerlink" href="#custom-handler-with-module-level-entry-point" title="Permalink to this headline">Â¶</a></h2>
<p>The custom handler file must define a module level function that acts as an entry point for execution.
The function can have any name, but it must accept the following parameters and return prediction results.</p>
<p>The signature of a entry point function is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create model object</span>
<span class="n">model</span> <span class="o">=</span> <span class="bp">None</span>

<span class="k">def</span> <span class="nf">entry_point_function_name</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Works on data and context to create model object or process inference request.</span>
<span class="sd">    Following sample demonstrates how model object can be initialized for jit mode.</span>
<span class="sd">    Similarly you can do it for eager mode models.</span>
<span class="sd">    :param data: Input data for prediction</span>
<span class="sd">    :param context: context contains model server system properties</span>
<span class="sd">    :return: prediction output</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">global</span> <span class="n">model</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">data</span><span class="p">:</span>
        <span class="n">manifest</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">manifest</span>

        <span class="n">properties</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">system_properties</span>
        <span class="n">model_dir</span> <span class="o">=</span> <span class="n">properties</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model_dir&quot;</span><span class="p">)</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">properties</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;gpu_id&quot;</span><span class="p">))</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

        <span class="c1"># Read model serialize/pt file</span>
        <span class="n">serialized_file</span> <span class="o">=</span> <span class="n">manifest</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">][</span><span class="s1">&#39;serializedFile&#39;</span><span class="p">]</span>
        <span class="n">model_pt_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">model_dir</span><span class="p">,</span> <span class="n">serialized_file</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">model_pt_path</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Missing the model.pt file&quot;</span><span class="p">)</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_pt_path</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1">#infer and return result</span>
        <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>This entry point is engaged in two cases:</p>
<ol class="simple">
<li><p>TorchServe is asked to scale a model out to increase the number of backend workers (it is done either via a <code class="docutils literal notranslate"><span class="pre">PUT</span> <span class="pre">/models/{model_name}</span></code> request
or a <code class="docutils literal notranslate"><span class="pre">POST</span> <span class="pre">/models</span></code> request with <code class="docutils literal notranslate"><span class="pre">initial-workers</span></code> option or during TorchServe startup when you use the <code class="docutils literal notranslate"><span class="pre">--models</span></code> option (<code class="docutils literal notranslate"><span class="pre">torchserve</span> <span class="pre">--start</span> <span class="pre">--models</span> <span class="pre">{model_name=model.mar}</span></code>), ie., you provide model(s) to load)</p></li>
<li><p>TorchServe gets a <code class="docutils literal notranslate"><span class="pre">POST</span> <span class="pre">/predictions/{model_name}</span></code> request.</p></li>
</ol>
<p>(1) is used to scale-up or scale-down workers for a model. (2) is used as a standard way to run inference against a model. (1) is also known as model load time.
Typically, you want code for model initialization to run at model load time.
You can find out more about these and other TorchServe APIs in <a class="reference internal" href="management_api.html"><span class="doc">TorchServe Management API</span></a> and <a class="reference internal" href="inference_api.html"><span class="doc">TorchServe Inference API</span></a></p>
</div>
<div class="section" id="custom-handler-with-class-level-entry-point">
<h2>Custom handler with <code class="docutils literal notranslate"><span class="pre">class</span></code> level entry point<a class="headerlink" href="#custom-handler-with-class-level-entry-point" title="Permalink to this headline">Â¶</a></h2>
<p>You can create custom handler by having class with any name, but it must have an <code class="docutils literal notranslate"><span class="pre">initialize</span></code> and a <code class="docutils literal notranslate"><span class="pre">handle</span></code> method.</p>
<p>NOTE - If you plan to have multiple classes in same python module/file then make sure that handler class is the first in the list</p>
<p>The signature of a entry point class and functions is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ModelHandler</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A custom model handler implementation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_context</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialized</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Invoke by torchserve for loading a model</span>
<span class="sd">        :param context: context contains model server system properties</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">#  load the model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">manifest</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">manifest</span>

        <span class="n">properties</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">system_properties</span>
        <span class="n">model_dir</span> <span class="o">=</span> <span class="n">properties</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model_dir&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">properties</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;gpu_id&quot;</span><span class="p">))</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

        <span class="c1"># Read model serialize/pt file</span>
        <span class="n">serialized_file</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">manifest</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">][</span><span class="s1">&#39;serializedFile&#39;</span><span class="p">]</span>
        <span class="n">model_pt_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">model_dir</span><span class="p">,</span> <span class="n">serialized_file</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">model_pt_path</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Missing the model.pt file&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_pt_path</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">initialized</span> <span class="o">=</span> <span class="bp">True</span>


    <span class="k">def</span> <span class="nf">handle</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Invoke by TorchServe for prediction request.</span>
<span class="sd">        Do pre-processing of data, prediction using model and postprocessing of prediciton output</span>
<span class="sd">        :param data: Input data for prediction</span>
<span class="sd">        :param context: Initial context contains model server system properties.</span>
<span class="sd">        :return: prediction output</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pred_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pred_out</span>
</pre></div>
</div>
</div>
<div class="section" id="advanced-custom-handlers">
<h2>Advanced custom handlers<a class="headerlink" href="#advanced-custom-handlers" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="writing-a-custom-handler-from-scratch">
<h3>Writing a custom handler from scratch<a class="headerlink" href="#writing-a-custom-handler-from-scratch" title="Permalink to this headline">Â¶</a></h3>
<p><em>You should generally derive from BaseHandler and ONLY override methods whose behavior needs to change!</em> As you can see in the examples, most of the time you only need to override <code class="docutils literal notranslate"><span class="pre">preprocess</span></code> or <code class="docutils literal notranslate"><span class="pre">postprocess</span></code></p>
<p>Nonetheless, you are able to write a class from scratch. Below is an example. Basically, it follows a typical Init-Pre-Infer-Post pattern to create maintainable custom handler.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># custom handler file</span>

<span class="c1"># model_handler.py</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">ModelHandler defines a custom model handler.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">ts.torch_handler.base_handler</span> <span class="kn">import</span> <span class="n">BaseHandler</span>

<span class="k">class</span> <span class="nc">ModelHandler</span><span class="p">(</span><span class="n">BaseHandler</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A custom model handler implementation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_context</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialized</span> <span class="o">=</span> <span class="bp">False</span>

    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize model. This will be called during model loading time</span>
<span class="sd">        :param context: Initial context contains model server system properties.</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_context</span> <span class="o">=</span> <span class="n">context</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialized</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="c1">#  load the model, refer &#39;custom handler class&#39; above for details</span>

    <span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Transform raw input into model input data.</span>
<span class="sd">        :param batch: list of raw requests, should match batch size</span>
<span class="sd">        :return: list of preprocessed model input data</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Take the input data and make it inference ready</span>
        <span class="n">preprocessed_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">preprocessed_data</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">preprocessed_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;body&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">preprocessed_data</span>


    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_input</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Internal inference methods</span>
<span class="sd">        :param model_input: transformed model input data</span>
<span class="sd">        :return: list of inference output in NDArray</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Do some inference call to engine here and return output</span>
        <span class="n">model_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">model_input</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model_output</span>

    <span class="k">def</span> <span class="nf">postprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inference_output</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return inference result.</span>
<span class="sd">        :param inference_output: list of inference output</span>
<span class="sd">        :return: list of predict results</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Take output from network and post-process to desired format</span>
        <span class="n">postprocess_output</span> <span class="o">=</span> <span class="n">inference_output</span>
        <span class="k">return</span> <span class="n">postprocess_output</span>

    <span class="k">def</span> <span class="nf">handle</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Invoke by TorchServe for prediction request.</span>
<span class="sd">        Do pre-processing of data, prediction using model and postprocessing of prediciton output</span>
<span class="sd">        :param data: Input data for prediction</span>
<span class="sd">        :param context: Initial context contains model server system properties.</span>
<span class="sd">        :return: prediction output</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">model_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">model_input</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">model_output</span><span class="p">)</span>
</pre></div>
</div>
<p>Refer <a class="reference external" href="../examples/text_to_speech_synthesizer/waveglow_handler.py">waveglow_handler</a> for more details.</p>
</div>
<div class="section" id="extend-default-handlers">
<h3>Extend default handlers<a class="headerlink" href="#extend-default-handlers" title="Permalink to this headline">Â¶</a></h3>
<p>TorchServe has following default handlers.</p>
<ul class="simple">
<li><p><a class="reference external" href="../ts/torch_handlers/image_classifier.py">image_classifier</a></p></li>
<li><p><a class="reference external" href="../ts/torch_handlers/image_segmenter.py">image_segmenter</a></p></li>
<li><p><a class="reference external" href="../ts/torch_handlers/object_detector.py">object_detector</a></p></li>
<li><p><a class="reference external" href="../ts/torch_handlers/text_classifier.py">text_classifier</a></p></li>
</ul>
<p>If required above handlers can be extended to create custom handler. Also, you can extend abstract <a class="reference external" href="../ts/torch_handlers/base_handler.py">base_handler</a>.</p>
<p>To import the default handler in a python script use the following import statement.</p>
<p><code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">ts.torch_handler.&lt;default_handler_name&gt;</span> <span class="pre">import</span> <span class="pre">&lt;DefaultHandlerClass&gt;</span></code></p>
<p>Following is an example of custom handler extending default image_classifier handler.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ts.torch_handler.image_classifier</span> <span class="kn">import</span> <span class="n">ImageClassifier</span>

<span class="k">class</span> <span class="nc">CustomImageClassifier</span><span class="p">(</span><span class="n">ImageClassifier</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overriding this method for custom preprocessing.</span>
<span class="sd">        :param data: raw data to be transformed</span>
<span class="sd">        :return: preprocessed data for model input</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># custom pre-procsess code goes here</span>
        <span class="k">return</span> <span class="n">data</span>
</pre></div>
</div>
<p>For more details refer following examples :</p>
<ul class="simple">
<li><p><a class="reference external" href="../examples/image_classifier/mnist/mnist_handler.py">mnist digit classifier handler</a></p></li>
<li><p><a class="reference external" href="../examples/image_classifier/resnet_152_batch/resnet152_handler.py">resnet-152-batch_image classifier handler</a></p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="creating-a-model-archive-with-an-entry-point">
<h1>Creating a model archive with an entry point<a class="headerlink" href="#creating-a-model-archive-with-an-entry-point" title="Permalink to this headline">Â¶</a></h1>
<p>TorchServe identifies the entry point to the custom service from a manifest file.
When you create the model archive, specify the location of the entry point by using the <code class="docutils literal notranslate"><span class="pre">--handler</span></code> option.</p>
<p>The <a class="reference external" href="https://github.com/pytorch/serve/blob/master/model-archiver/README">model-archiver</a> tool enables you to create a model archive that TorchServe can serve.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>torch-model-archiver --model-name &lt;model-name&gt; --version &lt;model_version_number&gt; --handler model_handler<span class="o">[</span>:&lt;entry_point_function_name&gt;<span class="o">]</span> <span class="o">[</span>--model-file &lt;path_to_model_architecture_file&gt;<span class="o">]</span> --serialized-file &lt;path_to_state_dict_file&gt; <span class="o">[</span>--extra-files &lt;comma_seperarted_additional_files&gt;<span class="o">]</span> <span class="o">[</span>--export-path &lt;output-dir&gt; --model-path &lt;model_dir&gt;<span class="o">]</span> <span class="o">[</span>--runtime python3<span class="o">]</span>
</pre></div>
</div>
<p>NOTE -</p>
<ol class="simple">
<li><p>Options in [] are optional.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entry_point_function_name</span></code> can be skipped if it is named as <code class="docutils literal notranslate"><span class="pre">handle</span></code> in your <a class="reference external" href="#custom-handler-with-module-level-entry-point">handler module</a> or handler is <a class="reference external" href="#custom-handler-with-class-level-entry-point">python class</a></p></li>
</ol>
<p>This creates the file <code class="docutils literal notranslate"><span class="pre">&lt;model-name&gt;.mar</span></code> in the directory <code class="docutils literal notranslate"><span class="pre">&lt;output-dir&gt;</span></code> for python3 runtime. The <code class="docutils literal notranslate"><span class="pre">--runtime</span></code> parameter enables usage of a specific python version at runtime.
By default it uses the default python distribution of the system.</p>
<p>Example</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>torch-model-archiver --model-name waveglow_synthesizer --version <span class="m">1</span>.0 --model-file waveglow_model.py --serialized-file nvidia_waveglowpyt_fp32_20190306.pth --handler waveglow_handler.py --extra-files tacotron.zip,nvidia_tacotron2pyt_fp32_20190306.pth
</pre></div>
</div>
</div>
<div class="section" id="handling-model-execution-on-multiple-gpus">
<h1>Handling model execution on multiple GPUs<a class="headerlink" href="#handling-model-execution-on-multiple-gpus" title="Permalink to this headline">Â¶</a></h1>
<p>TorchServe scales backend workers on vCPUs or GPUs. In case of multiple GPUs TorchServe selects the gpu device in round-robin fashion and passes on this device id to the model handler in context object.
User should use this GPU ID for creating pytorch device object to ensure that all the workers are not created in the same GPU.
The following code snippet can be used in model handler to create the PyTorch device object:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">ModelHandler</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A base Model handler implementation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
        <span class="n">properties</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">system_properties</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">properties</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;gpu_id&quot;</span><span class="p">))</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="installing-model-specific-python-dependencies">
<h1>Installing model specific python dependencies<a class="headerlink" href="#installing-model-specific-python-dependencies" title="Permalink to this headline">Â¶</a></h1>
<p>Custom models/handlers may depend on different python packages which are not installed by-default as a part of <code class="docutils literal notranslate"><span class="pre">TorchServe</span></code> setup.</p>
<p>Following steps allows user to supply a list of custom python packages to be installed by <code class="docutils literal notranslate"><span class="pre">TorchServe</span></code> for seamless model serving.</p>
<ol class="simple">
<li><p><a class="reference external" href="configuration.md#allow-model-specific-custom-python-packages">Enable model specific python package installation</a></p></li>
<li><p><a class="reference external" href="../model-archiver/README.md#torch-model-archiver-command-line-interface">Supply a requirements file with the model-archive</a>.</p></li>
</ol>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="batch_inference_with_ts.html" class="btn btn-neutral" title="Batch Inference with TorchServe" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, PyTorch Serve Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Contents of this Document</a></li>
<li><a class="reference internal" href="#custom-handlers">Custom handlers</a><ul>
<li><a class="reference internal" href="#start-with-basehandler">Start with BaseHandler!</a></li>
<li><a class="reference internal" href="#custom-handler-with-module-level-entry-point">Custom handler with <code class="docutils literal notranslate"><span class="pre">module</span></code> level entry point</a></li>
<li><a class="reference internal" href="#custom-handler-with-class-level-entry-point">Custom handler with <code class="docutils literal notranslate"><span class="pre">class</span></code> level entry point</a></li>
<li><a class="reference internal" href="#advanced-custom-handlers">Advanced custom handlers</a><ul>
<li><a class="reference internal" href="#writing-a-custom-handler-from-scratch">Writing a custom handler from scratch</a></li>
<li><a class="reference internal" href="#extend-default-handlers">Extend default handlers</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#creating-a-model-archive-with-an-entry-point">Creating a model archive with an entry point</a></li>
<li><a class="reference internal" href="#handling-model-execution-on-multiple-gpus">Handling model execution on multiple GPUs</a></li>
<li><a class="reference internal" href="#installing-model-specific-python-dependencies">Installing model specific python dependencies</a></li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/language_data.js"></script>
         <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"></script>
         <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"></script>
         <script src="_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>